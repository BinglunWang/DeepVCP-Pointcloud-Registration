{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72O4rhDEZrIq",
        "outputId": "f6081b4b-bd38-4891-f0c5-378f0df34056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepVCP-Pointcloud-Registration'...\n",
            "remote: Enumerating objects: 1333, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 1333 (delta 11), reused 19 (delta 7), pack-reused 1297\u001b[K\n",
            "Receiving objects: 100% (1333/1333), 138.82 MiB | 15.24 MiB/s, done.\n",
            "Resolving deltas: 100% (344/344), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/niladridutt/DeepVCP-Pointcloud-Registration.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUGR4V4kDY15",
        "outputId": "f98057c9-a400-4d78-abac-3db1c02f9869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-15 10:12:35--  https://shapenet.cs.stanford.edu/media/modelnet40_normal_resampled.zip\n",
            "Resolving shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)... 171.67.77.19\n",
            "Connecting to shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)|171.67.77.19|:443... connected.\n",
            "WARNING: cannot verify shapenet.cs.stanford.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1705117335 (1.6G) [application/zip]\n",
            "Saving to: ‘modelnet40_normal_resampled.zip’\n",
            "\n",
            "modelnet40_normal_r 100%[===================>]   1.59G  58.1MB/s    in 29s     \n",
            "\n",
            "2023-04-15 10:13:04 (56.1 MB/s) - ‘modelnet40_normal_resampled.zip’ saved [1705117335/1705117335]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://shapenet.cs.stanford.edu/media/modelnet40_normal_resampled.zip --no-check-certificate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcNwoHRlmtTL"
      },
      "outputs": [],
      "source": [
        "! unzip -q modelnet40_normal_resampled.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpM8oiQsaMz2"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade https://github.com/unlimblue/KNN_CUDA/releases/download/0.2/KNN_CUDA-0.2-py3-none-any.whl -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWFanNlZbNz2",
        "outputId": "76a9918b-62d3-4d6f-b5cf-13539c2509d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/146.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install Ninja -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnFkroz4c8Ht",
        "outputId": "e3cecb93-6de6-4345-d933-556e00683786"
      },
      "outputs": [],
      "source": [
        "! pip install trimesh -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWF9CPBba-kv",
        "outputId": "4c7ed8e4-530a-44e8-e6df-ece38b3019f5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "import time\n",
        "import pickle\n",
        "import argparse\n",
        "from utils import *\n",
        "\n",
        "from deepVCP import DeepVCP\n",
        "from ModelNet40Dataset import ModelNet40Dataset\n",
        "from KITTIDataset import KITTIDataset\n",
        "#from CustomDataset import CustomDataset\n",
        "from deepVCP_loss import deepVCP_loss\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6eg9nCTqdPTA"
      },
      "outputs": [],
      "source": [
        "dataset = 'modelnet'\n",
        "retrain_path = 'store'\n",
        "model_path = 'final_model.pt'\n",
        "full_dataset = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2R0MObvcqHG",
        "outputId": "e6ab55fc-13e2-45ff-fd7e-455511bce501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Params: epochs: 4, batch: 1, lr: 0.001, alpha: 0.5\n",
            "\n",
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 4\n",
        "batch_size = 1\n",
        "lr = 0.001\n",
        "# loss balancing factor \n",
        "alpha = 0.5\n",
        "\n",
        "print(f\"Params: epochs: {num_epochs}, batch: {batch_size}, lr: {lr}, alpha: {alpha}\\n\")\n",
        "\n",
        "# check if cuda is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTia5bfVcxG_",
        "outputId": "70299cfc-fe26-463d-cdf2-b86eacc5dbf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Total clouds 194\n"
          ]
        }
      ],
      "source": [
        "root = 'modelnet40_normal_resampled/'\n",
        "shape_names = np.loadtxt(root+\"modelnet10_shape_names.txt\", dtype=\"str\")\n",
        "train_data= ModelNet40Dataset(root=root, augment=True, full_dataset=full_dataset, split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWiQwvqcdA7p",
        "outputId": "86a82273-537d-4db2-b8d9-e98ed20385d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Total clouds 49\n"
          ]
        }
      ],
      "source": [
        "test_data = ModelNet40Dataset(root=root, augment=True, full_dataset=full_dataset,  split='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQpQfDt_c27b",
        "outputId": "e162b74f-da03-4d21-acda-547aad9b3bdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size:  194\n",
            "Test dataset size:  49\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeepVCP(\n",
              "  (FE1): feat_extraction_layer(\n",
              "    (sa1): PointNetSetAbstraction(\n",
              "      (mlp_convs): ModuleList(\n",
              "        (0): Conv2d(6, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (mlp_bns): ModuleList(\n",
              "        (0-1): 2 x BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (sa2): PointNetSetAbstraction(\n",
              "      (mlp_convs): ModuleList(\n",
              "        (0): Conv2d(6, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (mlp_bns): ModuleList(\n",
              "        (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (sa3): PointNetSetAbstraction(\n",
              "      (mlp_convs): ModuleList(\n",
              "        (0): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (mlp_bns): ModuleList(\n",
              "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (WL): weighting_layer(\n",
              "    (fc1): Sequential(\n",
              "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (fc2): Sequential(\n",
              "      (0): Linear(in_features=16, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (fc3): Sequential(\n",
              "      (0): Linear(in_features=8, out_features=1, bias=True)\n",
              "      (1): Softplus(beta=1, threshold=20)\n",
              "    )\n",
              "  )\n",
              "  (DFE): feat_embedding_layer(\n",
              "    (fc1): Linear(in_features=35, out_features=32, bias=True)\n",
              "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "    (fc3): Linear(in_features=32, out_features=32, bias=True)\n",
              "    (max_pool): MaxPool1d(kernel_size=32, stride=32, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (cpg): cpg(\n",
              "    (conv1): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (conv2): Conv3d(16, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (conv3): Conv3d(4, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (softmax): Softmax(dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "num_train = len(train_data)\n",
        "num_test = len(test_data)\n",
        "print('Train dataset size: ', num_train)\n",
        "print('Test dataset size: ', num_test)\n",
        "\n",
        "use_normal = dataset == \"modelnet\"\n",
        "\n",
        "# Initialize the model\n",
        "model = DeepVCP(use_normal=use_normal)\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('epoch_1_model.pt', map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYuFCk8MdSHp",
        "outputId": "fdf7aedf-b807-4479-96fd-91a92a2e3e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch #0\n",
            "Processing file: cup_0001.txt\n",
            "feature extraction time:  7.300182104110718\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\niladutt\\.conda\\envs\\nsd\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7225, 8315, 2431,  ...,  867, 5384, 7366], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09932112693786621\n",
            "Loss: 0.18842597458872895\n",
            "rotation error test:  33.11807969238972\n",
            "translation error test:  0.5595127627188282\n",
            "--- 13.37564492225647 seconds ---\n",
            "Processing file: cup_0002.txt\n",
            "feature extraction time:  5.731013774871826\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3796, 9925, 7499,  ..., 6854, 5590, 6975], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0950002670288086\n",
            "Loss: 0.30353287532512857\n",
            "rotation error test:  73.2038296769951\n",
            "translation error test:  1.0332415645065136\n",
            "--- 11.647027492523193 seconds ---\n",
            "Processing file: cup_0003.txt\n",
            "feature extraction time:  5.7620134353637695\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 903, 5946, 9989,  ...,  934, 5615, 8676], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0989999771118164\n",
            "Loss: 0.3071642538261567\n",
            "rotation error test:  38.72618081430331\n",
            "translation error test:  0.9019388894498043\n",
            "--- 11.70602822303772 seconds ---\n",
            "Processing file: cup_0004.txt\n",
            "feature extraction time:  5.739013433456421\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009996891021728516\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8444, 2893, 4823,  ..., 4852, 3009, 3497], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10046768188476562\n",
            "Loss: 0.1007138676783142\n",
            "rotation error test:  25.734295584785826\n",
            "translation error test:  0.28280400693179114\n",
            "--- 11.658612489700317 seconds ---\n",
            "Processing file: cup_0005.txt\n",
            "feature extraction time:  5.764166593551636\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1932, 5688, 8014,  ..., 7423,  420, 2062], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08999991416931152\n",
            "Loss: 0.4098139925059722\n",
            "rotation error test:  15.838810940236508\n",
            "translation error test:  1.2055542046154746\n",
            "--- 11.723277568817139 seconds ---\n",
            "Epoch: [0/4], Batch: 4, Loss: 0.4098139925059722\n",
            "Processing file: cup_0006.txt\n",
            "feature extraction time:  5.761013507843018\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6120, 8274, 4232,  ..., 8983, 2196, 1560], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10909771919250488\n",
            "Loss: 0.17635016609439536\n",
            "rotation error test:  30.537398639685048\n",
            "translation error test:  0.5037381393796535\n",
            "--- 11.70112419128418 seconds ---\n",
            "Processing file: cup_0007.txt\n",
            "feature extraction time:  5.759011268615723\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 277, 8637, 8437,  ..., 8004, 4670, 7801], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400056838989258\n",
            "Loss: 0.32619128345219517\n",
            "rotation error test:  47.370664803518906\n",
            "translation error test:  0.8142146955081804\n",
            "--- 11.705023050308228 seconds ---\n",
            "Processing file: cup_0008.txt\n",
            "feature extraction time:  5.732011318206787\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000581741333008\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6550,  669, 2649,  ..., 7499, 5113,  179], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10700058937072754\n",
            "Loss: 0.13402778684177766\n",
            "rotation error test:  9.583863861492778\n",
            "translation error test:  0.3815361399217797\n",
            "--- 11.698023080825806 seconds ---\n",
            "Processing file: cup_0009.txt\n",
            "feature extraction time:  5.7680113315582275\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013998746871948242\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2268, 7559, 5784,  ..., 9465, 3908, 8019], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11907124519348145\n",
            "Loss: 0.19328606572331195\n",
            "rotation error test:  95.12363504787133\n",
            "translation error test:  0.6065598272858227\n",
            "--- 11.740737676620483 seconds ---\n",
            "Processing file: cup_0010.txt\n",
            "feature extraction time:  5.744011402130127\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2357, 9226, 6729,  ...,  996, 7355, 7810], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400128364562988\n",
            "Loss: 0.512086011003053\n",
            "rotation error test:  24.931366100199142\n",
            "translation error test:  0.873965981519509\n",
            "--- 11.710023403167725 seconds ---\n",
            "Epoch: [0/4], Batch: 9, Loss: 0.512086011003053\n",
            "Processing file: cup_0011.txt\n",
            "feature extraction time:  5.757011651992798\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015001058578491211\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.00099945068359375\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6424, 1201, 8504,  ..., 3573, 9349,  670], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900044441223145\n",
            "Loss: 0.628613982897563\n",
            "rotation error test:  30.826136299875447\n",
            "translation error test:  1.1214107664642468\n",
            "--- 11.719022989273071 seconds ---\n",
            "Processing file: cup_0012.txt\n",
            "feature extraction time:  5.764011383056641\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2772, 6161,  226,  ..., 8934, 1980, 4148], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09399986267089844\n",
            "Loss: 0.3250189050347312\n",
            "rotation error test:  20.136454557415693\n",
            "translation error test:  0.9004565470239018\n",
            "--- 11.711100339889526 seconds ---\n",
            "Processing file: cup_0013.txt\n",
            "feature extraction time:  5.738010883331299\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5212,  273, 3272,  ..., 7322, 8172, 3828], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09300041198730469\n",
            "Loss: 0.5029722073684748\n",
            "rotation error test:  5.391798614724658\n",
            "translation error test:  1.5367520479314238\n",
            "--- 11.688023090362549 seconds ---\n",
            "Processing file: cup_0014.txt\n",
            "feature extraction time:  5.725168228149414\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014002799987792969\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2286, 7091, 4000,  ..., 5360, 2434, 2247], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10599899291992188\n",
            "Loss: 0.3190508171164173\n",
            "rotation error test:  45.21077571308984\n",
            "translation error test:  0.7920269133014399\n",
            "--- 11.660744190216064 seconds ---\n",
            "Processing file: cup_0015.txt\n",
            "feature extraction time:  5.7530553340911865\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1824, 7086, 6259,  ..., 5627, 6566,  971], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09014129638671875\n",
            "Loss: 0.41290616771176747\n",
            "rotation error test:  19.111409551577843\n",
            "translation error test:  0.7865339606428915\n",
            "--- 11.677211284637451 seconds ---\n",
            "Epoch: [0/4], Batch: 14, Loss: 0.41290616771176747\n",
            "Processing file: cup_0016.txt\n",
            "feature extraction time:  5.740010499954224\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4521,  201, 9604,  ..., 2438, 8172, 1361], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11100029945373535\n",
            "Loss: 0.20183499587403392\n",
            "rotation error test:  27.7618266644945\n",
            "translation error test:  0.47865401219289677\n",
            "--- 11.703095197677612 seconds ---\n",
            "Processing file: cup_0017.txt\n",
            "feature extraction time:  5.758011341094971\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3591, 2532, 8681,  ..., 5048, 1702, 2473], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11440014839172363\n",
            "Loss: 0.15714429164954702\n",
            "rotation error test:  67.36798063184192\n",
            "translation error test:  0.667559270198021\n",
            "--- 11.72942304611206 seconds ---\n",
            "Processing file: cup_0018.txt\n",
            "feature extraction time:  5.738011121749878\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4936,   14, 7005,  ...,  105, 2194, 3198], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1032705307006836\n",
            "Loss: 0.28985778188580585\n",
            "rotation error test:  311.7987741594572\n",
            "translation error test:  0.6901287198277679\n",
            "--- 11.659383535385132 seconds ---\n",
            "Processing file: cup_0019.txt\n",
            "feature extraction time:  5.726011514663696\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7689, 7866, 2861,  ..., 7538, 1187, 6194], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0970003604888916\n",
            "Loss: 0.23293507409375208\n",
            "rotation error test:  310.34017247875283\n",
            "translation error test:  0.33336381955614103\n",
            "--- 11.661023378372192 seconds ---\n",
            "Processing file: cup_0020.txt\n",
            "feature extraction time:  5.72701096534729\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6957,  415, 9850,  ..., 9567, 1915, 5639], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09599995613098145\n",
            "Loss: 0.23612757814911733\n",
            "rotation error test:  46.227397620350146\n",
            "translation error test:  0.7158251337628966\n",
            "--- 11.68614912033081 seconds ---\n",
            "Epoch: [0/4], Batch: 19, Loss: 0.23612757814911733\n",
            "Processing file: cup_0021.txt\n",
            "feature extraction time:  5.747014045715332\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9428, 1725, 5151,  ..., 2219, 4732, 7423], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12199997901916504\n",
            "Loss: 0.27100528239079247\n",
            "rotation error test:  308.51936934559285\n",
            "translation error test:  0.6067689572706094\n",
            "--- 11.840026617050171 seconds ---\n",
            "Processing file: cup_0022.txt\n",
            "feature extraction time:  5.758012533187866\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1365, 8283, 4815,  ..., 7398, 4396, 7363], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0950002670288086\n",
            "Loss: 0.2807057519168912\n",
            "rotation error test:  159.40963373746192\n",
            "translation error test:  0.4641465224788244\n",
            "--- 11.70602297782898 seconds ---\n",
            "Processing file: cup_0023.txt\n",
            "feature extraction time:  5.748011112213135\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 654, 9148, 4035,  ..., 5817, 7057, 1783], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08599996566772461\n",
            "Loss: 0.37390594575514924\n",
            "rotation error test:  347.7032314409869\n",
            "translation error test:  1.0812820533212524\n",
            "--- 11.650023221969604 seconds ---\n",
            "Processing file: cup_0024.txt\n",
            "feature extraction time:  5.711010932922363\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7718, 6643, 3080,  ..., 5631, 5644, 4945], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11289024353027344\n",
            "Loss: 0.3170379947355905\n",
            "rotation error test:  48.2647939412051\n",
            "translation error test:  1.2111092335816527\n",
            "--- 11.640958070755005 seconds ---\n",
            "Processing file: cup_0025.txt\n",
            "feature extraction time:  5.740077257156372\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5150, 2683, 5882,  ..., 3077, 4244, 8210], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10242509841918945\n",
            "Loss: 0.3401612616243826\n",
            "rotation error test:  182.95158353438816\n",
            "translation error test:  0.5129812139220066\n",
            "--- 11.686507940292358 seconds ---\n",
            "Epoch: [0/4], Batch: 24, Loss: 0.3401612616243826\n",
            "Processing file: cup_0026.txt\n",
            "feature extraction time:  5.722070932388306\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6969, 3564, 9330,  ..., 5573,  373, 1902], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1119990348815918\n",
            "Loss: 0.36932751798954877\n",
            "rotation error test:  13.135793926316536\n",
            "translation error test:  0.9979606055131374\n",
            "--- 11.689082622528076 seconds ---\n",
            "Processing file: cup_0027.txt\n",
            "feature extraction time:  5.749011278152466\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000654220581055\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9841, 6283,  565,  ..., 2903, 2843,  267], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1080007553100586\n",
            "Loss: 0.39712534030242874\n",
            "rotation error test:  23.015848441773592\n",
            "translation error test:  0.9473059556792264\n",
            "--- 11.724023342132568 seconds ---\n",
            "Processing file: cup_0028.txt\n",
            "feature extraction time:  5.7120115756988525\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6370,  902,  462,  ..., 8396, 7055, 3683], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09400057792663574\n",
            "Loss: 0.22820267221718407\n",
            "rotation error test:  15.35635048600713\n",
            "translation error test:  0.8006342505698038\n",
            "--- 11.620023012161255 seconds ---\n",
            "Processing file: cup_0029.txt\n",
            "feature extraction time:  5.72201132774353\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 721, 1410, 4425,  ..., 5495, 4672, 4077], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12000036239624023\n",
            "Loss: 0.38710506378658055\n",
            "rotation error test:  281.38743669975196\n",
            "translation error test:  1.0461528178170185\n",
            "--- 11.64702296257019 seconds ---\n",
            "Processing file: cup_0030.txt\n",
            "feature extraction time:  5.733011245727539\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3232, 1445, 8718,  ..., 3471, 5741, 3688], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09300017356872559\n",
            "Loss: 0.2723785447275825\n",
            "rotation error test:  42.58480363727744\n",
            "translation error test:  0.5499314950310562\n",
            "--- 11.64902400970459 seconds ---\n",
            "Epoch: [0/4], Batch: 29, Loss: 0.2723785447275825\n",
            "Processing file: cup_0031.txt\n",
            "feature extraction time:  5.71401047706604\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6506, 2541, 9961,  ..., 8396, 9100, 8881], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900044441223145\n",
            "Loss: 0.25395086474315187\n",
            "rotation error test:  342.09232741887377\n",
            "translation error test:  0.7848348199632095\n",
            "--- 11.644022703170776 seconds ---\n",
            "Processing file: cup_0032.txt\n",
            "feature extraction time:  5.736011743545532\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5233,  551, 7475,  ..., 6519, 7699, 6529], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10699987411499023\n",
            "Loss: 0.5165376362720004\n",
            "rotation error test:  25.791610022572513\n",
            "translation error test:  1.2727537193077627\n",
            "--- 11.676020622253418 seconds ---\n",
            "Processing file: cup_0033.txt\n",
            "feature extraction time:  5.736505031585693\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7190, 9245, 3513,  ..., 4039, 2090,   24], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08300089836120605\n",
            "Loss: 0.2987519996776888\n",
            "rotation error test:  44.472217781624316\n",
            "translation error test:  0.7330742465068191\n",
            "--- 11.643830299377441 seconds ---\n",
            "Processing file: cup_0034.txt\n",
            "feature extraction time:  5.7220094203948975\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1679, 3168, 4253,  ..., 6081, 6661, 1048], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09099936485290527\n",
            "Loss: 0.2854521092108915\n",
            "rotation error test:  76.70095783854103\n",
            "translation error test:  0.9605073318227519\n",
            "--- 11.650019645690918 seconds ---\n",
            "Processing file: cup_0035.txt\n",
            "feature extraction time:  5.73600959777832\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5071, 9829,   30,  ..., 3925, 9322, 7248], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10600042343139648\n",
            "Loss: 0.2174148619782311\n",
            "rotation error test:  18.939797508259016\n",
            "translation error test:  0.599146063660531\n",
            "--- 11.67520546913147 seconds ---\n",
            "Epoch: [0/4], Batch: 34, Loss: 0.2174148619782311\n",
            "Processing file: cup_0036.txt\n",
            "feature extraction time:  5.7190468311309814\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2693, 1215, 4535,  ..., 6278,  292, 4104], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10134291648864746\n",
            "Loss: 0.3896751859356479\n",
            "rotation error test:  194.44114088318557\n",
            "translation error test:  1.1152993955130666\n",
            "--- 11.645478963851929 seconds ---\n",
            "Processing file: cup_0037.txt\n",
            "feature extraction time:  5.732130765914917\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7633, 6008, 5571,  ..., 8465, 4881, 1800], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09999942779541016\n",
            "Loss: 0.1534942527909382\n",
            "rotation error test:  21.962832019953492\n",
            "translation error test:  0.28550445084338305\n",
            "--- 11.669140815734863 seconds ---\n",
            "Processing file: cup_0038.txt\n",
            "feature extraction time:  5.760010242462158\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7670, 7355, 3753,  ..., 3380, 1729, 4763], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09999990463256836\n",
            "Loss: 0.25854555995097855\n",
            "rotation error test:  141.33137903743688\n",
            "translation error test:  0.47070870588080793\n",
            "--- 11.68101954460144 seconds ---\n",
            "Processing file: cup_0039.txt\n",
            "feature extraction time:  5.730009317398071\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2008, 1032, 9261,  ..., 3428, 4012, 5901], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300016403198242\n",
            "Loss: 0.10271788734748187\n",
            "rotation error test:  40.68740043541641\n",
            "translation error test:  0.07671733292027265\n",
            "--- 11.665019512176514 seconds ---\n",
            "Processing file: cup_0040.txt\n",
            "feature extraction time:  5.724009275436401\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2944, 8970, 5214,  ..., 7632, 7366, 9477], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0989992618560791\n",
            "Loss: 0.19906363983608427\n",
            "rotation error test:  25.0985018952479\n",
            "translation error test:  0.5776581086088942\n",
            "--- 11.656019687652588 seconds ---\n",
            "Epoch: [0/4], Batch: 39, Loss: 0.19906363983608427\n",
            "Processing file: cup_0041.txt\n",
            "feature extraction time:  5.753009796142578\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3426,  997, 5515,  ..., 1770, 1534, 3457], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300040245056152\n",
            "Loss: 0.3305783455092762\n",
            "rotation error test:  22.110959941631265\n",
            "translation error test:  0.9456575009760464\n",
            "--- 11.675075054168701 seconds ---\n",
            "Processing file: cup_0042.txt\n",
            "feature extraction time:  5.7470703125\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9289, 6155, 6758,  ..., 6491, 1070, 3928], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09739279747009277\n",
            "Loss: 0.31780045784298333\n",
            "rotation error test:  35.59818088557525\n",
            "translation error test:  0.5871918303056919\n",
            "--- 11.68353271484375 seconds ---\n",
            "Processing file: cup_0043.txt\n",
            "feature extraction time:  5.770009994506836\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015999317169189453\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4076, 8877,  577,  ..., 5784, 1285, 1255], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10600042343139648\n",
            "Loss: 0.37227809158660463\n",
            "rotation error test:  55.66319297162367\n",
            "translation error test:  0.5322673595519354\n",
            "--- 11.73016881942749 seconds ---\n",
            "Processing file: cup_0044.txt\n",
            "feature extraction time:  5.762012004852295\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1961, 8593, 8378,  ..., 6853, 4497, 2266], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10699963569641113\n",
            "Loss: 0.30949752856847523\n",
            "rotation error test:  24.114566356726773\n",
            "translation error test:  1.0043001173963917\n",
            "--- 11.707123517990112 seconds ---\n",
            "Processing file: cup_0045.txt\n",
            "feature extraction time:  5.735121726989746\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015003442764282227\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5389, 9650, 7384,  ..., 6503, 3735, 2840], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11442756652832031\n",
            "Loss: 0.33231742821050075\n",
            "rotation error test:  108.28404303637082\n",
            "translation error test:  1.0627856749222901\n",
            "--- 11.700019359588623 seconds ---\n",
            "Epoch: [0/4], Batch: 44, Loss: 0.33231742821050075\n",
            "Processing file: cup_0046.txt\n",
            "feature extraction time:  5.750009298324585\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5399, 9287, 7110,  ..., 5443, 1629,  424], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08900094032287598\n",
            "Loss: 0.19896999980264155\n",
            "rotation error test:  13.217464809825518\n",
            "translation error test:  0.5535065333740702\n",
            "--- 11.688341617584229 seconds ---\n",
            "Processing file: cup_0047.txt\n",
            "feature extraction time:  5.757012128829956\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.016000032424926758\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6838, 9483, 1816,  ..., 6847, 6328, 9089], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09100151062011719\n",
            "Loss: 0.11091606423217637\n",
            "rotation error test:  60.014450510131084\n",
            "translation error test:  0.24416653639837033\n",
            "--- 11.683022022247314 seconds ---\n",
            "Processing file: cup_0048.txt\n",
            "feature extraction time:  5.743009328842163\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009996891021728516\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3189, 9185,  347,  ..., 7366, 7030, 1683], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900020599365234\n",
            "Loss: 0.22438118726935044\n",
            "rotation error test:  21.63271590538049\n",
            "translation error test:  0.57770450493827\n",
            "--- 11.69924783706665 seconds ---\n",
            "Processing file: cup_0049.txt\n",
            "feature extraction time:  5.763138055801392\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.0149993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010006427764892578\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6186, 1189, 5059,  ..., 7355, 3635, 5778], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08299994468688965\n",
            "Loss: 0.3686862828130308\n",
            "rotation error test:  128.41398794733888\n",
            "translation error test:  0.9694356459304948\n",
            "--- 11.664222002029419 seconds ---\n",
            "Processing file: cup_0050.txt\n",
            "feature extraction time:  5.696009159088135\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8205, 8126, 4491,  ..., 8713,  777, 6387], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10099983215332031\n",
            "Loss: 0.4657233993177592\n",
            "rotation error test:  30.97608605805726\n",
            "translation error test:  1.3079556780697872\n",
            "--- 11.584178447723389 seconds ---\n",
            "Epoch: [0/4], Batch: 49, Loss: 0.4657233993177592\n",
            "Processing file: cup_0051.txt\n",
            "feature extraction time:  5.7220518589019775\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009996891021728516\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6014, 9860, 2812,  ..., 7271, 3657, 3599], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600043296813965\n",
            "Loss: 0.2344266340624919\n",
            "rotation error test:  72.4364730023866\n",
            "translation error test:  0.2618938889235394\n",
            "--- 11.63543152809143 seconds ---\n",
            "Processing file: cup_0052.txt\n",
            "feature extraction time:  5.713423728942871\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1937, 9587, 5542,  ..., 1586, 2967, 7112], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10107922554016113\n",
            "Loss: 0.3044095046715745\n",
            "rotation error test:  328.8356398580291\n",
            "translation error test:  0.8344778415270467\n",
            "--- 11.642990827560425 seconds ---\n",
            "Processing file: cup_0053.txt\n",
            "feature extraction time:  5.7270097732543945\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3734, 3933, 6147,  ..., 4235, 3493, 8366], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600043296813965\n",
            "Loss: 0.3271374349983623\n",
            "rotation error test:  97.55729821020468\n",
            "translation error test:  0.9236068296214494\n",
            "--- 11.658019781112671 seconds ---\n",
            "Processing file: cup_0054.txt\n",
            "feature extraction time:  5.7290098667144775\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9127,  356, 4540,  ..., 8042, 5037, 2206], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900044441223145\n",
            "Loss: 0.2957096499935561\n",
            "rotation error test:  24.902922255598465\n",
            "translation error test:  0.9747923396268439\n",
            "--- 11.649019956588745 seconds ---\n",
            "Processing file: cup_0055.txt\n",
            "feature extraction time:  5.739010334014893\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4162, 7746, 1142,  ..., 4217,  445, 3239], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1100001335144043\n",
            "Loss: 0.31031820295114526\n",
            "rotation error test:  313.69055366115197\n",
            "translation error test:  0.6811177918822875\n",
            "--- 11.662019729614258 seconds ---\n",
            "Epoch: [0/4], Batch: 54, Loss: 0.31031820295114526\n",
            "Processing file: cup_0056.txt\n",
            "feature extraction time:  5.751009941101074\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6973, 9694, 9658,  ..., 7846, 4486, 7253], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500025749206543\n",
            "Loss: 0.3064615903957366\n",
            "rotation error test:  152.16315943285986\n",
            "translation error test:  0.6550817398552694\n",
            "--- 11.692019701004028 seconds ---\n",
            "Processing file: cup_0057.txt\n",
            "feature extraction time:  5.744009971618652\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6177,  162, 2067,  ..., 4908,  781, 6459], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400009155273438\n",
            "Loss: 0.21697612751217923\n",
            "rotation error test:  112.63546584968493\n",
            "translation error test:  0.2705602722609064\n",
            "--- 11.673894882202148 seconds ---\n",
            "Processing file: cup_0058.txt\n",
            "feature extraction time:  5.714009761810303\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2938, 3894, 5193,  ..., 7030, 8782, 2777], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500025749206543\n",
            "Loss: 0.29203791265602635\n",
            "rotation error test:  330.68986453719333\n",
            "translation error test:  0.6927384985986454\n",
            "--- 11.640078067779541 seconds ---\n",
            "Processing file: cup_0059.txt\n",
            "feature extraction time:  5.7190070152282715\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2280, 5730, 8482,  ..., 6082, 5034, 9809], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09200072288513184\n",
            "Loss: 0.2451695564536407\n",
            "rotation error test:  22.932719978622043\n",
            "translation error test:  0.6265895619084114\n",
            "--- 11.62601613998413 seconds ---\n",
            "Processing file: cup_0060.txt\n",
            "feature extraction time:  5.7350077629089355\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3079, 7813, 1163,  ..., 2451, 4022, 8813], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10699987411499023\n",
            "Loss: 0.2321465390463794\n",
            "rotation error test:  35.50502193063919\n",
            "translation error test:  0.8071562690016804\n",
            "--- 11.679015874862671 seconds ---\n",
            "Epoch: [0/4], Batch: 59, Loss: 0.2321465390463794\n",
            "Processing file: cup_0061.txt\n",
            "feature extraction time:  5.722008466720581\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015999794006347656\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3896, 8026, 2840,  ..., 6117, 6894, 4457], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08999943733215332\n",
            "Loss: 0.1293013902979479\n",
            "rotation error test:  27.768886623909236\n",
            "translation error test:  0.28534682020670366\n",
            "--- 11.630016088485718 seconds ---\n",
            "Processing file: cup_0062.txt\n",
            "feature extraction time:  5.7370076179504395\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9568, 8443, 1516,  ..., 9915, 8425, 5204], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10600018501281738\n",
            "Loss: 0.35628311928546935\n",
            "rotation error test:  25.24790642393124\n",
            "translation error test:  0.7434368492347543\n",
            "--- 11.651015996932983 seconds ---\n",
            "Processing file: cup_0063.txt\n",
            "feature extraction time:  5.745008230209351\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3375,   40, 5015,  ..., 5179, 6593, 5307], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200023651123047\n",
            "Loss: 0.19306912008443294\n",
            "rotation error test:  38.50984013650737\n",
            "translation error test:  0.3468779941342308\n",
            "--- 11.675017833709717 seconds ---\n",
            "Processing file: cup_0064.txt\n",
            "feature extraction time:  5.715077638626099\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010004043579101562\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6250, 2134, 1228,  ..., 4143, 8125, 2695], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09914445877075195\n",
            "Loss: 0.21952767833923734\n",
            "rotation error test:  268.981024825564\n",
            "translation error test:  0.42655075889035005\n",
            "--- 11.647233486175537 seconds ---\n",
            "Processing file: cup_0065.txt\n",
            "feature extraction time:  5.716010570526123\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7644, 2847, 5419,  ..., 6858, 8222, 4590], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10130620002746582\n",
            "Loss: 0.25005237224239063\n",
            "rotation error test:  134.07066115779955\n",
            "translation error test:  0.3856983563322041\n",
            "--- 11.649386882781982 seconds ---\n",
            "Epoch: [0/4], Batch: 64, Loss: 0.25005237224239063\n",
            "Processing file: cup_0066.txt\n",
            "feature extraction time:  5.7380077838897705\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 351, 9180,  643,  ..., 2383, 7888, 5460], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500001907348633\n",
            "Loss: 0.1549995590811434\n",
            "rotation error test:  13.381330967417211\n",
            "translation error test:  0.5602543740613539\n",
            "--- 11.657015800476074 seconds ---\n",
            "Processing file: cup_0067.txt\n",
            "feature extraction time:  5.724105596542358\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01600027084350586\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2395, 3941, 6467,  ..., 4167, 5103,  615], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10000014305114746\n",
            "Loss: 0.2812398611862624\n",
            "rotation error test:  49.74838105944511\n",
            "translation error test:  0.6973218671231365\n",
            "--- 11.665114164352417 seconds ---\n",
            "Processing file: cup_0068.txt\n",
            "feature extraction time:  5.716066122055054\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6363,  519, 4300,  ...,  873, 5300, 3908], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11400032043457031\n",
            "Loss: 0.3467525336761772\n",
            "rotation error test:  25.61219391377735\n",
            "translation error test:  1.1016215806353808\n",
            "--- 11.65111255645752 seconds ---\n",
            "Processing file: cup_0069.txt\n",
            "feature extraction time:  5.7580084800720215\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.0149993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 513, 1159, 9004,  ..., 1820, 8903,  936], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09900021553039551\n",
            "Loss: 0.09362232391639326\n",
            "rotation error test:  30.40557769659561\n",
            "translation error test:  0.1463315008683125\n",
            "--- 11.728016376495361 seconds ---\n",
            "Processing file: cup_0070.txt\n",
            "feature extraction time:  5.766973972320557\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4203, 1026, 1610,  ..., 8559, 7299, 9505], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600019454956055\n",
            "Loss: 0.29504875079168613\n",
            "rotation error test:  330.61117699105705\n",
            "translation error test:  0.6948956692225171\n",
            "--- 11.719980955123901 seconds ---\n",
            "Epoch: [0/4], Batch: 69, Loss: 0.29504875079168613\n",
            "Processing file: cup_0071.txt\n",
            "feature extraction time:  5.755007743835449\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01600027084350586\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4065, 9510, 8456,  ...,  470, 4175, 2261], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09200024604797363\n",
            "Loss: 0.2243747386300169\n",
            "rotation error test:  16.62836717061562\n",
            "translation error test:  0.44609187884766016\n",
            "--- 11.70301628112793 seconds ---\n",
            "Processing file: cup_0072.txt\n",
            "feature extraction time:  5.761008024215698\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7853,  637, 8704,  ..., 2355, 4194, 7649], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09399962425231934\n",
            "Loss: 0.2512979901349367\n",
            "rotation error test:  59.14708833846646\n",
            "translation error test:  0.6413639500024232\n",
            "--- 11.709015607833862 seconds ---\n",
            "Processing file: cup_0073.txt\n",
            "feature extraction time:  5.770008325576782\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.0149993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4601, 2730, 7399,  ...,  216, 6277, 9905], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0970001220703125\n",
            "Loss: 0.34253156551044306\n",
            "rotation error test:  30.989459105996747\n",
            "translation error test:  0.9356492974120271\n",
            "--- 11.704015731811523 seconds ---\n",
            "Processing file: cup_0074.txt\n",
            "feature extraction time:  5.761084794998169\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8651, 8282, 4077,  ..., 9674, 9298,  401], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10600018501281738\n",
            "Loss: 0.32466875789509514\n",
            "rotation error test:  36.149050941287534\n",
            "translation error test:  0.8668084483499713\n",
            "--- 11.710373401641846 seconds ---\n",
            "Processing file: cup_0075.txt\n",
            "feature extraction time:  5.761091947555542\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   1, 2876, 7855,  ..., 4406, 6787, 6758], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10600018501281738\n",
            "Loss: 0.27695869061181216\n",
            "rotation error test:  21.52458806917532\n",
            "translation error test:  1.0081950574726344\n",
            "--- 11.72010064125061 seconds ---\n",
            "Epoch: [0/4], Batch: 74, Loss: 0.27695869061181216\n",
            "Processing file: cup_0076.txt\n",
            "feature extraction time:  5.774065732955933\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 423, 4832, 3293,  ..., 4269, 5433, 8078], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10000061988830566\n",
            "Loss: 0.3004290587556945\n",
            "rotation error test:  18.30263268239611\n",
            "translation error test:  0.8447252185959068\n",
            "--- 11.713249921798706 seconds ---\n",
            "Processing file: cup_0077.txt\n",
            "feature extraction time:  5.760010719299316\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1830, 1333, 3954,  ..., 8946, 5588, 7829], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10805916786193848\n",
            "Loss: 0.15103398781792157\n",
            "rotation error test:  339.453294556169\n",
            "translation error test:  0.37019091148574856\n",
            "--- 11.721077919006348 seconds ---\n",
            "Processing file: cup_0078.txt\n",
            "feature extraction time:  5.7640063762664795\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9335, 6388, 7240,  ..., 9494, 4851, 7017], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10000014305114746\n",
            "Loss: 0.14135821045356323\n",
            "rotation error test:  312.7163441881134\n",
            "translation error test:  0.4407693304006692\n",
            "--- 11.733014822006226 seconds ---\n",
            "Processing file: cup_0079.txt\n",
            "feature extraction time:  5.741042852401733\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000654220581055\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.00099945068359375\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2116, 8529, 4753,  ..., 9406, 1143,  814], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0950005054473877\n",
            "Loss: 0.2857117535452416\n",
            "rotation error test:  28.87203942115332\n",
            "translation error test:  0.9241886562423166\n",
            "--- 11.68300747871399 seconds ---\n",
            "Processing file: lamp_0001.txt\n",
            "feature extraction time:  5.738072156906128\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013998985290527344\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2449, 5238, 3199,  ..., 4054, 8762, 4258], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1101841926574707\n",
            "Loss: 0.1472617153443776\n",
            "rotation error test:  23.40993358506212\n",
            "translation error test:  0.31124234914515775\n",
            "--- 11.676469087600708 seconds ---\n",
            "Epoch: [0/4], Batch: 79, Loss: 0.1472617153443776\n",
            "Processing file: lamp_0002.txt\n",
            "feature extraction time:  5.73101019859314\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013998985290527344\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  19, 9508, 2347,  ..., 2250, 1443, 6338], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.14300012588500977\n",
            "Loss: 0.21763485333723173\n",
            "rotation error test:  30.418706493930355\n",
            "translation error test:  0.6802972796572037\n",
            "--- 11.689320087432861 seconds ---\n",
            "Processing file: lamp_0003.txt\n",
            "feature extraction time:  5.7290074825286865\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7924, 1515, 5295,  ..., 4463, 1134, 3080], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11466455459594727\n",
            "Loss: 0.2961286563384274\n",
            "rotation error test:  181.13978190144627\n",
            "translation error test:  0.35068074475251027\n",
            "--- 11.651683568954468 seconds ---\n",
            "Processing file: lamp_0004.txt\n",
            "feature extraction time:  5.736130952835083\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000011444091797\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 378, 4413, 8771,  ..., 5358, 9992, 3848], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12204384803771973\n",
            "Loss: 0.06733068709839113\n",
            "rotation error test:  22.275671374615527\n",
            "translation error test:  0.12975590654983238\n",
            "--- 11.674185276031494 seconds ---\n",
            "Processing file: lamp_0005.txt\n",
            "feature extraction time:  5.748009920120239\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2126, 3526, 9549,  ...,  480, 6712,  435], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1139993667602539\n",
            "Loss: 0.2860948688617599\n",
            "rotation error test:  29.15051803548638\n",
            "translation error test:  0.5750328905903286\n",
            "--- 11.703016757965088 seconds ---\n",
            "Processing file: lamp_0006.txt\n",
            "feature extraction time:  5.730006694793701\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4124, 4385, 5219,  ..., 3230, 7569, 7209], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09999966621398926\n",
            "Loss: 0.2873542056377172\n",
            "rotation error test:  143.17803730128844\n",
            "translation error test:  0.63019918570213\n",
            "--- 11.65001368522644 seconds ---\n",
            "Epoch: [0/4], Batch: 84, Loss: 0.2873542056377172\n",
            "Processing file: lamp_0007.txt\n",
            "feature extraction time:  5.73114013671875\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9295,  823, 3370,  ..., 5833, 1081, 1990], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12400031089782715\n",
            "Loss: 0.18325812585540352\n",
            "rotation error test:  32.14433647767949\n",
            "translation error test:  0.40634022213102267\n",
            "--- 11.690372943878174 seconds ---\n",
            "Processing file: lamp_0008.txt\n",
            "feature extraction time:  5.7560508251190186\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1060, 7962, 6261,  ..., 3542, 8231, 8534], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10517144203186035\n",
            "Loss: 0.1337486465919888\n",
            "rotation error test:  24.320941561927846\n",
            "translation error test:  0.40651902225039366\n",
            "--- 11.660844564437866 seconds ---\n",
            "Processing file: lamp_0009.txt\n",
            "feature extraction time:  5.725006818771362\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6925, 1654, 3061,  ..., 9118, 4017, 2357], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11100029945373535\n",
            "Loss: 0.2532516030325044\n",
            "rotation error test:  14.587796355362718\n",
            "translation error test:  0.6541467237071495\n",
            "--- 11.639013528823853 seconds ---\n",
            "Processing file: lamp_0010.txt\n",
            "feature extraction time:  5.726074934005737\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3437, 8230, 1238,  ...,  161, 1209, 3592], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1099998950958252\n",
            "Loss: 0.27523517992541907\n",
            "rotation error test:  334.8308377699683\n",
            "translation error test:  0.36845422073107065\n",
            "--- 11.654158592224121 seconds ---\n",
            "Processing file: lamp_0011.txt\n",
            "feature extraction time:  5.724005460739136\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5787,  735, 5153,  ..., 5336, 2870, 1951], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11700034141540527\n",
            "Loss: 0.1834817522610716\n",
            "rotation error test:  38.783915251180595\n",
            "translation error test:  0.4800125128260127\n",
            "--- 11.64201307296753 seconds ---\n",
            "Epoch: [0/4], Batch: 89, Loss: 0.1834817522610716\n",
            "Processing file: lamp_0012.txt\n",
            "feature extraction time:  5.729007244110107\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4119, 5382,  814,  ..., 7654, 6764, 6192], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1120002269744873\n",
            "Loss: 0.16944982926490484\n",
            "rotation error test:  65.01818161402761\n",
            "translation error test:  0.35346970911702497\n",
            "--- 11.668014526367188 seconds ---\n",
            "Processing file: lamp_0013.txt\n",
            "feature extraction time:  5.736006021499634\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2646, 9594, 4104,  ..., 9608, 9961, 1642], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12600040435791016\n",
            "Loss: 0.38188112109466016\n",
            "rotation error test:  41.340542277509805\n",
            "translation error test:  0.9187385208720286\n",
            "--- 11.68001389503479 seconds ---\n",
            "Processing file: lamp_0014.txt\n",
            "feature extraction time:  5.737006425857544\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.018000125885009766\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5880, 6577, 1250,  ..., 9103, 8765, 8972], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900020599365234\n",
            "Loss: 0.37422728747711786\n",
            "rotation error test:  36.2190761927697\n",
            "translation error test:  0.9478058392929403\n",
            "--- 11.677013397216797 seconds ---\n",
            "Processing file: lamp_0015.txt\n",
            "feature extraction time:  5.734007120132446\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000581741333008\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 894, 5086, 3909,  ..., 4389, 9054, 3564], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500049591064453\n",
            "Loss: 0.3086080394166544\n",
            "rotation error test:  242.90805784604086\n",
            "translation error test:  0.6067128567223127\n",
            "--- 11.671013832092285 seconds ---\n",
            "Processing file: lamp_0016.txt\n",
            "feature extraction time:  5.740007162094116\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010004043579101562\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6983, 8617,  825,  ...,  727, 2740, 8255], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11699986457824707\n",
            "Loss: 0.2486760254656203\n",
            "rotation error test:  140.520999987772\n",
            "translation error test:  0.3086895280664316\n",
            "--- 11.675014019012451 seconds ---\n",
            "Epoch: [0/4], Batch: 94, Loss: 0.2486760254656203\n",
            "Processing file: lamp_0017.txt\n",
            "feature extraction time:  5.742006778717041\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010008811950683594\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2860, 7016, 9577,  ..., 7077, 8782, 3597], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13100051879882812\n",
            "Loss: 0.3462228826681738\n",
            "rotation error test:  25.558365205220568\n",
            "translation error test:  1.2434492588026043\n",
            "--- 11.718013763427734 seconds ---\n",
            "Processing file: lamp_0018.txt\n",
            "feature extraction time:  5.751007080078125\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000581741333008\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009996891021728516\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2200, 4752, 5740,  ..., 4856, 1065, 3095], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1080007553100586\n",
            "Loss: 0.21246312253999064\n",
            "rotation error test:  16.84323080205905\n",
            "translation error test:  0.6668209539104338\n",
            "--- 11.701014041900635 seconds ---\n",
            "Processing file: lamp_0019.txt\n",
            "feature extraction time:  5.74600625038147\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5864, 7372, 8238,  ..., 5402, 8778, 2181], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09300041198730469\n",
            "Loss: 0.17121140246248606\n",
            "rotation error test:  29.614639852151864\n",
            "translation error test:  0.5270663484379118\n",
            "--- 11.656013488769531 seconds ---\n",
            "Processing file: lamp_0020.txt\n",
            "feature extraction time:  5.734007358551025\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9529, 3333, 9930,  ..., 3093, 9730, 7075], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09400057792663574\n",
            "Loss: 0.16315881491404655\n",
            "rotation error test:  43.405231424211834\n",
            "translation error test:  0.5256250520585282\n",
            "--- 11.672014713287354 seconds ---\n",
            "Processing file: lamp_0021.txt\n",
            "feature extraction time:  5.738007307052612\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000581741333008\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5706, 2656, 1606,  ..., 8568, 3165,  954], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10637259483337402\n",
            "Loss: 0.187891438834971\n",
            "rotation error test:  20.484727013803816\n",
            "translation error test:  0.4369872010919098\n",
            "--- 11.686389207839966 seconds ---\n",
            "Epoch: [0/4], Batch: 99, Loss: 0.187891438834971\n",
            "Processing file: lamp_0022.txt\n",
            "feature extraction time:  5.734370708465576\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 663, 3178, 8987,  ..., 2430, 2784, 8938], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1210012435913086\n",
            "Loss: 0.23416769321893793\n",
            "rotation error test:  28.290715719852656\n",
            "translation error test:  0.4936804405877031\n",
            "--- 11.668378114700317 seconds ---\n",
            "Processing file: lamp_0023.txt\n",
            "feature extraction time:  5.737063646316528\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9918, 5875, 7720,  ..., 1676, 2614, 6682], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11500048637390137\n",
            "Loss: 0.27386905993234034\n",
            "rotation error test:  12.896836233614888\n",
            "translation error test:  0.6827291895270179\n",
            "--- 11.683070659637451 seconds ---\n",
            "Processing file: lamp_0024.txt\n",
            "feature extraction time:  5.7561118602752686\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010004043579101562\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7268, 3664, 5761,  ..., 9920, 7712, 3265], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12200069427490234\n",
            "Loss: 0.1382677390593591\n",
            "rotation error test:  16.521408169222948\n",
            "translation error test:  0.3729694224035029\n",
            "--- 11.687951803207397 seconds ---\n",
            "Processing file: lamp_0025.txt\n",
            "feature extraction time:  5.587006568908691\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9497,   91, 4154,  ..., 1502, 1086, 8447], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12000036239624023\n",
            "Loss: 0.3866882899092389\n",
            "rotation error test:  133.91828880677502\n",
            "translation error test:  1.0316124419379298\n",
            "--- 11.543014764785767 seconds ---\n",
            "Processing file: lamp_0026.txt\n",
            "feature extraction time:  5.550128221511841\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2481, 5922,   11,  ...,  338, 1331, 6006], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200023651123047\n",
            "Loss: 0.25666342369685935\n",
            "rotation error test:  336.2734464383697\n",
            "translation error test:  0.725387770054447\n",
            "--- 11.379395723342896 seconds ---\n",
            "Epoch: [0/4], Batch: 104, Loss: 0.25666342369685935\n",
            "Processing file: lamp_0027.txt\n",
            "feature extraction time:  5.74600625038147\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 399, 4849, 1928,  ..., 6859, 6194, 4981], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09920144081115723\n",
            "Loss: 0.1786837458368724\n",
            "rotation error test:  33.53066293788382\n",
            "translation error test:  0.6313878776474336\n",
            "--- 11.669217824935913 seconds ---\n",
            "Processing file: lamp_0028.txt\n",
            "feature extraction time:  5.716006755828857\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3238, 1214, 2128,  ..., 1169, 2933, 4480], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11700034141540527\n",
            "Loss: 0.24370435799795565\n",
            "rotation error test:  27.110056672590567\n",
            "translation error test:  0.8644780116737631\n",
            "--- 11.666164636611938 seconds ---\n",
            "Processing file: lamp_0029.txt\n",
            "feature extraction time:  5.720009803771973\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.017000198364257812\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2787, 2943, 6346,  ..., 9419, 4104,  678], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600067138671875\n",
            "Loss: 0.2558868833536459\n",
            "rotation error test:  150.5682923500983\n",
            "translation error test:  0.45107957330523085\n",
            "--- 11.62001657485962 seconds ---\n",
            "Processing file: lamp_0030.txt\n",
            "feature extraction time:  5.7120068073272705\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01500082015991211\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8108, 8362, 4179,  ..., 4248, 3017, 7420], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300040245056152\n",
            "Loss: 0.3850414612451659\n",
            "rotation error test:  131.3168115605948\n",
            "translation error test:  0.8415341298440945\n",
            "--- 11.600382566452026 seconds ---\n",
            "Processing file: lamp_0031.txt\n",
            "feature extraction time:  5.739009380340576\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 478, 1351, 7553,  ..., 1990, 2496, 9713], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.14800024032592773\n",
            "Loss: 0.2766373253748055\n",
            "rotation error test:  21.463505609365736\n",
            "translation error test:  0.7369693359912464\n",
            "--- 11.67801570892334 seconds ---\n",
            "Epoch: [0/4], Batch: 109, Loss: 0.2766373253748055\n",
            "Processing file: lamp_0032.txt\n",
            "feature extraction time:  5.718064069747925\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9509, 9364, 2182,  ..., 6452, 9094, 1416], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.14299964904785156\n",
            "Loss: 0.17964438524055507\n",
            "rotation error test:  30.623671869940676\n",
            "translation error test:  0.5664455370958601\n",
            "--- 11.66809892654419 seconds ---\n",
            "Processing file: lamp_0033.txt\n",
            "feature extraction time:  5.705005884170532\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01600050926208496\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2759, 1994, 2621,  ..., 9922, 4173, 9857], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1100006103515625\n",
            "Loss: 0.2527975097277948\n",
            "rotation error test:  33.07073919051048\n",
            "translation error test:  0.890655013331358\n",
            "--- 11.602012395858765 seconds ---\n",
            "Processing file: lamp_0034.txt\n",
            "feature extraction time:  5.72200608253479\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  21, 1425, 1949,  ..., 2406, 9778,  928], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1230766773223877\n",
            "Loss: 0.2432629765227694\n",
            "rotation error test:  24.479809783445077\n",
            "translation error test:  0.7857318410863474\n",
            "--- 11.645358085632324 seconds ---\n",
            "Processing file: lamp_0035.txt\n",
            "feature extraction time:  5.707237243652344\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2536, 8336, 4841,  ..., 7952, 4798,   23], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600019454956055\n",
            "Loss: 0.2980976301568832\n",
            "rotation error test:  33.43844983735868\n",
            "translation error test:  0.5588805177728808\n",
            "--- 11.594244003295898 seconds ---\n",
            "Processing file: lamp_0036.txt\n",
            "feature extraction time:  5.719117641448975\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013956785202026367\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4365, 8773, 6663,  ..., 8733, 9998, 7531], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11200070381164551\n",
            "Loss: 0.08354482011666053\n",
            "rotation error test:  7.206342474780697\n",
            "translation error test:  0.15604680133250043\n",
            "--- 11.647223234176636 seconds ---\n",
            "Epoch: [0/4], Batch: 114, Loss: 0.08354482011666053\n",
            "Processing file: lamp_0037.txt\n",
            "feature extraction time:  5.706110239028931\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  28, 9467, 6795,  ..., 3057, 7204, 8909], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12600040435791016\n",
            "Loss: 0.3085893283696036\n",
            "rotation error test:  93.38668199697862\n",
            "translation error test:  0.9621742072152062\n",
            "--- 11.63319993019104 seconds ---\n",
            "Processing file: lamp_0038.txt\n",
            "feature extraction time:  5.719005346298218\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9759, 1045,  109,  ..., 9493, 4320, 5426], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09900021553039551\n",
            "Loss: 0.35205810911646673\n",
            "rotation error test:  31.854172167571882\n",
            "translation error test:  1.2084453425789674\n",
            "--- 11.632012367248535 seconds ---\n",
            "Processing file: lamp_0039.txt\n",
            "feature extraction time:  5.715613603591919\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8734,   14, 2045,  ..., 3854, 9875, 7589], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11100077629089355\n",
            "Loss: 0.3329675374642668\n",
            "rotation error test:  59.93140219673783\n",
            "translation error test:  0.5573236472878805\n",
            "--- 11.636621236801147 seconds ---\n",
            "Processing file: lamp_0040.txt\n",
            "feature extraction time:  5.735005617141724\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4203, 4583, 1992,  ..., 8843, 5596, 4703], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11411261558532715\n",
            "Loss: 0.22725739165290507\n",
            "rotation error test:  27.157066363377748\n",
            "translation error test:  0.6872871970210926\n",
            "--- 11.664092302322388 seconds ---\n",
            "Processing file: lamp_0041.txt\n",
            "feature extraction time:  5.71606707572937\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5054,  501, 5178,  ..., 9954, 5458, 7617], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12299990653991699\n",
            "Loss: 0.2284625731063752\n",
            "rotation error test:  12.18355731544543\n",
            "translation error test:  0.5374976931775427\n",
            "--- 11.664225816726685 seconds ---\n",
            "Epoch: [0/4], Batch: 119, Loss: 0.2284625731063752\n",
            "Processing file: lamp_0042.txt\n",
            "feature extraction time:  5.726062297821045\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3584, 8117,  474,  ..., 3710, 3798, 9543], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09199976921081543\n",
            "Loss: 0.23000149631740338\n",
            "rotation error test:  21.602179017881955\n",
            "translation error test:  0.8642919253348614\n",
            "--- 11.62506914138794 seconds ---\n",
            "Processing file: lamp_0043.txt\n",
            "feature extraction time:  5.7310380935668945\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2077, 4874, 9942,  ..., 1146,  649, 6933], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10599970817565918\n",
            "Loss: 0.23173785870249752\n",
            "rotation error test:  24.09397121233598\n",
            "translation error test:  0.7555357069239845\n",
            "--- 11.65203309059143 seconds ---\n",
            "Processing file: lamp_0044.txt\n",
            "feature extraction time:  5.710009574890137\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999151229858398\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3197, 2357, 9786,  ..., 5473, 8035, 5433], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1068580150604248\n",
            "Loss: 0.358416140747678\n",
            "rotation error test:  130.7239132099454\n",
            "translation error test:  1.2105195016538433\n",
            "--- 11.606874227523804 seconds ---\n",
            "Processing file: lamp_0045.txt\n",
            "feature extraction time:  5.6993677616119385\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4442, 2288, 6447,  ..., 7658, 1950, 5665], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09300041198730469\n",
            "Loss: 0.2162663926580693\n",
            "rotation error test:  18.564037967072668\n",
            "translation error test:  0.6947408117335748\n",
            "--- 11.586374044418335 seconds ---\n",
            "Processing file: lamp_0046.txt\n",
            "feature extraction time:  5.731048107147217\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014003515243530273\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.00099945068359375\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6256, 3439, 9438,  ..., 4224, 4994, 4143], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11500000953674316\n",
            "Loss: 0.375150455012194\n",
            "rotation error test:  27.312064428412885\n",
            "translation error test:  0.8106898150253641\n",
            "--- 11.649471044540405 seconds ---\n",
            "Epoch: [0/4], Batch: 124, Loss: 0.375150455012194\n",
            "Processing file: lamp_0047.txt\n",
            "feature extraction time:  5.791006565093994\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 899, 3309, 4160,  ..., 1969, 5116, 6655], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12800049781799316\n",
            "Loss: 0.13778031246073838\n",
            "rotation error test:  23.831485307172592\n",
            "translation error test:  0.32642820202655737\n",
            "--- 11.750251770019531 seconds ---\n",
            "Processing file: lamp_0048.txt\n",
            "feature extraction time:  5.740009307861328\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8295, 9932,  890,  ..., 9562, 6116, 4761], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900139808654785\n",
            "Loss: 0.1595014612190239\n",
            "rotation error test:  18.88166847498881\n",
            "translation error test:  0.3259367875944086\n",
            "--- 11.667173624038696 seconds ---\n",
            "Processing file: lamp_0049.txt\n",
            "feature extraction time:  5.717005729675293\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014002799987792969\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8794,  991, 6861,  ..., 3219,  941, 2906], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09200048446655273\n",
            "Loss: 0.180775377176773\n",
            "rotation error test:  38.76628348084237\n",
            "translation error test:  0.6069359951622838\n",
            "--- 11.619018793106079 seconds ---\n",
            "Processing file: lamp_0050.txt\n",
            "feature extraction time:  5.725006103515625\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   2, 4790, 6199,  ..., 7098, 8174, 3963], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09399962425231934\n",
            "Loss: 0.3169671461507534\n",
            "rotation error test:  187.14123323614064\n",
            "translation error test:  0.7912556793484409\n",
            "--- 11.6220121383667 seconds ---\n",
            "Processing file: lamp_0051.txt\n",
            "feature extraction time:  5.713005781173706\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2734, 1096, 9996,  ..., 3243, 6717, 3612], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09500002861022949\n",
            "Loss: 0.18105152099563834\n",
            "rotation error test:  34.0187542420584\n",
            "translation error test:  0.5501518963906871\n",
            "--- 11.60501217842102 seconds ---\n",
            "Epoch: [0/4], Batch: 129, Loss: 0.18105152099563834\n",
            "Processing file: lamp_0052.txt\n",
            "feature extraction time:  5.722005844116211\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7308, 5038,   48,  ..., 6382, 9305, 6847], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09900069236755371\n",
            "Loss: 0.15154788474338243\n",
            "rotation error test:  14.135369774566616\n",
            "translation error test:  0.4036759673772326\n",
            "--- 11.623012065887451 seconds ---\n",
            "Processing file: lamp_0053.txt\n",
            "feature extraction time:  5.7010064125061035\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1822, 7610,  834,  ..., 3415, 1027, 5997], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09800052642822266\n",
            "Loss: 0.33754095946111884\n",
            "rotation error test:  21.586452721643038\n",
            "translation error test:  1.1219613566101283\n",
            "--- 11.572012901306152 seconds ---\n",
            "Processing file: lamp_0054.txt\n",
            "feature extraction time:  5.71800684928894\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1321, 6419, 9276,  ..., 2509,  967, 4042], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13400030136108398\n",
            "Loss: 0.2913571729518318\n",
            "rotation error test:  352.72686345006974\n",
            "translation error test:  1.0418426104499308\n",
            "--- 11.663012266159058 seconds ---\n",
            "Processing file: lamp_0055.txt\n",
            "feature extraction time:  5.714005947113037\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9999, 3283,  115,  ...,  270, 9976, 4387], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09800434112548828\n",
            "Loss: 0.35116242596660613\n",
            "rotation error test:  71.27738448241288\n",
            "translation error test:  1.1912284233473236\n",
            "--- 11.610883712768555 seconds ---\n",
            "Processing file: lamp_0056.txt\n",
            "feature extraction time:  5.709006309509277\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6373, 3619, 4577,  ..., 4854, 8370,  627], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11800098419189453\n",
            "Loss: 0.1589222028171386\n",
            "rotation error test:  27.40647130378634\n",
            "translation error test:  0.28523070077112556\n",
            "--- 11.639012575149536 seconds ---\n",
            "Epoch: [0/4], Batch: 134, Loss: 0.1589222028171386\n",
            "Processing file: lamp_0057.txt\n",
            "feature extraction time:  5.694005012512207\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   2, 4818, 3572,  ..., 1684,  285, 5431], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10100030899047852\n",
            "Loss: 0.06434962283562591\n",
            "rotation error test:  30.60400248713409\n",
            "translation error test:  0.16267774711123528\n",
            "--- 11.585011005401611 seconds ---\n",
            "Processing file: lamp_0058.txt\n",
            "feature extraction time:  5.703005790710449\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 187, 6387, 3853,  ..., 4010, 9680, 8843], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10600042343139648\n",
            "Loss: 0.2317877459690405\n",
            "rotation error test:  334.6764344852983\n",
            "translation error test:  0.5122144352443644\n",
            "--- 11.613010883331299 seconds ---\n",
            "Processing file: lamp_0059.txt\n",
            "feature extraction time:  5.687005043029785\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4705, 2350, 6940,  ...,  668, 6259, 1373], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08499956130981445\n",
            "Loss: 0.4808746148353624\n",
            "rotation error test:  35.1460422840879\n",
            "translation error test:  1.1564877182625828\n",
            "--- 11.56701111793518 seconds ---\n",
            "Processing file: lamp_0060.txt\n",
            "feature extraction time:  5.7080078125\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 174, 3909, 6873,  ..., 9354, 2712, 1186], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600067138671875\n",
            "Loss: 0.10947516807175825\n",
            "rotation error test:  90.25061930670054\n",
            "translation error test:  0.298263894904039\n",
            "--- 11.582058668136597 seconds ---\n",
            "Processing file: lamp_0061.txt\n",
            "feature extraction time:  5.719130754470825\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3031, 3401, 3712,  ..., 8149, 5893, 4232], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10744404792785645\n",
            "Loss: 0.2524209622713056\n",
            "rotation error test:  64.55878033819882\n",
            "translation error test:  0.819943271456514\n",
            "--- 11.614792823791504 seconds ---\n",
            "Epoch: [0/4], Batch: 139, Loss: 0.2524209622713056\n",
            "Processing file: lamp_0062.txt\n",
            "feature extraction time:  5.7261269092559814\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  23, 4657, 9692,  ..., 7787, 5245, 1445], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12600064277648926\n",
            "Loss: 0.22803812322097083\n",
            "rotation error test:  7.760633562186541\n",
            "translation error test:  0.7527991034162337\n",
            "--- 11.656132698059082 seconds ---\n",
            "Processing file: lamp_0063.txt\n",
            "feature extraction time:  5.7180562019348145\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8571, 4078,  722,  ..., 7652, 9237, 5692], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08947324752807617\n",
            "Loss: 0.412143999227188\n",
            "rotation error test:  28.518627445996405\n",
            "translation error test:  0.7597816966375612\n",
            "--- 11.610538005828857 seconds ---\n",
            "Processing file: lamp_0064.txt\n",
            "feature extraction time:  5.696087837219238\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9048, 6146,   46,  ...,  332, 5588, 9922], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12899994850158691\n",
            "Loss: 0.23516861014472334\n",
            "rotation error test:  30.44365452050748\n",
            "translation error test:  0.6197732201074906\n",
            "--- 11.599170684814453 seconds ---\n",
            "Processing file: lamp_0065.txt\n",
            "feature extraction time:  5.746525287628174\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9385,  485, 1903,  ..., 3250,  203, 8725], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1120002269744873\n",
            "Loss: 0.23232210071533488\n",
            "rotation error test:  28.813538748930867\n",
            "translation error test:  0.7162938540451482\n",
            "--- 11.672531127929688 seconds ---\n",
            "Processing file: lamp_0066.txt\n",
            "feature extraction time:  5.69812798500061\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8581, 2029, 4949,  ..., 2332, 4591, 5963], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12100076675415039\n",
            "Loss: 0.21917505766766537\n",
            "rotation error test:  45.28311380293002\n",
            "translation error test:  0.7017047197301658\n",
            "--- 11.649357080459595 seconds ---\n",
            "Epoch: [0/4], Batch: 144, Loss: 0.21917505766766537\n",
            "Processing file: lamp_0067.txt\n",
            "feature extraction time:  5.714064598083496\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2579, 4923, 3907,  ...,  430, 8766,  801], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11812257766723633\n",
            "Loss: 0.2868117376666387\n",
            "rotation error test:  30.359522913384435\n",
            "translation error test:  0.5287538880942453\n",
            "--- 11.624141931533813 seconds ---\n",
            "Processing file: lamp_0068.txt\n",
            "feature extraction time:  5.717132806777954\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   5, 5491, 9095,  ..., 9872, 5542, 3388], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.07166337966918945\n",
            "Loss: 0.09766437398684306\n",
            "rotation error test:  75.04214662944555\n",
            "translation error test:  0.29458748257768047\n",
            "--- 11.607799053192139 seconds ---\n",
            "Processing file: lamp_0069.txt\n",
            "feature extraction time:  5.719144821166992\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014002799987792969\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 141, 5367, 9540,  ..., 9489, 6245,  386], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10199952125549316\n",
            "Loss: 0.11716771141703661\n",
            "rotation error test:  23.180483728163534\n",
            "translation error test:  0.24172353002190158\n",
            "--- 11.640330791473389 seconds ---\n",
            "Processing file: lamp_0070.txt\n",
            "feature extraction time:  5.741004943847656\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9707, 1918, 4993,  ...,  334, 3268, 6150], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0989999771118164\n",
            "Loss: 0.18374380594471776\n",
            "rotation error test:  253.1119685707474\n",
            "translation error test:  0.2459668339682114\n",
            "--- 11.670010805130005 seconds ---\n",
            "Processing file: lamp_0071.txt\n",
            "feature extraction time:  5.716004848480225\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2900, 7435,  981,  ..., 4287,  824,  964], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400032997131348\n",
            "Loss: 0.41307477328942466\n",
            "rotation error test:  69.40075180720919\n",
            "translation error test:  0.9480637347237998\n",
            "--- 11.629010677337646 seconds ---\n",
            "Epoch: [0/4], Batch: 149, Loss: 0.41307477328942466\n",
            "Processing file: lamp_0072.txt\n",
            "feature extraction time:  5.708005666732788\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9784, 6250, 2934,  ..., 2630, 8612, 5963], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1149137020111084\n",
            "Loss: 0.08318731502075602\n",
            "rotation error test:  25.99350809182706\n",
            "translation error test:  0.16115779155346815\n",
            "--- 11.632924795150757 seconds ---\n",
            "Processing file: lamp_0073.txt\n",
            "feature extraction time:  5.7410054206848145\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7711, 4585,  154,  ..., 8060,  986, 2643], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1080470085144043\n",
            "Loss: 0.21674581235151086\n",
            "rotation error test:  11.572526398854862\n",
            "translation error test:  0.5642598034998262\n",
            "--- 11.666455745697021 seconds ---\n",
            "Processing file: lamp_0074.txt\n",
            "feature extraction time:  5.736005067825317\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2463, 2201,  582,  ..., 9896, 8458, 6462], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11900043487548828\n",
            "Loss: 0.2458314818478138\n",
            "rotation error test:  340.58333716382936\n",
            "translation error test:  0.3184026131793979\n",
            "--- 11.673609495162964 seconds ---\n",
            "Processing file: lamp_0075.txt\n",
            "feature extraction time:  5.724005937576294\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999462127685547\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2686, 9385,  414,  ..., 1758, 6894, 1681], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11600017547607422\n",
            "Loss: 0.2177429999877598\n",
            "rotation error test:  23.830226886936433\n",
            "translation error test:  0.6480310256406917\n",
            "--- 11.65001130104065 seconds ---\n",
            "Processing file: lamp_0076.txt\n",
            "feature extraction time:  5.74500584602356\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  30, 3235, 5574,  ..., 7009, 1974, 8190], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12900018692016602\n",
            "Loss: 0.28188393403638046\n",
            "rotation error test:  88.85207212172725\n",
            "translation error test:  0.415627945934856\n",
            "--- 11.685011386871338 seconds ---\n",
            "Epoch: [0/4], Batch: 154, Loss: 0.28188393403638046\n",
            "Processing file: lamp_0077.txt\n",
            "feature extraction time:  5.735004663467407\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.016000032424926758\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 492, 9421, 2184,  ..., 7597, 4624, 6953], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11400032043457031\n",
            "Loss: 0.3704217598167029\n",
            "rotation error test:  82.12892891345535\n",
            "translation error test:  0.7430741109709934\n",
            "--- 11.660011291503906 seconds ---\n",
            "Processing file: lamp_0078.txt\n",
            "feature extraction time:  5.716005325317383\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7137, 2997, 5272,  ..., 1922, 2481,   84], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1120004653930664\n",
            "Loss: 0.11495547731623987\n",
            "rotation error test:  22.425275233706866\n",
            "translation error test:  0.2703686185427703\n",
            "--- 11.640045642852783 seconds ---\n",
            "Processing file: lamp_0079.txt\n",
            "feature extraction time:  5.73304557800293\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999223709106445\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2371,    1, 5038,  ..., 3024, 1858, 6702], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11399984359741211\n",
            "Loss: 0.3945769834359416\n",
            "rotation error test:  319.7697166696322\n",
            "translation error test:  0.9323463670302814\n",
            "--- 11.655901432037354 seconds ---\n",
            "Processing file: lamp_0080.txt\n",
            "feature extraction time:  5.7400054931640625\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3716, 5340, 7359,  ..., 9992, 7301, 9815], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11707091331481934\n",
            "Loss: 0.15725005690623395\n",
            "rotation error test:  28.43574229549483\n",
            "translation error test:  0.4968192463037114\n",
            "--- 11.689081907272339 seconds ---\n",
            "Processing file: lamp_0081.txt\n",
            "feature extraction time:  5.7140052318573\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3880, 9628,  574,  ..., 3363, 7230, 3030], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09549188613891602\n",
            "Loss: 0.44884303146694604\n",
            "rotation error test:  27.602419625496708\n",
            "translation error test:  1.246455173614297\n",
            "--- 11.632574558258057 seconds ---\n",
            "Epoch: [0/4], Batch: 159, Loss: 0.44884303146694604\n",
            "Processing file: lamp_0082.txt\n",
            "feature extraction time:  5.73700475692749\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9337, 4995, 3767,  ..., 8426, 1113, 4434], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12999963760375977\n",
            "Loss: 0.25531723086518693\n",
            "rotation error test:  17.8328019318558\n",
            "translation error test:  0.7529785240759085\n",
            "--- 11.711077690124512 seconds ---\n",
            "Processing file: lamp_0083.txt\n",
            "feature extraction time:  5.736369609832764\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9712,    1, 1678,  ..., 6657, 4822, 9849], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08705401420593262\n",
            "Loss: 0.4798774645241527\n",
            "rotation error test:  187.9028984153602\n",
            "translation error test:  0.9136402705662745\n",
            "--- 11.642430543899536 seconds ---\n",
            "Processing file: lamp_0084.txt\n",
            "feature extraction time:  5.689007520675659\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000581741333008\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1328, 1796, 3053,  ...,    7, 7204, 5638], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10099983215332031\n",
            "Loss: 0.3919104008697183\n",
            "rotation error test:  356.27100365517373\n",
            "translation error test:  1.2460132973707807\n",
            "--- 11.578012466430664 seconds ---\n",
            "Processing file: lamp_0085.txt\n",
            "feature extraction time:  5.695005178451538\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 842, 7168, 6187,  ..., 3511, 1737, 9565], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11100053787231445\n",
            "Loss: 0.13248178930769142\n",
            "rotation error test:  27.62784133043164\n",
            "translation error test:  0.28307622678915284\n",
            "--- 11.603010416030884 seconds ---\n",
            "Processing file: lamp_0086.txt\n",
            "feature extraction time:  5.68400502204895\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 109, 8058, 8084,  ..., 1706, 1122, 5039], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12600064277648926\n",
            "Loss: 0.27873772754254744\n",
            "rotation error test:  310.0023059996428\n",
            "translation error test:  0.7785921414288383\n",
            "--- 11.602282524108887 seconds ---\n",
            "Epoch: [0/4], Batch: 164, Loss: 0.27873772754254744\n",
            "Processing file: lamp_0087.txt\n",
            "feature extraction time:  5.708080530166626\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010006427764892578\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3880, 9912, 2568,  ..., 1110, 7787, 6504], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11800026893615723\n",
            "Loss: 0.3432191696027272\n",
            "rotation error test:  30.968936317207092\n",
            "translation error test:  1.0719844318358984\n",
            "--- 11.592085599899292 seconds ---\n",
            "Processing file: lamp_0088.txt\n",
            "feature extraction time:  5.717073202133179\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9714, 3958,   47,  ..., 1727, 4893, 4660], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11379456520080566\n",
            "Loss: 0.33198837416385407\n",
            "rotation error test:  366.4495820575952\n",
            "translation error test:  0.8136738523477006\n",
            "--- 11.605377912521362 seconds ---\n",
            "Processing file: lamp_0089.txt\n",
            "feature extraction time:  5.700974941253662\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8669, 6359,    5,  ..., 5894, 6197, 3264], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200023651123047\n",
            "Loss: 0.16417905896944052\n",
            "rotation error test:  12.52352544919838\n",
            "translation error test:  0.6075545322749648\n",
            "--- 11.584980249404907 seconds ---\n",
            "Processing file: lamp_0090.txt\n",
            "feature extraction time:  5.713178873062134\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013001680374145508\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4359, 7130, 5213,  ..., 7974, 1982, 5093], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09200048446655273\n",
            "Loss: 0.3975675527083588\n",
            "rotation error test:  177.80798413966815\n",
            "translation error test:  1.0836166439858188\n",
            "--- 11.624577283859253 seconds ---\n",
            "Processing file: lamp_0091.txt\n",
            "feature extraction time:  5.712005138397217\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7994, 2290,    8,  ..., 2759, 7638, 2100], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12400007247924805\n",
            "Loss: 0.24621111823786962\n",
            "rotation error test:  302.86191960617015\n",
            "translation error test:  0.3303340473169406\n",
            "--- 11.658010482788086 seconds ---\n",
            "Epoch: [0/4], Batch: 169, Loss: 0.24621111823786962\n",
            "Processing file: lamp_0092.txt\n",
            "feature extraction time:  5.7310051918029785\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010004043579101562\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7112, 4048, 1517,  ..., 2554, 5402, 7009], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1230001449584961\n",
            "Loss: 0.26567009662454677\n",
            "rotation error test:  310.41601808245315\n",
            "translation error test:  0.4613938757955687\n",
            "--- 11.669079542160034 seconds ---\n",
            "Processing file: lamp_0093.txt\n",
            "feature extraction time:  5.7200047969818115\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5745, 7448, 7524,  ..., 3120, 3819, 1859], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1269998550415039\n",
            "Loss: 0.3600998621097715\n",
            "rotation error test:  350.6931282034271\n",
            "translation error test:  0.9614938127026132\n",
            "--- 11.648010015487671 seconds ---\n",
            "Processing file: lamp_0094.txt\n",
            "feature extraction time:  5.716005086898804\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7067, 5288, 1717,  ..., 1559, 9450, 6263], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12099933624267578\n",
            "Loss: 0.22264268849475044\n",
            "rotation error test:  30.95983225245404\n",
            "translation error test:  0.5962238106043255\n",
            "--- 11.653010368347168 seconds ---\n",
            "Processing file: lamp_0095.txt\n",
            "feature extraction time:  5.698004722595215\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6426, 3609, 2142,  ..., 8997, 3591, 8819], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10587310791015625\n",
            "Loss: 0.26465346403412693\n",
            "rotation error test:  29.680850231008407\n",
            "translation error test:  0.8467329953445232\n",
            "--- 11.606972932815552 seconds ---\n",
            "Processing file: lamp_0096.txt\n",
            "feature extraction time:  5.728040933609009\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014992475509643555\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5384, 3380,  420,  ...,  822, 9287, 8983], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1099998950958252\n",
            "Loss: 0.295992275018624\n",
            "rotation error test:  83.04712040708517\n",
            "translation error test:  1.0143358151851856\n",
            "--- 11.665082693099976 seconds ---\n",
            "Epoch: [0/4], Batch: 174, Loss: 0.295992275018624\n",
            "Processing file: lamp_0097.txt\n",
            "feature extraction time:  5.72500467300415\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5697, 3380, 1825,  ...,  219, 4022, 3204], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11800026893615723\n",
            "Loss: 0.3179671167905807\n",
            "rotation error test:  287.2140547821413\n",
            "translation error test:  0.8711575508386297\n",
            "--- 11.66001033782959 seconds ---\n",
            "Processing file: lamp_0098.txt\n",
            "feature extraction time:  5.7330052852630615\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9761, 6274, 9689,  ..., 1433, 7501, 1141], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11699938774108887\n",
            "Loss: 0.3191212648075115\n",
            "rotation error test:  31.338694954290386\n",
            "translation error test:  0.8292092261486507\n",
            "--- 11.674010753631592 seconds ---\n",
            "Processing file: lamp_0099.txt\n",
            "feature extraction time:  5.732003450393677\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2384,    2, 4244,  ..., 9201, 4742, 5365], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10133719444274902\n",
            "Loss: 0.3092663473395353\n",
            "rotation error test:  31.339679612820365\n",
            "translation error test:  1.0589502259315682\n",
            "--- 11.634640455245972 seconds ---\n",
            "Processing file: lamp_0100.txt\n",
            "feature extraction time:  5.708005428314209\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01500082015991211\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 446, 8142, 2123,  ..., 4797, 5931,   90], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11432623863220215\n",
            "Loss: 0.2594603170433449\n",
            "rotation error test:  26.43806514458852\n",
            "translation error test:  0.8887187233212773\n",
            "--- 11.633373498916626 seconds ---\n",
            "Processing file: lamp_0101.txt\n",
            "feature extraction time:  5.7200071811676025\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3016, 9817, 8454,  ...,   41, 8954, 5882], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09400105476379395\n",
            "Loss: 0.35846616330235376\n",
            "rotation error test:  172.2009584580364\n",
            "translation error test:  0.8397574375489569\n",
            "--- 11.632075309753418 seconds ---\n",
            "Epoch: [0/4], Batch: 179, Loss: 0.35846616330235376\n",
            "Processing file: lamp_0102.txt\n",
            "feature extraction time:  5.728090047836304\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5664, 4214, 9166,  ..., 2791, 9854,  907], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12200379371643066\n",
            "Loss: 0.1293026983761153\n",
            "rotation error test:  9.998064646265046\n",
            "translation error test:  0.4466743595577463\n",
            "--- 11.681256532669067 seconds ---\n",
            "Processing file: lamp_0103.txt\n",
            "feature extraction time:  5.739197492599487\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2499, 5456, 7081,  ..., 6751, 2064, 2312], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09400320053100586\n",
            "Loss: 0.3177888600608093\n",
            "rotation error test:  335.6201918286606\n",
            "translation error test:  0.6440756874445058\n",
            "--- 11.656419515609741 seconds ---\n",
            "Processing file: lamp_0104.txt\n",
            "feature extraction time:  5.709253787994385\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   5, 7855, 8979,  ..., 7528, 8625, 5502], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12600374221801758\n",
            "Loss: 0.24396406709167226\n",
            "rotation error test:  45.438246440419086\n",
            "translation error test:  0.7031599454438956\n",
            "--- 11.624380111694336 seconds ---\n",
            "Processing file: lamp_0105.txt\n",
            "feature extraction time:  5.704159259796143\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8075, 7194,  108,  ..., 9813, 1579, 6883], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1320044994354248\n",
            "Loss: 0.2083497866544992\n",
            "rotation error test:  341.4373205933309\n",
            "translation error test:  0.7424349192138998\n",
            "--- 11.645325660705566 seconds ---\n",
            "Processing file: lamp_0106.txt\n",
            "feature extraction time:  5.710203647613525\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 121, 1884, 4086,  ..., 8984, 4644, 4989], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09900331497192383\n",
            "Loss: 0.3661389521346153\n",
            "rotation error test:  29.201967005083194\n",
            "translation error test:  0.8800761794111744\n",
            "--- 11.594367980957031 seconds ---\n",
            "Epoch: [0/4], Batch: 184, Loss: 0.3661389521346153\n",
            "Processing file: lamp_0107.txt\n",
            "feature extraction time:  5.70215916633606\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4842, 9833, 1156,  ..., 4140, 7822, 8145], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12100338935852051\n",
            "Loss: 0.2921042737154921\n",
            "rotation error test:  122.04667501600183\n",
            "translation error test:  0.6543488040687829\n",
            "--- 11.62332534790039 seconds ---\n",
            "Processing file: lamp_0108.txt\n",
            "feature extraction time:  5.704159259796143\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01300048828125\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4682, 9644, 6295,  ..., 4264, 1726, 8947], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300350189208984\n",
            "Loss: 0.31760906061212096\n",
            "rotation error test:  105.49275847049502\n",
            "translation error test:  0.7153686262288217\n",
            "--- 11.605324745178223 seconds ---\n",
            "Processing file: lamp_0109.txt\n",
            "feature extraction time:  5.697159290313721\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3622,    1, 7159,  ..., 8872, 3275, 7592], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08900260925292969\n",
            "Loss: 0.3840349028799166\n",
            "rotation error test:  22.00118925571047\n",
            "translation error test:  0.7700461309337409\n",
            "--- 11.600324869155884 seconds ---\n",
            "Processing file: lamp_0110.txt\n",
            "feature extraction time:  5.710159540176392\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000581741333008\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1538, 3639, 7244,  ..., 6682, 7987, 3705], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10049796104431152\n",
            "Loss: 0.264411055341209\n",
            "rotation error test:  56.15473100535724\n",
            "translation error test:  0.904103663817892\n",
            "--- 11.617940902709961 seconds ---\n",
            "Processing file: lamp_0111.txt\n",
            "feature extraction time:  5.7274394035339355\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4480, 1667, 6624,  ..., 6571, 8350, 4052], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12700366973876953\n",
            "Loss: 0.2445431045356767\n",
            "rotation error test:  47.2812241356464\n",
            "translation error test:  0.6649623998360372\n",
            "--- 11.693711280822754 seconds ---\n",
            "Epoch: [0/4], Batch: 189, Loss: 0.2445431045356767\n",
            "Processing file: lamp_0112.txt\n",
            "feature extraction time:  5.716159820556641\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  16, 7135,  179,  ..., 3326, 8010, 4215], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10800361633300781\n",
            "Loss: 0.39653115375825587\n",
            "rotation error test:  277.37226607539577\n",
            "translation error test:  1.1420229839114118\n",
            "--- 11.663326025009155 seconds ---\n",
            "Processing file: lamp_0113.txt\n",
            "feature extraction time:  5.7432146072387695\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014997720718383789\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2513, 9564, 6331,  ..., 2595, 3428, 5554], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.14400434494018555\n",
            "Loss: 0.41675725516800727\n",
            "rotation error test:  79.09382103126647\n",
            "translation error test:  1.1096434729491433\n",
            "--- 11.729328155517578 seconds ---\n",
            "Processing file: lamp_0114.txt\n",
            "feature extraction time:  5.7401604652404785\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1329,  382, 7795,  ..., 7814, 5102, 1768], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10000300407409668\n",
            "Loss: 0.18287870601991332\n",
            "rotation error test:  15.827147589479118\n",
            "translation error test:  0.5350931615315717\n",
            "--- 11.650362968444824 seconds ---\n",
            "Processing file: lamp_0115.txt\n",
            "feature extraction time:  5.7251598834991455\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3801,   22, 8327,  ..., 5768, 7908, 5595], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10700297355651855\n",
            "Loss: 0.2412239470461937\n",
            "rotation error test:  24.76921309809542\n",
            "translation error test:  0.6377805376481142\n",
            "--- 11.642325639724731 seconds ---\n",
            "loss epoch [0.18842597458872895, 0.30353287532512857, 0.3071642538261567, 0.1007138676783142, 0.4098139925059722, 0.17635016609439536, 0.32619128345219517, 0.13402778684177766, 0.19328606572331195, 0.512086011003053, 0.628613982897563, 0.3250189050347312, 0.5029722073684748, 0.3190508171164173, 0.41290616771176747, 0.20183499587403392, 0.15714429164954702, 0.28985778188580585, 0.23293507409375208, 0.23612757814911733, 0.27100528239079247, 0.2807057519168912, 0.37390594575514924, 0.3170379947355905, 0.3401612616243826, 0.36932751798954877, 0.39712534030242874, 0.22820267221718407, 0.38710506378658055, 0.2723785447275825, 0.25395086474315187, 0.5165376362720004, 0.2987519996776888, 0.2854521092108915, 0.2174148619782311, 0.3896751859356479, 0.1534942527909382, 0.25854555995097855, 0.10271788734748187, 0.19906363983608427, 0.3305783455092762, 0.31780045784298333, 0.37227809158660463, 0.30949752856847523, 0.33231742821050075, 0.19896999980264155, 0.11091606423217637, 0.22438118726935044, 0.3686862828130308, 0.4657233993177592, 0.2344266340624919, 0.3044095046715745, 0.3271374349983623, 0.2957096499935561, 0.31031820295114526, 0.3064615903957366, 0.21697612751217923, 0.29203791265602635, 0.2451695564536407, 0.2321465390463794, 0.1293013902979479, 0.35628311928546935, 0.19306912008443294, 0.21952767833923734, 0.25005237224239063, 0.1549995590811434, 0.2812398611862624, 0.3467525336761772, 0.09362232391639326, 0.29504875079168613, 0.2243747386300169, 0.2512979901349367, 0.34253156551044306, 0.32466875789509514, 0.27695869061181216, 0.3004290587556945, 0.15103398781792157, 0.14135821045356323, 0.2857117535452416, 0.1472617153443776, 0.21763485333723173, 0.2961286563384274, 0.06733068709839113, 0.2860948688617599, 0.2873542056377172, 0.18325812585540352, 0.1337486465919888, 0.2532516030325044, 0.27523517992541907, 0.1834817522610716, 0.16944982926490484, 0.38188112109466016, 0.37422728747711786, 0.3086080394166544, 0.2486760254656203, 0.3462228826681738, 0.21246312253999064, 0.17121140246248606, 0.16315881491404655, 0.187891438834971, 0.23416769321893793, 0.27386905993234034, 0.1382677390593591, 0.3866882899092389, 0.25666342369685935, 0.1786837458368724, 0.24370435799795565, 0.2558868833536459, 0.3850414612451659, 0.2766373253748055, 0.17964438524055507, 0.2527975097277948, 0.2432629765227694, 0.2980976301568832, 0.08354482011666053, 0.3085893283696036, 0.35205810911646673, 0.3329675374642668, 0.22725739165290507, 0.2284625731063752, 0.23000149631740338, 0.23173785870249752, 0.358416140747678, 0.2162663926580693, 0.375150455012194, 0.13778031246073838, 0.1595014612190239, 0.180775377176773, 0.3169671461507534, 0.18105152099563834, 0.15154788474338243, 0.33754095946111884, 0.2913571729518318, 0.35116242596660613, 0.1589222028171386, 0.06434962283562591, 0.2317877459690405, 0.4808746148353624, 0.10947516807175825, 0.2524209622713056, 0.22803812322097083, 0.412143999227188, 0.23516861014472334, 0.23232210071533488, 0.21917505766766537, 0.2868117376666387, 0.09766437398684306, 0.11716771141703661, 0.18374380594471776, 0.41307477328942466, 0.08318731502075602, 0.21674581235151086, 0.2458314818478138, 0.2177429999877598, 0.28188393403638046, 0.3704217598167029, 0.11495547731623987, 0.3945769834359416, 0.15725005690623395, 0.44884303146694604, 0.25531723086518693, 0.4798774645241527, 0.3919104008697183, 0.13248178930769142, 0.27873772754254744, 0.3432191696027272, 0.33198837416385407, 0.16417905896944052, 0.3975675527083588, 0.24621111823786962, 0.26567009662454677, 0.3600998621097715, 0.22264268849475044, 0.26465346403412693, 0.295992275018624, 0.3179671167905807, 0.3191212648075115, 0.3092663473395353, 0.2594603170433449, 0.35846616330235376, 0.1293026983761153, 0.3177888600608093, 0.24396406709167226, 0.2083497866544992, 0.3661389521346153, 0.2921042737154921, 0.31760906061212096, 0.3840349028799166, 0.264411055341209, 0.2445431045356767, 0.39653115375825587, 0.41675725516800727, 0.18287870601991332, 0.2412239470461937]\n",
            "epoch #1\n",
            "Processing file: cup_0001.txt\n",
            "feature extraction time:  5.761160612106323\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4303, 5889, 5671,  ..., 2062, 8335, 8424], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09900307655334473\n",
            "Loss: 0.45527400474711477\n",
            "rotation error test:  45.09613584914412\n",
            "translation error test:  1.0136588705913503\n",
            "--- 11.664325475692749 seconds ---\n",
            "Processing file: cup_0002.txt\n",
            "feature extraction time:  5.721317768096924\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015001058578491211\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 472, 4016, 8889,  ..., 9087,  481, 8703], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10934114456176758\n",
            "Loss: 0.16102683546538485\n",
            "rotation error test:  19.33711626823266\n",
            "translation error test:  0.5595512687818458\n",
            "--- 11.623786926269531 seconds ---\n",
            "Processing file: cup_0003.txt\n",
            "feature extraction time:  5.68515944480896\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7696, 2464,  342,  ..., 3595, 3977, 3120], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10100317001342773\n",
            "Loss: 0.15882663663940244\n",
            "rotation error test:  4.374516926617972\n",
            "translation error test:  0.49196209285334863\n",
            "--- 11.599657773971558 seconds ---\n",
            "Processing file: cup_0004.txt\n",
            "feature extraction time:  5.744159936904907\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000654220581055\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2585, 7706, 9782,  ..., 8041,  885, 8887], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09811663627624512\n",
            "Loss: 0.25849248702655886\n",
            "rotation error test:  50.21056919845389\n",
            "translation error test:  0.5739522386299293\n",
            "--- 11.648499011993408 seconds ---\n",
            "Processing file: cup_0005.txt\n",
            "feature extraction time:  5.716216087341309\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01600050926208496\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1722, 9848, 3978,  ...,  431, 8794, 7054], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09051918983459473\n",
            "Loss: 0.34591763087816435\n",
            "rotation error test:  90.67084386112228\n",
            "translation error test:  0.984085302264822\n",
            "--- 11.633040189743042 seconds ---\n",
            "Epoch: [1/4], Batch: 4, Loss: 0.34591763087816435\n",
            "Processing file: cup_0006.txt\n",
            "feature extraction time:  5.7043445110321045\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2888, 3205,  217,  ..., 6743, 8706, 5356], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10266542434692383\n",
            "Loss: 0.3429389358279148\n",
            "rotation error test:  7.1093274103329\n",
            "translation error test:  0.7410708109729712\n",
            "--- 11.646199226379395 seconds ---\n",
            "Processing file: cup_0007.txt\n",
            "feature extraction time:  5.743203401565552\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9960, 7253, 7038,  ..., 8414, 6075,  210], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200357437133789\n",
            "Loss: 0.1982837523109891\n",
            "rotation error test:  26.449702881771696\n",
            "translation error test:  0.7120825376626866\n",
            "--- 11.692498207092285 seconds ---\n",
            "Processing file: cup_0008.txt\n",
            "feature extraction time:  5.7712790966033936\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2649, 6070,  669,  ..., 7172, 8391, 7189], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09000277519226074\n",
            "Loss: 0.209079750931471\n",
            "rotation error test:  15.542556044310379\n",
            "translation error test:  0.6321885441834473\n",
            "--- 11.73444128036499 seconds ---\n",
            "Processing file: cup_0009.txt\n",
            "feature extraction time:  5.766192197799683\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5987, 2306,  466,  ..., 9875, 5731, 5321], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1430046558380127\n",
            "Loss: 0.4235630480723163\n",
            "rotation error test:  344.7745133388423\n",
            "translation error test:  1.3837425601561903\n",
            "--- 11.750359773635864 seconds ---\n",
            "Processing file: cup_0010.txt\n",
            "feature extraction time:  5.741127014160156\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000654220581055\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1222, 5996, 3353,  ..., 3663, 5053, 5930], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1127784252166748\n",
            "Loss: 0.28412886561578027\n",
            "rotation error test:  14.671982950758581\n",
            "translation error test:  0.8379520817346802\n",
            "--- 11.686108112335205 seconds ---\n",
            "Epoch: [1/4], Batch: 9, Loss: 0.28412886561578027\n",
            "Processing file: cup_0011.txt\n",
            "feature extraction time:  5.7688889503479\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000581741333008\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2013, 3416, 9433,  ..., 1183, 5428,  699], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1060025691986084\n",
            "Loss: 0.2129886666992797\n",
            "rotation error test:  255.94972043640502\n",
            "translation error test:  0.41493832229400945\n",
            "--- 11.701194524765015 seconds ---\n",
            "Processing file: cup_0012.txt\n",
            "feature extraction time:  5.745289325714111\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7520,   39, 1545,  ..., 8441, 6676, 5817], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400199890136719\n",
            "Loss: 0.21434566620136392\n",
            "rotation error test:  35.33679067027381\n",
            "translation error test:  0.626899790790315\n",
            "--- 11.692643165588379 seconds ---\n",
            "Processing file: cup_0013.txt\n",
            "feature extraction time:  5.736114501953125\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1183, 3681, 7807,  ...,  728, 7328, 5623], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600090980529785\n",
            "Loss: 0.27994061746532445\n",
            "rotation error test:  11.989540270810679\n",
            "translation error test:  0.6400515257320517\n",
            "--- 11.665233373641968 seconds ---\n",
            "Processing file: cup_0014.txt\n",
            "feature extraction time:  5.845146894454956\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1851, 4976, 4819,  ..., 9570, 5483, 1859], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09892797470092773\n",
            "Loss: 0.22128945746324513\n",
            "rotation error test:  9.94212768705971\n",
            "translation error test:  0.7359223680926832\n",
            "--- 11.653189897537231 seconds ---\n",
            "Processing file: cup_0015.txt\n",
            "feature extraction time:  5.5200982093811035\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2195, 7085, 6642,  ..., 7463, 7848, 5170], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10773754119873047\n",
            "Loss: 0.1657887019420152\n",
            "rotation error test:  34.535319942085586\n",
            "translation error test:  0.6199768935207122\n",
            "--- 11.334923267364502 seconds ---\n",
            "Epoch: [1/4], Batch: 14, Loss: 0.1657887019420152\n",
            "Processing file: cup_0016.txt\n",
            "feature extraction time:  5.483110666275024\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7065, 8514, 9508,  ..., 9571, 6237, 7175], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10423922538757324\n",
            "Loss: 0.31622406888448445\n",
            "rotation error test:  15.5028889763074\n",
            "translation error test:  0.9544657266341344\n",
            "--- 11.274463891983032 seconds ---\n",
            "Processing file: cup_0017.txt\n",
            "feature extraction time:  5.502110481262207\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01300048828125\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9019, 8581, 9764,  ..., 4794,  253, 6033], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11500287055969238\n",
            "Loss: 0.08415670840548141\n",
            "rotation error test:  7.986436483222886\n",
            "translation error test:  0.22606423050520097\n",
            "--- 11.264226198196411 seconds ---\n",
            "Processing file: cup_0018.txt\n",
            "feature extraction time:  5.645113229751587\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014031648635864258\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7356, 1127, 2308,  ..., 5351,   27, 6445], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11000251770019531\n",
            "Loss: 0.27240474737070713\n",
            "rotation error test:  23.287178158146922\n",
            "translation error test:  0.878500581061502\n",
            "--- 11.436251640319824 seconds ---\n",
            "Processing file: cup_0019.txt\n",
            "feature extraction time:  5.4961113929748535\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1084, 5770, 3407,  ..., 4041, 4341, 8229], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10100221633911133\n",
            "Loss: 0.2492287964462493\n",
            "rotation error test:  19.40573574927516\n",
            "translation error test:  0.6082477245569367\n",
            "--- 11.280226707458496 seconds ---\n",
            "Processing file: cup_0020.txt\n",
            "feature extraction time:  5.579111337661743\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7988, 9267, 1411,  ..., 4350, 2397, 3222], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09931063652038574\n",
            "Loss: 0.21093088768476034\n",
            "rotation error test:  28.01884204421077\n",
            "translation error test:  0.7911847795742957\n",
            "--- 11.268536567687988 seconds ---\n",
            "Epoch: [1/4], Batch: 19, Loss: 0.21093088768476034\n",
            "Processing file: cup_0021.txt\n",
            "feature extraction time:  5.717212915420532\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000654220581055\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009996891021728516\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1004, 8938, 9053,  ..., 6261, 2734, 7769], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500264167785645\n",
            "Loss: 0.2867944432633349\n",
            "rotation error test:  350.3891900044575\n",
            "translation error test:  0.8750750943463105\n",
            "--- 11.410537481307983 seconds ---\n",
            "Processing file: cup_0022.txt\n",
            "feature extraction time:  5.691212177276611\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8578,  874, 3664,  ...,  749, 6497, 7974], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200214385986328\n",
            "Loss: 0.3165942885371198\n",
            "rotation error test:  273.50294861329036\n",
            "translation error test:  0.7041076437695789\n",
            "--- 11.400390625 seconds ---\n",
            "Processing file: cup_0023.txt\n",
            "feature extraction time:  5.584246873855591\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6466, 1266, 6608,  ..., 2319, 2765, 6682], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08993959426879883\n",
            "Loss: 0.2657789387703685\n",
            "rotation error test:  22.842250752562666\n",
            "translation error test:  0.9142653644245509\n",
            "--- 11.35334587097168 seconds ---\n",
            "Processing file: cup_0024.txt\n",
            "feature extraction time:  5.616112470626831\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8045, 4240, 6088,  ..., 3844, 1666, 5495], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500121116638184\n",
            "Loss: 0.3476941478175438\n",
            "rotation error test:  126.38110384878001\n",
            "translation error test:  0.594856200174575\n",
            "--- 11.346227407455444 seconds ---\n",
            "Processing file: cup_0025.txt\n",
            "feature extraction time:  5.498182773590088\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5256,  657, 1869,  ..., 8747, 5961, 8966], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10000181198120117\n",
            "Loss: 0.09379257766131105\n",
            "rotation error test:  17.525426286778913\n",
            "translation error test:  0.26937420747468427\n",
            "--- 11.227392196655273 seconds ---\n",
            "Epoch: [1/4], Batch: 24, Loss: 0.09379257766131105\n",
            "Processing file: cup_0026.txt\n",
            "feature extraction time:  5.59011435508728\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000249862670898\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6006, 3837, 1775,  ..., 6288, 2774, 5243], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08790445327758789\n",
            "Loss: 0.28684307401245335\n",
            "rotation error test:  10.230195556877774\n",
            "translation error test:  0.7705116043767674\n",
            "--- 11.364083290100098 seconds ---\n",
            "Processing file: cup_0027.txt\n",
            "feature extraction time:  5.510181188583374\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6721, 8915, 3692,  ...,  690, 7115, 2574], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09800219535827637\n",
            "Loss: 0.132354841581373\n",
            "rotation error test:  30.893430488128878\n",
            "translation error test:  0.3781984770818802\n",
            "--- 11.235779047012329 seconds ---\n",
            "Processing file: cup_0028.txt\n",
            "feature extraction time:  5.721114873886108\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01400303840637207\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9895, 8721, 5931,  ...,  260, 9866, 1193], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10805845260620117\n",
            "Loss: 0.3897312172065973\n",
            "rotation error test:  167.5778140235741\n",
            "translation error test:  1.0759149371910424\n",
            "--- 11.402404546737671 seconds ---\n",
            "Processing file: cup_0029.txt\n",
            "feature extraction time:  5.636188745498657\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5278, 2555, 2206,  ..., 7488, 5123, 9756], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600210189819336\n",
            "Loss: 0.36246292396738955\n",
            "rotation error test:  313.59151854346\n",
            "translation error test:  0.8069379266470506\n",
            "--- 11.31246566772461 seconds ---\n",
            "Processing file: cup_0030.txt\n",
            "feature extraction time:  5.544111251831055\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3713,  842, 8196,  ..., 6681,  838, 7077], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09800100326538086\n",
            "Loss: 0.24849482159636396\n",
            "rotation error test:  215.06038307702173\n",
            "translation error test:  0.7003236949926462\n",
            "--- 11.229351043701172 seconds ---\n",
            "Epoch: [1/4], Batch: 29, Loss: 0.24849482159636396\n",
            "Processing file: cup_0031.txt\n",
            "feature extraction time:  5.564146041870117\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014032125473022461\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3799, 7919, 7709,  ..., 4849, 9988, 9586], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08933591842651367\n",
            "Loss: 0.37684111920198243\n",
            "rotation error test:  22.896684653457502\n",
            "translation error test:  1.067041677291418\n",
            "--- 11.22730278968811 seconds ---\n",
            "Processing file: cup_0032.txt\n",
            "feature extraction time:  5.533113479614258\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3444, 6361, 4894,  ..., 9656, 1233, 7290], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10413146018981934\n",
            "Loss: 0.3144863537078124\n",
            "rotation error test:  260.09613410311\n",
            "translation error test:  0.7521123830773687\n",
            "--- 11.223360061645508 seconds ---\n",
            "Processing file: cup_0033.txt\n",
            "feature extraction time:  5.549262285232544\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4046, 5508, 1030,  ..., 7004, 1574, 8837], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08700203895568848\n",
            "Loss: 0.22146172884917126\n",
            "rotation error test:  38.145848263130915\n",
            "translation error test:  0.5116879627773533\n",
            "--- 11.237437009811401 seconds ---\n",
            "Processing file: cup_0034.txt\n",
            "feature extraction time:  5.488216876983643\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6704, 7779,  208,  ..., 4236, 2251, 1411], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0930020809173584\n",
            "Loss: 0.2744051643737851\n",
            "rotation error test:  111.37616669992775\n",
            "translation error test:  0.5749927307904814\n",
            "--- 11.35979413986206 seconds ---\n",
            "Processing file: cup_0035.txt\n",
            "feature extraction time:  5.5631115436553955\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1351,    5, 2173,  ..., 8002, 8152, 9729], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11020302772521973\n",
            "Loss: 0.19858872095992983\n",
            "rotation error test:  12.723192697636579\n",
            "translation error test:  0.4983976260509271\n",
            "--- 11.253727197647095 seconds ---\n",
            "Epoch: [1/4], Batch: 34, Loss: 0.19858872095992983\n",
            "Processing file: cup_0036.txt\n",
            "feature extraction time:  5.495109558105469\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4099,  186, 1364,  ..., 4489, 7607, 8592], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200285911560059\n",
            "Loss: 0.2171167079691272\n",
            "rotation error test:  41.59486721599051\n",
            "translation error test:  0.6383795197873193\n",
            "--- 11.461220502853394 seconds ---\n",
            "Processing file: cup_0037.txt\n",
            "feature extraction time:  5.553110837936401\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1332, 9125, 3494,  ...,  740, 6161,  192], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0930018424987793\n",
            "Loss: 0.38769440404681554\n",
            "rotation error test:  31.195649931478602\n",
            "translation error test:  1.0866686159926715\n",
            "--- 11.464229345321655 seconds ---\n",
            "Processing file: cup_0038.txt\n",
            "feature extraction time:  5.751116514205933\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010004043579101562\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 269, 7412, 5372,  ..., 4902, 1049, 5683], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500264167785645\n",
            "Loss: 0.3559055738027526\n",
            "rotation error test:  118.17578019780902\n",
            "translation error test:  0.8384146773034049\n",
            "--- 11.683235168457031 seconds ---\n",
            "Processing file: cup_0039.txt\n",
            "feature extraction time:  5.729105234146118\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 269, 1484, 2401,  ..., 3309, 4735, 9018], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09700131416320801\n",
            "Loss: 0.3059954286243376\n",
            "rotation error test:  17.650363466902967\n",
            "translation error test:  1.1300403547083941\n",
            "--- 11.663231134414673 seconds ---\n",
            "Processing file: cup_0040.txt\n",
            "feature extraction time:  6.938103199005127\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.021000146865844727\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   4, 1615, 9100,  ...,  470, 6402, 3994], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09300112724304199\n",
            "Loss: 0.1521629356171323\n",
            "rotation error test:  89.82508011395888\n",
            "translation error test:  0.2980915232762856\n",
            "--- 14.973217964172363 seconds ---\n",
            "Epoch: [1/4], Batch: 39, Loss: 0.1521629356171323\n",
            "Processing file: cup_0041.txt\n",
            "feature extraction time:  6.773097991943359\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.02200031280517578\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2370, 6864, 8591,  ..., 3367, 3096, 4499], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09800171852111816\n",
            "Loss: 0.20962712356081614\n",
            "rotation error test:  20.72211413944681\n",
            "translation error test:  0.41627714695896073\n",
            "--- 15.662389755249023 seconds ---\n",
            "Processing file: cup_0042.txt\n",
            "feature extraction time:  18.841270685195923\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.02900075912475586\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 941, 9938, 7615,  ..., 5411, 5077, 3592], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11700153350830078\n",
            "Loss: 0.3425766075134977\n",
            "rotation error test:  20.704997943128767\n",
            "translation error test:  0.9471276104093385\n",
            "--- 31.82445764541626 seconds ---\n",
            "Processing file: cup_0043.txt\n",
            "feature extraction time:  9.858141899108887\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.02200007438659668\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7524, 2868, 9343,  ..., 7095, 1966, 5579], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11631250381469727\n",
            "Loss: 0.14923117790176874\n",
            "rotation error test:  62.28798091191838\n",
            "translation error test:  0.14954525717038183\n",
            "--- 18.787582874298096 seconds ---\n",
            "Processing file: cup_0044.txt\n",
            "feature extraction time:  7.723111391067505\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.0149993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5564, 3943, 2811,  ..., 4457, 2689, 7831], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09800124168395996\n",
            "Loss: 0.2016536986509462\n",
            "rotation error test:  33.32096814015058\n",
            "translation error test:  0.628012519749986\n",
            "--- 13.738197803497314 seconds ---\n",
            "Processing file: cup_0045.txt\n",
            "feature extraction time:  5.777189493179321\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8383, 1740, 9627,  ..., 8804, 5791, 1563], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11400175094604492\n",
            "Loss: 0.24569422272113223\n",
            "rotation error test:  129.5637702075318\n",
            "translation error test:  0.5920161346769842\n",
            "--- 11.848276853561401 seconds ---\n",
            "Epoch: [1/4], Batch: 44, Loss: 0.24569422272113223\n",
            "Processing file: cup_0046.txt\n",
            "feature extraction time:  5.89208459854126\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1655, 7546, 4324,  ..., 4570, 5485, 4186], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09700155258178711\n",
            "Loss: 0.17508514046122925\n",
            "rotation error test:  12.506304537744096\n",
            "translation error test:  0.6304919734300386\n",
            "--- 12.048176288604736 seconds ---\n",
            "Processing file: cup_0047.txt\n",
            "feature extraction time:  5.952087879180908\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6773, 7284,  108,  ..., 9091, 7347, 1756], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900139808654785\n",
            "Loss: 0.15929560898462314\n",
            "rotation error test:  38.74802041690413\n",
            "translation error test:  0.22257900953358023\n",
            "--- 12.054175615310669 seconds ---\n",
            "Processing file: cup_0048.txt\n",
            "feature extraction time:  5.867084264755249\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8301,  749, 2192,  ...,  865, 3892, 4188], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09200143814086914\n",
            "Loss: 0.19804328951262756\n",
            "rotation error test:  48.32075972186846\n",
            "translation error test:  0.4570120235298854\n",
            "--- 11.841170310974121 seconds ---\n",
            "Processing file: cup_0049.txt\n",
            "feature extraction time:  5.7111430168151855\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000249862670898\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010004043579101562\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1162, 3607, 5122,  ..., 1176, 9337, 5578], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09215950965881348\n",
            "Loss: 0.2241625441367116\n",
            "rotation error test:  24.98196173329302\n",
            "translation error test:  0.4536019449318153\n",
            "--- 11.595388889312744 seconds ---\n",
            "Processing file: cup_0050.txt\n",
            "feature extraction time:  5.79908299446106\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000654220581055\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9623, 8956, 2692,  ..., 5193, 8881, 9030], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08800148963928223\n",
            "Loss: 0.26318626263974165\n",
            "rotation error test:  170.25936661894985\n",
            "translation error test:  0.6835524251580113\n",
            "--- 11.72031307220459 seconds ---\n",
            "Epoch: [1/4], Batch: 49, Loss: 0.26318626263974165\n",
            "Processing file: cup_0051.txt\n",
            "feature extraction time:  5.761085748672485\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999462127685547\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2185, 7021, 8148,  ..., 3284, 6213, 2498], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0989999771118164\n",
            "Loss: 0.16060092846903937\n",
            "rotation error test:  40.70908120539638\n",
            "translation error test:  0.28289110121485284\n",
            "--- 11.74917197227478 seconds ---\n",
            "Processing file: cup_0052.txt\n",
            "feature extraction time:  5.731082439422607\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  99, 2207,  613,  ...,  310,  825, 6125], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09163761138916016\n",
            "Loss: 0.2428296015350897\n",
            "rotation error test:  84.68284277503827\n",
            "translation error test:  0.15905588613599\n",
            "--- 11.632806062698364 seconds ---\n",
            "Processing file: cup_0053.txt\n",
            "feature extraction time:  5.731280088424683\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 163,  964, 9999,  ..., 7776, 6353, 8677], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10688114166259766\n",
            "Loss: 0.33123539662787743\n",
            "rotation error test:  148.59000375049982\n",
            "translation error test:  0.9537656573508398\n",
            "--- 11.67030382156372 seconds ---\n",
            "Processing file: cup_0054.txt\n",
            "feature extraction time:  5.714085102081299\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6776, 9953, 9917,  ..., 7390, 2005, 7986], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10700273513793945\n",
            "Loss: 0.24225035784680884\n",
            "rotation error test:  15.594116608383922\n",
            "translation error test:  0.8087928546834092\n",
            "--- 11.610170125961304 seconds ---\n",
            "Processing file: cup_0055.txt\n",
            "feature extraction time:  5.721081972122192\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7514, 7440,  518,  ..., 3498, 4695, 3940], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11015152931213379\n",
            "Loss: 0.3275473182318409\n",
            "rotation error test:  42.27076641805827\n",
            "translation error test:  0.9304053675935502\n",
            "--- 11.646282434463501 seconds ---\n",
            "Epoch: [1/4], Batch: 54, Loss: 0.3275473182318409\n",
            "Processing file: cup_0056.txt\n",
            "feature extraction time:  5.7250823974609375\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   7, 6519, 9199,  ...,  838, 9765, 9677], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900115966796875\n",
            "Loss: 0.36138904072600225\n",
            "rotation error test:  270.42090510840313\n",
            "translation error test:  0.9711148940191633\n",
            "--- 11.635167598724365 seconds ---\n",
            "Processing file: cup_0057.txt\n",
            "feature extraction time:  5.682081460952759\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4436, 1749, 9255,  ...,   62, 6757, 3996], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09400153160095215\n",
            "Loss: 0.18554850630089403\n",
            "rotation error test:  38.396196539435174\n",
            "translation error test:  0.3438835108297166\n",
            "--- 11.548165798187256 seconds ---\n",
            "Processing file: cup_0058.txt\n",
            "feature extraction time:  5.692081689834595\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5990, 2798, 7302,  ..., 8274, 9564, 5524], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200166702270508\n",
            "Loss: 0.37408279913789416\n",
            "rotation error test:  27.9174567151326\n",
            "translation error test:  0.7668759059550838\n",
            "--- 11.571166276931763 seconds ---\n",
            "Processing file: cup_0059.txt\n",
            "feature extraction time:  5.684081315994263\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 103, 9056, 4239,  ..., 3393, 4513, 9976], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08945822715759277\n",
            "Loss: 0.14324025356129966\n",
            "rotation error test:  26.985447805175912\n",
            "translation error test:  0.4302646274690846\n",
            "--- 11.54317021369934 seconds ---\n",
            "Processing file: cup_0060.txt\n",
            "feature extraction time:  5.671080827713013\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5786, 5840, 1883,  ..., 5045, 3837, 9705], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08407902717590332\n",
            "Loss: 0.4396203196036467\n",
            "rotation error test:  18.63520743267424\n",
            "translation error test:  1.5144040636138882\n",
            "--- 11.555983066558838 seconds ---\n",
            "Epoch: [1/4], Batch: 59, Loss: 0.4396203196036467\n",
            "Processing file: cup_0061.txt\n",
            "feature extraction time:  5.707155227661133\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01504206657409668\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4059,  509, 5489,  ..., 2407, 2198, 6186], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11500144004821777\n",
            "Loss: 0.22505952391079648\n",
            "rotation error test:  352.10672192002363\n",
            "translation error test:  0.8264806943640999\n",
            "--- 11.63727617263794 seconds ---\n",
            "Processing file: cup_0062.txt\n",
            "feature extraction time:  5.705121040344238\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000892639160156\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.00099945068359375\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2872, 9723, 5962,  ..., 4708, 3420, 2394], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0970010757446289\n",
            "Loss: 0.2083540923847415\n",
            "rotation error test:  330.14631545875187\n",
            "translation error test:  0.2944564989090441\n",
            "--- 11.610183238983154 seconds ---\n",
            "Processing file: cup_0063.txt\n",
            "feature extraction time:  5.744095087051392\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5243, 5919, 7758,  ..., 8106, 8949,  563], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900115966796875\n",
            "Loss: 0.15546683609985684\n",
            "rotation error test:  37.258398238054916\n",
            "translation error test:  0.32974040446091313\n",
            "--- 11.664963245391846 seconds ---\n",
            "Processing file: cup_0064.txt\n",
            "feature extraction time:  5.709100246429443\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3163, 9595, 7986,  ..., 1530, 5280, 1485], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11200141906738281\n",
            "Loss: 0.1460104112909174\n",
            "rotation error test:  25.547700180685656\n",
            "translation error test:  0.3496568697453794\n",
            "--- 11.604218244552612 seconds ---\n",
            "Processing file: cup_0065.txt\n",
            "feature extraction time:  5.693059206008911\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8023, 3325,  457,  ..., 3851, 7988, 9393], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200095176696777\n",
            "Loss: 0.27885954820547987\n",
            "rotation error test:  24.42680020583329\n",
            "translation error test:  0.644700522782145\n",
            "--- 11.562121391296387 seconds ---\n",
            "Epoch: [1/4], Batch: 64, Loss: 0.27885954820547987\n",
            "Processing file: cup_0066.txt\n",
            "feature extraction time:  5.692059755325317\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000011444091797\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5499, 2163, 5994,  ...,  971, 6368, 8385], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1100013256072998\n",
            "Loss: 0.327926914841122\n",
            "rotation error test:  59.39256783454458\n",
            "translation error test:  0.8987544089565349\n",
            "--- 11.577121496200562 seconds ---\n",
            "Processing file: cup_0067.txt\n",
            "feature extraction time:  5.713061809539795\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6037, 9616, 2263,  ..., 7633, 4064, 7338], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900044441223145\n",
            "Loss: 0.3426714219792685\n",
            "rotation error test:  42.095188190529804\n",
            "translation error test:  1.0414047969945377\n",
            "--- 11.593123435974121 seconds ---\n",
            "Processing file: cup_0068.txt\n",
            "feature extraction time:  5.725125074386597\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9194, 6768, 4634,  ..., 7153, 2888, 9616], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1060018539428711\n",
            "Loss: 0.17557525698331017\n",
            "rotation error test:  25.45386683988755\n",
            "translation error test:  0.49961374618726306\n",
            "--- 11.61018681526184 seconds ---\n",
            "Processing file: cup_0069.txt\n",
            "feature extraction time:  5.719059228897095\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01500082015991211\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9963, 4382, 5711,  ..., 4659,  105, 6634], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11400079727172852\n",
            "Loss: 0.3141313113580736\n",
            "rotation error test:  114.53675419601612\n",
            "translation error test:  0.6495620952414544\n",
            "--- 11.63112187385559 seconds ---\n",
            "Processing file: cup_0070.txt\n",
            "feature extraction time:  5.703059434890747\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9045, 9622,  798,  ..., 3620,  784, 7936], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300183296203613\n",
            "Loss: 0.13419808439688502\n",
            "rotation error test:  27.449053598935865\n",
            "translation error test:  0.414492579195234\n",
            "--- 11.61812162399292 seconds ---\n",
            "Epoch: [1/4], Batch: 69, Loss: 0.13419808439688502\n",
            "Processing file: cup_0071.txt\n",
            "feature extraction time:  5.723060846328735\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014081001281738281\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 624, 8476, 5602,  ..., 1259, 4274, 7101], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12800121307373047\n",
            "Loss: 0.14491123235083833\n",
            "rotation error test:  14.518149074148393\n",
            "translation error test:  0.32013718028253585\n",
            "--- 11.664308309555054 seconds ---\n",
            "Processing file: cup_0072.txt\n",
            "feature extraction time:  5.724177598953247\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1986, 8535, 1828,  ..., 2283, 9713,  298], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09800100326538086\n",
            "Loss: 0.19026480442048965\n",
            "rotation error test:  22.513861123348924\n",
            "translation error test:  0.3555499442747666\n",
            "--- 11.65069842338562 seconds ---\n",
            "Processing file: cup_0073.txt\n",
            "feature extraction time:  5.721059560775757\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1441,  692,   50,  ..., 9872, 7484, 3116], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08600091934204102\n",
            "Loss: 0.1950891404938086\n",
            "rotation error test:  338.8327698272176\n",
            "translation error test:  0.33840827866728435\n",
            "--- 11.604121208190918 seconds ---\n",
            "Processing file: cup_0074.txt\n",
            "feature extraction time:  5.688059091567993\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7499, 3973, 3132,  ..., 7792, 5097,  662], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0930323600769043\n",
            "Loss: 0.23665848792928598\n",
            "rotation error test:  71.84233116872183\n",
            "translation error test:  0.7522961158013901\n",
            "--- 11.56315279006958 seconds ---\n",
            "Processing file: cup_0075.txt\n",
            "feature extraction time:  5.731059312820435\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 577, 9324, 9363,  ..., 4508, 9414, 7409], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10016369819641113\n",
            "Loss: 0.29785549118825094\n",
            "rotation error test:  38.63126300695484\n",
            "translation error test:  0.8074296487546336\n",
            "--- 11.64225721359253 seconds ---\n",
            "Epoch: [1/4], Batch: 74, Loss: 0.29785549118825094\n",
            "Processing file: cup_0076.txt\n",
            "feature extraction time:  5.697059154510498\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015999794006347656\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5807,  670, 7584,  ..., 1346,  958, 4269], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10000157356262207\n",
            "Loss: 0.30624816889085305\n",
            "rotation error test:  185.72395794779905\n",
            "translation error test:  0.7620592938810783\n",
            "--- 11.590121269226074 seconds ---\n",
            "Processing file: cup_0077.txt\n",
            "feature extraction time:  5.709060192108154\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9007, 1762, 6503,  ..., 6330, 2894, 5887], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500144958496094\n",
            "Loss: 0.1251413360229346\n",
            "rotation error test:  14.986121785022222\n",
            "translation error test:  0.42169914960045407\n",
            "--- 11.598121881484985 seconds ---\n",
            "Processing file: cup_0078.txt\n",
            "feature extraction time:  5.720060110092163\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1460, 2289, 9481,  ..., 1822, 3057, 6898], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10700130462646484\n",
            "Loss: 0.3636692441165633\n",
            "rotation error test:  21.87065463785739\n",
            "translation error test:  1.068477164619357\n",
            "--- 11.633122205734253 seconds ---\n",
            "Processing file: cup_0079.txt\n",
            "feature extraction time:  5.699059724807739\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3334, 8165, 8218,  ..., 6936, 5491, 1245], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09100151062011719\n",
            "Loss: 0.2654947314610975\n",
            "rotation error test:  53.69980915322492\n",
            "translation error test:  0.7303668398309624\n",
            "--- 11.586121320724487 seconds ---\n",
            "Processing file: lamp_0001.txt\n",
            "feature extraction time:  5.687059164047241\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 809, 6832,  795,  ..., 7024, 6710, 5821], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11500120162963867\n",
            "Loss: 0.3340653747952148\n",
            "rotation error test:  26.87852495332423\n",
            "translation error test:  0.5853173157124612\n",
            "--- 11.58912181854248 seconds ---\n",
            "Epoch: [1/4], Batch: 79, Loss: 0.3340653747952148\n",
            "Processing file: lamp_0002.txt\n",
            "feature extraction time:  5.69805908203125\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7935, 6382, 4128,  ..., 3578, 6338,  897], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1380016803741455\n",
            "Loss: 0.24458216813181174\n",
            "rotation error test:  36.55299367636686\n",
            "translation error test:  0.8542164610638235\n",
            "--- 11.632122039794922 seconds ---\n",
            "Processing file: lamp_0003.txt\n",
            "feature extraction time:  5.666059255599976\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6399, 6340, 2215,  ..., 6305, 7413, 5372], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.108001708984375\n",
            "Loss: 0.2462299778743771\n",
            "rotation error test:  34.35705582408465\n",
            "translation error test:  0.6308440178133562\n",
            "--- 11.544119596481323 seconds ---\n",
            "Processing file: lamp_0004.txt\n",
            "feature extraction time:  5.672059774398804\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013998985290527344\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6220, 9996,  329,  ..., 9135,  485, 3207], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13000178337097168\n",
            "Loss: 0.13936745319560923\n",
            "rotation error test:  32.87807529359214\n",
            "translation error test:  0.39124201881028076\n",
            "--- 11.579122304916382 seconds ---\n",
            "Processing file: lamp_0005.txt\n",
            "feature extraction time:  5.701058387756348\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6348, 3626, 1684,  ...,  982,  993, 9891], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12600135803222656\n",
            "Loss: 0.11728595316627144\n",
            "rotation error test:  14.121189985199466\n",
            "translation error test:  0.35886476533040584\n",
            "--- 11.617058992385864 seconds ---\n",
            "Processing file: lamp_0006.txt\n",
            "feature extraction time:  5.698060512542725\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9883, 1998, 9914,  ..., 1649, 9338, 7920], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10000109672546387\n",
            "Loss: 0.3983563577209581\n",
            "rotation error test:  125.20459112324363\n",
            "translation error test:  0.9906506076481296\n",
            "--- 11.593121767044067 seconds ---\n",
            "Epoch: [1/4], Batch: 84, Loss: 0.3983563577209581\n",
            "Processing file: lamp_0007.txt\n",
            "feature extraction time:  5.67505955696106\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5477, 7185, 3028,  ..., 2169,  697, 3616], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13700175285339355\n",
            "Loss: 0.34436920487416334\n",
            "rotation error test:  8.780668817696888\n",
            "translation error test:  0.9527299463441288\n",
            "--- 11.584121465682983 seconds ---\n",
            "Processing file: lamp_0008.txt\n",
            "feature extraction time:  5.690058946609497\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009996891021728516\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3959, 6539,  230,  ...,  307, 3761,  889], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500144958496094\n",
            "Loss: 0.2409898511434317\n",
            "rotation error test:  190.27028434636466\n",
            "translation error test:  0.6485463365244916\n",
            "--- 11.587111949920654 seconds ---\n",
            "Processing file: lamp_0009.txt\n",
            "feature extraction time:  5.671043634414673\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01500082015991211\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9918, 2060, 5502,  ..., 4511, 2739, 6036], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11900138854980469\n",
            "Loss: 0.31955815077704786\n",
            "rotation error test:  259.1663908033343\n",
            "translation error test:  0.7083902857903109\n",
            "--- 11.555088520050049 seconds ---\n",
            "Processing file: lamp_0010.txt\n",
            "feature extraction time:  5.695044040679932\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9976,    3, 5240,  ..., 3890, 4230, 1057], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1100010871887207\n",
            "Loss: 0.20541671636215686\n",
            "rotation error test:  54.12363979812708\n",
            "translation error test:  0.5742757054718336\n",
            "--- 11.577089071273804 seconds ---\n",
            "Processing file: lamp_0011.txt\n",
            "feature extraction time:  5.671043157577515\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8730,  303, 9992,  ..., 8535, 2912, 7777], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13300180435180664\n",
            "Loss: 0.27033656117324084\n",
            "rotation error test:  29.865673410418903\n",
            "translation error test:  0.8329176227188572\n",
            "--- 11.58508849143982 seconds ---\n",
            "Epoch: [1/4], Batch: 89, Loss: 0.27033656117324084\n",
            "Processing file: lamp_0012.txt\n",
            "feature extraction time:  5.7060441970825195\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6702,  122, 2194,  ..., 9736, 2164, 9466], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11300110816955566\n",
            "Loss: 0.3911725883139244\n",
            "rotation error test:  315.09518527670264\n",
            "translation error test:  0.7614699985037519\n",
            "--- 11.612089395523071 seconds ---\n",
            "Processing file: lamp_0013.txt\n",
            "feature extraction time:  5.697043418884277\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7715,  251, 9645,  ...,  196, 4389, 5148], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12100100517272949\n",
            "Loss: 0.18521220734749716\n",
            "rotation error test:  35.97858847845375\n",
            "translation error test:  0.38890665621831766\n",
            "--- 11.59408950805664 seconds ---\n",
            "Processing file: lamp_0014.txt\n",
            "feature extraction time:  5.692043304443359\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000654220581055\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 634,    2, 9318,  ..., 4126, 2374, 8622], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600090980529785\n",
            "Loss: 0.26710329164273183\n",
            "rotation error test:  35.113604267045524\n",
            "translation error test:  0.46315245083515566\n",
            "--- 11.571088314056396 seconds ---\n",
            "Processing file: lamp_0015.txt\n",
            "feature extraction time:  5.7130444049835205\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999151229858398\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 246, 8036, 6715,  ..., 1112, 1981, 4902], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10100078582763672\n",
            "Loss: 0.33925489532618996\n",
            "rotation error test:  31.24819077330339\n",
            "translation error test:  0.6391936323949501\n",
            "--- 11.593089580535889 seconds ---\n",
            "Processing file: lamp_0016.txt\n",
            "feature extraction time:  5.721046447753906\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014055967330932617\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  70, 1604, 8328,  ..., 8409, 2480, 2567], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11540985107421875\n",
            "Loss: 0.3720227228566623\n",
            "rotation error test:  28.864329091460142\n",
            "translation error test:  0.6584071421154045\n",
            "--- 11.632018327713013 seconds ---\n",
            "Epoch: [1/4], Batch: 94, Loss: 0.3720227228566623\n",
            "Processing file: lamp_0017.txt\n",
            "feature extraction time:  5.704092741012573\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  11, 2255, 6040,  ..., 2310, 6084, 1801], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11100101470947266\n",
            "Loss: 0.123720537281003\n",
            "rotation error test:  24.123286671727254\n",
            "translation error test:  0.35654066022319464\n",
            "--- 11.609138011932373 seconds ---\n",
            "Processing file: lamp_0018.txt\n",
            "feature extraction time:  5.709043979644775\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000892639160156\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4791, 9274, 3479,  ..., 1171, 4893, 4400], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300087928771973\n",
            "Loss: 0.18068343420784008\n",
            "rotation error test:  59.642706672857514\n",
            "translation error test:  0.4446745752484316\n",
            "--- 11.610089778900146 seconds ---\n",
            "Processing file: lamp_0019.txt\n",
            "feature extraction time:  5.710104942321777\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5678, 7529,  891,  ..., 6988,  322, 1873], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0970008373260498\n",
            "Loss: 0.2583317942082571\n",
            "rotation error test:  74.82428810448026\n",
            "translation error test:  0.6055699633058141\n",
            "--- 11.60515022277832 seconds ---\n",
            "Processing file: lamp_0020.txt\n",
            "feature extraction time:  5.704225540161133\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999462127685547\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2968, 5505, 5901,  ..., 5750, 4893, 4701], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1230008602142334\n",
            "Loss: 0.1862328719135789\n",
            "rotation error test:  30.137149290891298\n",
            "translation error test:  0.6079595335772017\n",
            "--- 11.628326892852783 seconds ---\n",
            "Processing file: lamp_0021.txt\n",
            "feature extraction time:  5.740044116973877\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9351, 4979,  310,  ..., 7828, 2259, 5986], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09800100326538086\n",
            "Loss: 0.2433476898633749\n",
            "rotation error test:  31.43849537721814\n",
            "translation error test:  0.5822538393169364\n",
            "--- 11.662089347839355 seconds ---\n",
            "Epoch: [1/4], Batch: 99, Loss: 0.2433476898633749\n",
            "Processing file: lamp_0022.txt\n",
            "feature extraction time:  5.753046989440918\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3215, 3235, 7371,  ..., 2954, 7658, 1045], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900211334228516\n",
            "Loss: 0.2626685027775779\n",
            "rotation error test:  55.035558010418576\n",
            "translation error test:  0.6190944068503098\n",
            "--- 11.669093132019043 seconds ---\n",
            "Processing file: lamp_0023.txt\n",
            "feature extraction time:  5.725100994110107\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3770, 2572,  343,  ..., 8293, 2209, 1962], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1269996166229248\n",
            "Loss: 0.26191096339931724\n",
            "rotation error test:  65.0159771097874\n",
            "translation error test:  0.7101743775250104\n",
            "--- 11.667147159576416 seconds ---\n",
            "Processing file: lamp_0024.txt\n",
            "feature extraction time:  5.729109048843384\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000249862670898\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 778, 3664, 3747,  ...,  865, 6547, 9829], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900115966796875\n",
            "Loss: 0.1484951960604328\n",
            "rotation error test:  10.27547750952396\n",
            "translation error test:  0.332818161273812\n",
            "--- 11.648228645324707 seconds ---\n",
            "Processing file: lamp_0025.txt\n",
            "feature extraction time:  5.709043741226196\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 370, 3393, 6226,  ..., 3391, 6754, 8021], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09000110626220703\n",
            "Loss: 0.21611957734365903\n",
            "rotation error test:  36.83471036059856\n",
            "translation error test:  0.6198540198244765\n",
            "--- 11.595088958740234 seconds ---\n",
            "Processing file: lamp_0026.txt\n",
            "feature extraction time:  5.728046655654907\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   1, 7512, 6172,  ..., 4775, 7390, 2825], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1080014705657959\n",
            "Loss: 0.19078757160662413\n",
            "rotation error test:  143.07408905764044\n",
            "translation error test:  0.16626628830061943\n",
            "--- 11.673251628875732 seconds ---\n",
            "Epoch: [1/4], Batch: 104, Loss: 0.19078757160662413\n",
            "Processing file: lamp_0027.txt\n",
            "feature extraction time:  5.696043491363525\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3616, 7276, 3916,  ...,  179, 6933, 6981], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200119018554688\n",
            "Loss: 0.254433131404127\n",
            "rotation error test:  337.33388651119236\n",
            "translation error test:  0.9113167642672935\n",
            "--- 11.59012222290039 seconds ---\n",
            "Processing file: lamp_0028.txt\n",
            "feature extraction time:  5.701044082641602\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1926, 9179, 2568,  ..., 1102, 2796, 6530], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09200143814086914\n",
            "Loss: 0.22042021507359483\n",
            "rotation error test:  325.68142667950184\n",
            "translation error test:  0.5688483457011202\n",
            "--- 11.5920889377594 seconds ---\n",
            "Processing file: lamp_0029.txt\n",
            "feature extraction time:  5.701046943664551\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000654220581055\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6538, 1256, 2670,  ..., 3438, 6019, 4932], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09471392631530762\n",
            "Loss: 0.3647925629431907\n",
            "rotation error test:  34.3944023365597\n",
            "translation error test:  1.173923373808221\n",
            "--- 11.59491229057312 seconds ---\n",
            "Processing file: lamp_0030.txt\n",
            "feature extraction time:  5.707142353057861\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000654220581055\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009996891021728516\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8108, 8362, 4179,  ..., 6550, 8390, 6671], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12000179290771484\n",
            "Loss: 0.3202618894138984\n",
            "rotation error test:  315.5328948371495\n",
            "translation error test:  0.5550415593769069\n",
            "--- 11.623837232589722 seconds ---\n",
            "Processing file: lamp_0031.txt\n",
            "feature extraction time:  5.708135604858398\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6797, 6302, 8751,  ..., 3922, 6905, 2580], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.15400123596191406\n",
            "Loss: 0.25186457573703697\n",
            "rotation error test:  33.485111743226526\n",
            "translation error test:  0.48555749116197316\n",
            "--- 11.680265188217163 seconds ---\n",
            "Epoch: [1/4], Batch: 109, Loss: 0.25186457573703697\n",
            "Processing file: lamp_0032.txt\n",
            "feature extraction time:  5.706224679946899\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1868,    1, 5379,  ..., 1117,  467, 4872], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1230013370513916\n",
            "Loss: 0.3747129899485174\n",
            "rotation error test:  281.46712572179774\n",
            "translation error test:  0.7120349357653255\n",
            "--- 11.655324697494507 seconds ---\n",
            "Processing file: lamp_0033.txt\n",
            "feature extraction time:  5.731043815612793\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1702, 6642, 6598,  ..., 1866, 5970, 4377], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10571980476379395\n",
            "Loss: 0.27695991915232204\n",
            "rotation error test:  13.682426444501465\n",
            "translation error test:  0.5580200896037278\n",
            "--- 11.646807670593262 seconds ---\n",
            "Processing file: lamp_0034.txt\n",
            "feature extraction time:  5.751044034957886\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 652, 5471,  626,  ..., 9480, 1386, 8112], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11700057983398438\n",
            "Loss: 0.26672928732055\n",
            "rotation error test:  56.992702946853264\n",
            "translation error test:  0.4339883966659132\n",
            "--- 11.702078342437744 seconds ---\n",
            "Processing file: lamp_0035.txt\n",
            "feature extraction time:  5.728112459182739\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5886, 5043, 3383,  ..., 7613, 4916, 8868], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09800052642822266\n",
            "Loss: 0.28017385751011603\n",
            "rotation error test:  54.93279411105944\n",
            "translation error test:  0.5812322969743781\n",
            "--- 11.610276222229004 seconds ---\n",
            "Processing file: lamp_0036.txt\n",
            "feature extraction time:  5.696242570877075\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8870,  409, 9838,  ..., 5697,  833, 3971], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11855864524841309\n",
            "Loss: 0.14940035343238886\n",
            "rotation error test:  71.28494330768586\n",
            "translation error test:  0.45331007227485137\n",
            "--- 11.591798543930054 seconds ---\n",
            "Epoch: [1/4], Batch: 114, Loss: 0.14940035343238886\n",
            "Processing file: lamp_0037.txt\n",
            "feature extraction time:  5.691112995147705\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.0149993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1476, 4933,  609,  ..., 2226, 5290,  294], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11900115013122559\n",
            "Loss: 0.1902537346055173\n",
            "rotation error test:  41.488880242814176\n",
            "translation error test:  0.4657236100591071\n",
            "--- 11.588258504867554 seconds ---\n",
            "Processing file: lamp_0038.txt\n",
            "feature extraction time:  5.695117473602295\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3175,   98, 4308,  ..., 4489, 1921, 3083], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300064086914062\n",
            "Loss: 0.3374089851562577\n",
            "rotation error test:  25.776034959364505\n",
            "translation error test:  0.6324332149325581\n",
            "--- 11.59515118598938 seconds ---\n",
            "Processing file: lamp_0039.txt\n",
            "feature extraction time:  5.683032035827637\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4335, 2843, 6203,  ..., 3764, 8055, 2133], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12131333351135254\n",
            "Loss: 0.17502385307121834\n",
            "rotation error test:  6.671294576194779\n",
            "translation error test:  0.6022305208676751\n",
            "--- 11.584887266159058 seconds ---\n",
            "Processing file: lamp_0040.txt\n",
            "feature extraction time:  5.692132234573364\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 178, 5845, 4523,  ..., 6807, 2064,  174], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1080007553100586\n",
            "Loss: 0.15322005086251353\n",
            "rotation error test:  19.77966442963187\n",
            "translation error test:  0.5186303775545226\n",
            "--- 11.584441661834717 seconds ---\n",
            "Processing file: lamp_0041.txt\n",
            "feature extraction time:  5.69209361076355\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000011444091797\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2007, 8460, 2207,  ..., 6851, 4707, 3267], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10716366767883301\n",
            "Loss: 0.10704308757890732\n",
            "rotation error test:  21.5697132435223\n",
            "translation error test:  0.25198944228040465\n",
            "--- 11.574257612228394 seconds ---\n",
            "Epoch: [1/4], Batch: 119, Loss: 0.10704308757890732\n",
            "Processing file: lamp_0042.txt\n",
            "feature extraction time:  5.698034763336182\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015002727508544922\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 243, 4334, 3627,  ..., 9681, 7651, 9445], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1120004653930664\n",
            "Loss: 0.2054925654400545\n",
            "rotation error test:  37.59733883248705\n",
            "translation error test:  0.42194680238607185\n",
            "--- 11.59049367904663 seconds ---\n",
            "Processing file: lamp_0043.txt\n",
            "feature extraction time:  5.714032411575317\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6695, 8799, 6554,  ..., 7516, 6119, 9097], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08700013160705566\n",
            "Loss: 0.24626642860559372\n",
            "rotation error test:  30.316764269088864\n",
            "translation error test:  0.8492619033285578\n",
            "--- 11.599066019058228 seconds ---\n",
            "Processing file: lamp_0044.txt\n",
            "feature extraction time:  5.7030322551727295\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7735,  809, 8504,  ..., 3415, 1965, 8876], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11500120162963867\n",
            "Loss: 0.24019835115143368\n",
            "rotation error test:  12.434777483300907\n",
            "translation error test:  0.6248610118551289\n",
            "--- 11.621065855026245 seconds ---\n",
            "Processing file: lamp_0045.txt\n",
            "feature extraction time:  5.70108962059021\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6406, 9601, 9487,  ..., 6016,  382,  451], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12600040435791016\n",
            "Loss: 0.2738389927785744\n",
            "rotation error test:  345.09934515246516\n",
            "translation error test:  0.8166303002525811\n",
            "--- 11.607437372207642 seconds ---\n",
            "Processing file: lamp_0046.txt\n",
            "feature extraction time:  5.727188348770142\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8230, 9039,  127,  ..., 3039, 9436, 3559], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08500099182128906\n",
            "Loss: 0.2291767759476203\n",
            "rotation error test:  335.5824903189668\n",
            "translation error test:  0.779518099154064\n",
            "--- 11.617395162582397 seconds ---\n",
            "Epoch: [1/4], Batch: 124, Loss: 0.2291767759476203\n",
            "Processing file: lamp_0047.txt\n",
            "feature extraction time:  5.730093240737915\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 530, 4157, 3859,  ..., 5521, 2850, 6692], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1340007781982422\n",
            "Loss: 0.3297936168552792\n",
            "rotation error test:  227.39385844028578\n",
            "translation error test:  0.5725628702888795\n",
            "--- 11.658237934112549 seconds ---\n",
            "Processing file: lamp_0048.txt\n",
            "feature extraction time:  5.711031675338745\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3091, 1971, 8393,  ...,  177, 9530, 5103], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11300063133239746\n",
            "Loss: 0.22931883065643383\n",
            "rotation error test:  13.146865846345813\n",
            "translation error test:  0.8241145389804386\n",
            "--- 11.629065990447998 seconds ---\n",
            "Processing file: lamp_0049.txt\n",
            "feature extraction time:  5.709032297134399\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 922, 8613, 8895,  ..., 3185,  787, 4240], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0950002670288086\n",
            "Loss: 0.3043820162565991\n",
            "rotation error test:  318.4852706378329\n",
            "translation error test:  0.5885076677557534\n",
            "--- 11.606950521469116 seconds ---\n",
            "Processing file: lamp_0050.txt\n",
            "feature extraction time:  5.705141067504883\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5989, 4624, 6719,  ..., 5671, 3342, 9777], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12000036239624023\n",
            "Loss: 0.24391073003772537\n",
            "rotation error test:  20.713774086535526\n",
            "translation error test:  0.8586645483244694\n",
            "--- 11.652209520339966 seconds ---\n",
            "Processing file: lamp_0051.txt\n",
            "feature extraction time:  5.704031944274902\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4871, 2128,  561,  ..., 3477, 3034, 4535], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300040245056152\n",
            "Loss: 0.27684004965462766\n",
            "rotation error test:  275.4117409207384\n",
            "translation error test:  0.8962679861845053\n",
            "--- 11.619860887527466 seconds ---\n",
            "Epoch: [1/4], Batch: 129, Loss: 0.27684004965462766\n",
            "Processing file: lamp_0052.txt\n",
            "feature extraction time:  5.695251226425171\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 573, 3265, 4719,  ..., 8823, 5574, 4134], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08600068092346191\n",
            "Loss: 0.30154151508305294\n",
            "rotation error test:  38.200586020617735\n",
            "translation error test:  0.4821456526172138\n",
            "--- 11.570284366607666 seconds ---\n",
            "Processing file: lamp_0053.txt\n",
            "feature extraction time:  5.694032192230225\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 437, 7626,  834,  ...,  118, 2385, 4544], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09829139709472656\n",
            "Loss: 0.16031478024915835\n",
            "rotation error test:  16.578778466878493\n",
            "translation error test:  0.3449007574641921\n",
            "--- 11.589394569396973 seconds ---\n",
            "Processing file: lamp_0054.txt\n",
            "feature extraction time:  5.655092477798462\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7206, 5195, 3263,  ..., 5189, 1504, 1075], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11507439613342285\n",
            "Loss: 0.27945315550516736\n",
            "rotation error test:  43.42065713324946\n",
            "translation error test:  0.8618716159193753\n",
            "--- 11.552477836608887 seconds ---\n",
            "Processing file: lamp_0055.txt\n",
            "feature extraction time:  5.705107688903809\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 926,  765, 6115,  ..., 4193,  363, 1723], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11417078971862793\n",
            "Loss: 0.2501716279350139\n",
            "rotation error test:  28.423752526184607\n",
            "translation error test:  0.7430638006570321\n",
            "--- 11.600135087966919 seconds ---\n",
            "Processing file: lamp_0056.txt\n",
            "feature extraction time:  5.707090377807617\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3325, 1212, 3691,  ..., 5155, 2210, 6661], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12666583061218262\n",
            "Loss: 0.30128923285533915\n",
            "rotation error test:  48.12088225420461\n",
            "translation error test:  0.6949498524013812\n",
            "--- 11.634791851043701 seconds ---\n",
            "Epoch: [1/4], Batch: 134, Loss: 0.30128923285533915\n",
            "Processing file: lamp_0057.txt\n",
            "feature extraction time:  5.694247245788574\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4899, 6050, 5874,  ..., 5346, 9720, 4080], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11808514595031738\n",
            "Loss: 0.28693780307169764\n",
            "rotation error test:  12.083481437243023\n",
            "translation error test:  0.7062474284492156\n",
            "--- 11.617332458496094 seconds ---\n",
            "Processing file: lamp_0058.txt\n",
            "feature extraction time:  5.7011942863464355\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014002561569213867\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 391, 5701, 9327,  ..., 8843, 7903, 7738], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0937650203704834\n",
            "Loss: 0.2740635774518229\n",
            "rotation error test:  35.47426920522828\n",
            "translation error test:  0.6849358276886243\n",
            "--- 11.594986915588379 seconds ---\n",
            "Processing file: lamp_0059.txt\n",
            "feature extraction time:  5.7071521282196045\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  33, 8638, 2311,  ..., 3951, 2976,  974], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10100126266479492\n",
            "Loss: 0.5450929611524883\n",
            "rotation error test:  316.3378537508112\n",
            "translation error test:  1.3111899473494708\n",
            "--- 11.631242036819458 seconds ---\n",
            "Processing file: lamp_0060.txt\n",
            "feature extraction time:  5.708030700683594\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6038,  170, 4032,  ..., 5466,  501, 3569], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12200117111206055\n",
            "Loss: 0.22542240340797087\n",
            "rotation error test:  41.85033158361437\n",
            "translation error test:  0.3593102581256679\n",
            "--- 11.633055925369263 seconds ---\n",
            "Processing file: lamp_0061.txt\n",
            "feature extraction time:  5.688024282455444\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2456,  354,   52,  ..., 8477, 3801,  175], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1340012550354004\n",
            "Loss: 0.30820030926633185\n",
            "rotation error test:  68.21191073407154\n",
            "translation error test:  0.7540479626960666\n",
            "--- 11.618693351745605 seconds ---\n",
            "Epoch: [1/4], Batch: 139, Loss: 0.30820030926633185\n",
            "Processing file: lamp_0062.txt\n",
            "feature extraction time:  5.705027103424072\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1508, 4005, 8936,  ..., 3561, 7332, 7348], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09800100326538086\n",
            "Loss: 0.2634869958020222\n",
            "rotation error test:  307.53399551848116\n",
            "translation error test:  0.3038970776962476\n",
            "--- 11.58105182647705 seconds ---\n",
            "Processing file: lamp_0063.txt\n",
            "feature extraction time:  5.678024768829346\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1888, 3431, 8119,  ..., 6004, 7988,  965], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10600137710571289\n",
            "Loss: 0.2590528871182852\n",
            "rotation error test:  65.76237717799599\n",
            "translation error test:  0.419975627724162\n",
            "--- 11.563049554824829 seconds ---\n",
            "Processing file: lamp_0064.txt\n",
            "feature extraction time:  5.716105937957764\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009996891021728516\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6238, 3797, 8345,  ..., 9933, 1059, 7855], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11900043487548828\n",
            "Loss: 0.237558342612934\n",
            "rotation error test:  118.90906978497497\n",
            "translation error test:  0.3629909854443739\n",
            "--- 11.604130983352661 seconds ---\n",
            "Processing file: lamp_0065.txt\n",
            "feature extraction time:  5.692074775695801\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999462127685547\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8986, 1556, 2423,  ..., 5228,    1, 3748], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09400033950805664\n",
            "Loss: 0.30493257654863715\n",
            "rotation error test:  18.17114303643466\n",
            "translation error test:  0.8065166293237337\n",
            "--- 11.565982103347778 seconds ---\n",
            "Processing file: lamp_0066.txt\n",
            "feature extraction time:  5.665026664733887\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 479, 2819,  135,  ...,   18, 8410, 5436], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11564230918884277\n",
            "Loss: 0.20424004206041954\n",
            "rotation error test:  37.49363583007644\n",
            "translation error test:  0.2784778035923745\n",
            "--- 11.548696279525757 seconds ---\n",
            "Epoch: [1/4], Batch: 144, Loss: 0.20424004206041954\n",
            "Processing file: lamp_0067.txt\n",
            "feature extraction time:  5.678026437759399\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2853, 6597, 6142,  ..., 8832, 2791, 4440], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300064086914062\n",
            "Loss: 0.26235447049917165\n",
            "rotation error test:  30.879005132864116\n",
            "translation error test:  0.811560837947854\n",
            "--- 11.555052042007446 seconds ---\n",
            "Processing file: lamp_0068.txt\n",
            "feature extraction time:  5.709023714065552\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1038, 6101, 3953,  ..., 4769, 5697, 9493], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12209582328796387\n",
            "Loss: 0.30884575982517226\n",
            "rotation error test:  75.94816998258577\n",
            "translation error test:  0.730046258536886\n",
            "--- 11.648106336593628 seconds ---\n",
            "Processing file: lamp_0069.txt\n",
            "feature extraction time:  5.677024841308594\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 107, 9593, 2522,  ..., 4888, 9718, 2430], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1080007553100586\n",
            "Loss: 0.2711247490884643\n",
            "rotation error test:  21.15806108705463\n",
            "translation error test:  0.7311739825419175\n",
            "--- 11.58204984664917 seconds ---\n",
            "Processing file: lamp_0070.txt\n",
            "feature extraction time:  5.683023929595947\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999462127685547\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8182, 1963, 3106,  ..., 6794, 9156, 2938], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11481595039367676\n",
            "Loss: 0.13653824539452622\n",
            "rotation error test:  19.585390763088636\n",
            "translation error test:  0.3975910149913146\n",
            "--- 11.578837633132935 seconds ---\n",
            "Processing file: lamp_0071.txt\n",
            "feature extraction time:  5.703160524368286\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7884, 2165, 6000,  ..., 6742, 1085, 5571], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11500096321105957\n",
            "Loss: 0.1567739953601833\n",
            "rotation error test:  104.99755099471642\n",
            "translation error test:  0.21054278076717464\n",
            "--- 11.61218547821045 seconds ---\n",
            "Epoch: [1/4], Batch: 149, Loss: 0.1567739953601833\n",
            "Processing file: lamp_0072.txt\n",
            "feature extraction time:  5.71302604675293\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014996528625488281\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 189, 9109, 3694,  ..., 9545, 7609, 3375], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600019454956055\n",
            "Loss: 0.3509668312457909\n",
            "rotation error test:  54.53577637897738\n",
            "translation error test:  0.9119201612923116\n",
            "--- 11.631051540374756 seconds ---\n",
            "Processing file: lamp_0073.txt\n",
            "feature extraction time:  5.6830244064331055\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9849, 6435, 7052,  ..., 2730, 9052, 4165], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10870742797851562\n",
            "Loss: 0.12256969648200591\n",
            "rotation error test:  33.08204274993912\n",
            "translation error test:  0.11069007359968941\n",
            "--- 11.572815656661987 seconds ---\n",
            "Processing file: lamp_0074.txt\n",
            "feature extraction time:  5.705025672912598\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999223709106445\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1732, 7824, 9139,  ..., 2210, 5528,  336], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13200092315673828\n",
            "Loss: 0.08848552958450688\n",
            "rotation error test:  26.23185519559136\n",
            "translation error test:  0.19913851619639755\n",
            "--- 11.64208722114563 seconds ---\n",
            "Processing file: lamp_0075.txt\n",
            "feature extraction time:  5.708092927932739\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  18, 7237, 2811,  ..., 4597, 8383,  567], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0950007438659668\n",
            "Loss: 0.3767092893155121\n",
            "rotation error test:  55.62944155917356\n",
            "translation error test:  1.1487853972341113\n",
            "--- 11.607118129730225 seconds ---\n",
            "Processing file: lamp_0076.txt\n",
            "feature extraction time:  5.709073305130005\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9091, 4873,  103,  ..., 7239, 4065, 1581], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500025749206543\n",
            "Loss: 0.35309688545000084\n",
            "rotation error test:  25.401172325520207\n",
            "translation error test:  0.8421222973212465\n",
            "--- 11.622098684310913 seconds ---\n",
            "Epoch: [1/4], Batch: 154, Loss: 0.35309688545000084\n",
            "Processing file: lamp_0077.txt\n",
            "feature extraction time:  5.70902419090271\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9592, 3439,  451,  ..., 5318, 9289, 7314], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1250007152557373\n",
            "Loss: 0.1406231686407281\n",
            "rotation error test:  9.315683302902634\n",
            "translation error test:  0.3031166798109531\n",
            "--- 11.650874853134155 seconds ---\n",
            "Processing file: lamp_0078.txt\n",
            "feature extraction time:  5.721027135848999\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015031576156616211\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6698, 1631,   38,  ..., 8970, 1583, 3165], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11600089073181152\n",
            "Loss: 0.14188930149933837\n",
            "rotation error test:  22.16873770848546\n",
            "translation error test:  0.32891652790216414\n",
            "--- 11.645967245101929 seconds ---\n",
            "Processing file: lamp_0079.txt\n",
            "feature extraction time:  5.714102506637573\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1412, 8257, 4688,  ..., 9817, 4712, 2555], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10800051689147949\n",
            "Loss: 0.14364176723489197\n",
            "rotation error test:  324.4901252047456\n",
            "translation error test:  0.3465259766255276\n",
            "--- 11.67273759841919 seconds ---\n",
            "Processing file: lamp_0080.txt\n",
            "feature extraction time:  5.69812273979187\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.016000032424926758\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6638, 9342, 8508,  ..., 1715, 6450, 6878], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10199999809265137\n",
            "Loss: 0.20259927808597922\n",
            "rotation error test:  26.126191846845554\n",
            "translation error test:  0.5965149961998383\n",
            "--- 11.613412618637085 seconds ---\n",
            "Processing file: lamp_0081.txt\n",
            "feature extraction time:  5.72302508354187\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4585,  334, 9763,  ..., 1768, 4595, 3575], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11900115013122559\n",
            "Loss: 0.22750145499511099\n",
            "rotation error test:  27.720800812812154\n",
            "translation error test:  0.4345717965004742\n",
            "--- 11.64805006980896 seconds ---\n",
            "Epoch: [1/4], Batch: 159, Loss: 0.22750145499511099\n",
            "Processing file: lamp_0082.txt\n",
            "feature extraction time:  5.714024066925049\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4830, 1744, 8396,  ...,  532, 2055, 7315], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13300013542175293\n",
            "Loss: 0.25478528357575225\n",
            "rotation error test:  11.76030117992444\n",
            "translation error test:  0.8141286039444123\n",
            "--- 11.676049709320068 seconds ---\n",
            "Processing file: lamp_0083.txt\n",
            "feature extraction time:  5.703022480010986\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4453,  692, 3742,  ..., 4939, 9669, 7354], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600186347961426\n",
            "Loss: 0.1568973489051877\n",
            "rotation error test:  8.062779661571534\n",
            "translation error test:  0.37228929204145583\n",
            "--- 11.606048107147217 seconds ---\n",
            "Processing file: lamp_0084.txt\n",
            "feature extraction time:  5.70402455329895\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9863,  901, 5793,  ...,  954, 9745, 3572], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1122748851776123\n",
            "Loss: 0.24705450315404442\n",
            "rotation error test:  79.91112967754444\n",
            "translation error test:  0.8715506369855215\n",
            "--- 11.618043184280396 seconds ---\n",
            "Processing file: lamp_0085.txt\n",
            "feature extraction time:  5.74102520942688\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 754, 7133, 6376,  ..., 7004, 2554, 8037], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500001907348633\n",
            "Loss: 0.20663603053009222\n",
            "rotation error test:  71.70265753947413\n",
            "translation error test:  0.5462787508262079\n",
            "--- 11.661473035812378 seconds ---\n",
            "Processing file: lamp_0086.txt\n",
            "feature extraction time:  5.700021028518677\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6781,   22, 6757,  ..., 4800, 7775, 2492], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300159454345703\n",
            "Loss: 0.3363588312155469\n",
            "rotation error test:  29.120213717357476\n",
            "translation error test:  0.9865938942030974\n",
            "--- 11.602209568023682 seconds ---\n",
            "Epoch: [1/4], Batch: 164, Loss: 0.3363588312155469\n",
            "Processing file: lamp_0087.txt\n",
            "feature extraction time:  5.7070183753967285\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01500248908996582\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6131, 2695, 5936,  ..., 5782, 1297, 4752], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13112139701843262\n",
            "Loss: 0.28317568762237877\n",
            "rotation error test:  33.412888182622524\n",
            "translation error test:  0.655020601550334\n",
            "--- 11.640174865722656 seconds ---\n",
            "Processing file: lamp_0088.txt\n",
            "feature extraction time:  5.708018064498901\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  20, 2444, 6554,  ..., 7922, 2870, 4516], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500121116638184\n",
            "Loss: 0.15607536798480917\n",
            "rotation error test:  22.444638297972272\n",
            "translation error test:  0.578663019155111\n",
            "--- 11.615038394927979 seconds ---\n",
            "Processing file: lamp_0089.txt\n",
            "feature extraction time:  5.699087858200073\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8401, 4917, 9095,  ..., 9446, 8752, 8723], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10599970817565918\n",
            "Loss: 0.2133054355967837\n",
            "rotation error test:  76.35438650778516\n",
            "translation error test:  0.4857416184595195\n",
            "--- 11.592106342315674 seconds ---\n",
            "Processing file: lamp_0090.txt\n",
            "feature extraction time:  5.706021785736084\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4214, 7385,   29,  ..., 7169, 6867, 2081], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09804201126098633\n",
            "Loss: 0.369359275960673\n",
            "rotation error test:  105.06033607985383\n",
            "translation error test:  0.9447539719967815\n",
            "--- 11.607081890106201 seconds ---\n",
            "Processing file: lamp_0091.txt\n",
            "feature extraction time:  5.709018230438232\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7167,  447, 8927,  ..., 8900, 1529, 7776], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11800122261047363\n",
            "Loss: 0.22026254712986837\n",
            "rotation error test:  261.3293247627385\n",
            "translation error test:  0.7455589214420173\n",
            "--- 11.624038934707642 seconds ---\n",
            "Epoch: [1/4], Batch: 169, Loss: 0.22026254712986837\n",
            "Processing file: lamp_0092.txt\n",
            "feature extraction time:  5.710224390029907\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5121, 8791, 9715,  ..., 2032, 9316, 3777], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11627650260925293\n",
            "Loss: 0.22075490776539017\n",
            "rotation error test:  30.260674121568726\n",
            "translation error test:  0.6431565252019946\n",
            "--- 11.628581285476685 seconds ---\n",
            "Processing file: lamp_0093.txt\n",
            "feature extraction time:  5.695155620574951\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999462127685547\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  12, 2994, 9722,  ..., 2764, 3590, 3964], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11900091171264648\n",
            "Loss: 0.35262575813557706\n",
            "rotation error test:  311.04516096341615\n",
            "translation error test:  0.8326281998598094\n",
            "--- 11.580232381820679 seconds ---\n",
            "Processing file: lamp_0094.txt\n",
            "feature extraction time:  5.66601824760437\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.012999534606933594\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3847, 4841, 8254,  ..., 3469, 8621, 6526], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1359996795654297\n",
            "Loss: 0.16713991928684377\n",
            "rotation error test:  28.601657944688917\n",
            "translation error test:  0.28683757159134377\n",
            "--- 11.55823802947998 seconds ---\n",
            "Processing file: lamp_0095.txt\n",
            "feature extraction time:  5.764066219329834\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9972, 9410, 4729,  ..., 8183, 1307, 3176], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11200094223022461\n",
            "Loss: 0.19270295132054882\n",
            "rotation error test:  47.58729232647613\n",
            "translation error test:  0.5970925402113669\n",
            "--- 11.519186735153198 seconds ---\n",
            "Processing file: lamp_0096.txt\n",
            "feature extraction time:  5.485020875930786\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   7, 5541, 1470,  ..., 6844, 3519, 7019], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10744929313659668\n",
            "Loss: 0.1384257462976895\n",
            "rotation error test:  41.27545312304493\n",
            "translation error test:  0.22408297689243892\n",
            "--- 11.16564130783081 seconds ---\n",
            "Epoch: [1/4], Batch: 174, Loss: 0.1384257462976895\n",
            "Processing file: lamp_0097.txt\n",
            "feature extraction time:  5.678018808364868\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7319, 4113, 1982,  ..., 2560, 5908,  538], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10100007057189941\n",
            "Loss: 0.29840417377324513\n",
            "rotation error test:  22.060927224061047\n",
            "translation error test:  0.6847805709202089\n",
            "--- 11.396037578582764 seconds ---\n",
            "Processing file: lamp_0098.txt\n",
            "feature extraction time:  5.706019639968872\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1282, 9407, 3417,  ..., 8584, 4511, 5657], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900068283081055\n",
            "Loss: 0.12350333198360994\n",
            "rotation error test:  30.50981465572842\n",
            "translation error test:  0.15002518139831947\n",
            "--- 11.465113878250122 seconds ---\n",
            "Processing file: lamp_0099.txt\n",
            "feature extraction time:  5.586018085479736\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 523, 4475,    4,  ..., 6193, 7677, 7908], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09199976921081543\n",
            "Loss: 0.15707206619529845\n",
            "rotation error test:  43.73901084104264\n",
            "translation error test:  0.5314719788371235\n",
            "--- 11.330036878585815 seconds ---\n",
            "Processing file: lamp_0100.txt\n",
            "feature extraction time:  5.608304977416992\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1998, 9663, 6266,  ..., 4156,  244, 1558], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10504770278930664\n",
            "Loss: 0.28246830549807\n",
            "rotation error test:  25.479129849538747\n",
            "translation error test:  0.5543756698362364\n",
            "--- 11.292733192443848 seconds ---\n",
            "Processing file: lamp_0101.txt\n",
            "feature extraction time:  5.610017776489258\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 140, 3182, 8692,  ..., 5771, 1010,  441], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500073432922363\n",
            "Loss: 0.12737552184645745\n",
            "rotation error test:  14.340539162083605\n",
            "translation error test:  0.44529119643909765\n",
            "--- 11.409037113189697 seconds ---\n",
            "Epoch: [1/4], Batch: 179, Loss: 0.12737552184645745\n",
            "Processing file: lamp_0102.txt\n",
            "feature extraction time:  5.567018270492554\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7340, 2313, 2419,  ..., 4962, 1748, 3221], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12200117111206055\n",
            "Loss: 0.38888273299555615\n",
            "rotation error test:  95.09475090724861\n",
            "translation error test:  0.832163011177855\n",
            "--- 11.294036865234375 seconds ---\n",
            "Processing file: lamp_0103.txt\n",
            "feature extraction time:  5.593141555786133\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1526, 1071, 5737,  ..., 1982, 3599, 6681], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09633350372314453\n",
            "Loss: 0.2952244355781632\n",
            "rotation error test:  25.379075470567408\n",
            "translation error test:  1.0233302083299793\n",
            "--- 11.316750288009644 seconds ---\n",
            "Processing file: lamp_0104.txt\n",
            "feature extraction time:  5.701018810272217\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2907, 5069, 1426,  ..., 7778,  885, 1052], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11600041389465332\n",
            "Loss: 0.1612827079817331\n",
            "rotation error test:  20.49879555184157\n",
            "translation error test:  0.5694717465375109\n",
            "--- 11.468173742294312 seconds ---\n",
            "Processing file: lamp_0105.txt\n",
            "feature extraction time:  5.694018840789795\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 153, 5726, 5916,  ..., 4970, 5194, 7579], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11815071105957031\n",
            "Loss: 0.2666595912870346\n",
            "rotation error test:  19.08318829777612\n",
            "translation error test:  0.6047011036956186\n",
            "--- 11.387190341949463 seconds ---\n",
            "Processing file: lamp_0106.txt\n",
            "feature extraction time:  5.672018527984619\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6869, 4461, 6938,  ..., 9221, 4800, 8829], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11500048637390137\n",
            "Loss: 0.274321417438455\n",
            "rotation error test:  161.6900119651591\n",
            "translation error test:  0.3619719620791172\n",
            "--- 11.402101993560791 seconds ---\n",
            "Epoch: [1/4], Batch: 184, Loss: 0.274321417438455\n",
            "Processing file: lamp_0107.txt\n",
            "feature extraction time:  5.57101845741272\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5571, 3516, 8775,  ..., 8328, 6572, 9331], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13100123405456543\n",
            "Loss: 0.22053536161576376\n",
            "rotation error test:  45.61123781685057\n",
            "translation error test:  0.5829718670267616\n",
            "--- 11.288052320480347 seconds ---\n",
            "Processing file: lamp_0108.txt\n",
            "feature extraction time:  5.583125114440918\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014988183975219727\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2043, 9893, 5413,  ..., 7628, 2467, 7075], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0820000171661377\n",
            "Loss: 0.28995173944747443\n",
            "rotation error test:  290.03538236067743\n",
            "translation error test:  0.65163552544653\n",
            "--- 11.405678510665894 seconds ---\n",
            "Processing file: lamp_0109.txt\n",
            "feature extraction time:  5.560154438018799\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000654220581055\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7613, 5692, 5156,  ..., 1591, 9040, 2200], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11500000953674316\n",
            "Loss: 0.21829682679710086\n",
            "rotation error test:  10.585501485152433\n",
            "translation error test:  0.5096089748960403\n",
            "--- 11.249173402786255 seconds ---\n",
            "Processing file: lamp_0110.txt\n",
            "feature extraction time:  5.496021509170532\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014042139053344727\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3314, 4819, 7616,  ...,  564, 7119,  807], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12868523597717285\n",
            "Loss: 0.1665452998572377\n",
            "rotation error test:  63.51467209209831\n",
            "translation error test:  0.30684180524868043\n",
            "--- 11.198853731155396 seconds ---\n",
            "Processing file: lamp_0111.txt\n",
            "feature extraction time:  5.481020450592041\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 861, 5748, 8949,  ..., 8119, 9194, 4458], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11799979209899902\n",
            "Loss: 0.2830015340233021\n",
            "rotation error test:  26.9757670181442\n",
            "translation error test:  0.6303905160136288\n",
            "--- 11.263039588928223 seconds ---\n",
            "Epoch: [1/4], Batch: 189, Loss: 0.2830015340233021\n",
            "Processing file: lamp_0112.txt\n",
            "feature extraction time:  5.570017576217651\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000249862670898\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009996891021728516\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9848,  221, 6489,  ..., 3058, 7280, 7943], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13200116157531738\n",
            "Loss: 0.23840459636050199\n",
            "rotation error test:  21.87753368397286\n",
            "translation error test:  0.9173908808765822\n",
            "--- 11.433114051818848 seconds ---\n",
            "Processing file: lamp_0113.txt\n",
            "feature extraction time:  5.549014329910278\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000011444091797\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9266, 7139,  436,  ..., 2398, 2884, 4330], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13700008392333984\n",
            "Loss: 0.14309741005407417\n",
            "rotation error test:  14.387431756321492\n",
            "translation error test:  0.3172445759928739\n",
            "--- 11.263029098510742 seconds ---\n",
            "Processing file: lamp_0114.txt\n",
            "feature extraction time:  5.507014513015747\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9960, 6928, 7097,  ..., 8478, 3657, 9413], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11599969863891602\n",
            "Loss: 0.3141107111722531\n",
            "rotation error test:  8.596610462233238\n",
            "translation error test:  0.7007773477453715\n",
            "--- 11.26202917098999 seconds ---\n",
            "Processing file: lamp_0115.txt\n",
            "feature extraction time:  5.641014099121094\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1085,    1, 9605,  ..., 2958, 8650, 2833], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1136481761932373\n",
            "Loss: 0.1539806604855575\n",
            "rotation error test:  19.53563618732735\n",
            "translation error test:  0.4860181619447\n",
            "--- 11.323708057403564 seconds ---\n",
            "loss epoch [0.45527400474711477, 0.16102683546538485, 0.15882663663940244, 0.25849248702655886, 0.34591763087816435, 0.3429389358279148, 0.1982837523109891, 0.209079750931471, 0.4235630480723163, 0.28412886561578027, 0.2129886666992797, 0.21434566620136392, 0.27994061746532445, 0.22128945746324513, 0.1657887019420152, 0.31622406888448445, 0.08415670840548141, 0.27240474737070713, 0.2492287964462493, 0.21093088768476034, 0.2867944432633349, 0.3165942885371198, 0.2657789387703685, 0.3476941478175438, 0.09379257766131105, 0.28684307401245335, 0.132354841581373, 0.3897312172065973, 0.36246292396738955, 0.24849482159636396, 0.37684111920198243, 0.3144863537078124, 0.22146172884917126, 0.2744051643737851, 0.19858872095992983, 0.2171167079691272, 0.38769440404681554, 0.3559055738027526, 0.3059954286243376, 0.1521629356171323, 0.20962712356081614, 0.3425766075134977, 0.14923117790176874, 0.2016536986509462, 0.24569422272113223, 0.17508514046122925, 0.15929560898462314, 0.19804328951262756, 0.2241625441367116, 0.26318626263974165, 0.16060092846903937, 0.2428296015350897, 0.33123539662787743, 0.24225035784680884, 0.3275473182318409, 0.36138904072600225, 0.18554850630089403, 0.37408279913789416, 0.14324025356129966, 0.4396203196036467, 0.22505952391079648, 0.2083540923847415, 0.15546683609985684, 0.1460104112909174, 0.27885954820547987, 0.327926914841122, 0.3426714219792685, 0.17557525698331017, 0.3141313113580736, 0.13419808439688502, 0.14491123235083833, 0.19026480442048965, 0.1950891404938086, 0.23665848792928598, 0.29785549118825094, 0.30624816889085305, 0.1251413360229346, 0.3636692441165633, 0.2654947314610975, 0.3340653747952148, 0.24458216813181174, 0.2462299778743771, 0.13936745319560923, 0.11728595316627144, 0.3983563577209581, 0.34436920487416334, 0.2409898511434317, 0.31955815077704786, 0.20541671636215686, 0.27033656117324084, 0.3911725883139244, 0.18521220734749716, 0.26710329164273183, 0.33925489532618996, 0.3720227228566623, 0.123720537281003, 0.18068343420784008, 0.2583317942082571, 0.1862328719135789, 0.2433476898633749, 0.2626685027775779, 0.26191096339931724, 0.1484951960604328, 0.21611957734365903, 0.19078757160662413, 0.254433131404127, 0.22042021507359483, 0.3647925629431907, 0.3202618894138984, 0.25186457573703697, 0.3747129899485174, 0.27695991915232204, 0.26672928732055, 0.28017385751011603, 0.14940035343238886, 0.1902537346055173, 0.3374089851562577, 0.17502385307121834, 0.15322005086251353, 0.10704308757890732, 0.2054925654400545, 0.24626642860559372, 0.24019835115143368, 0.2738389927785744, 0.2291767759476203, 0.3297936168552792, 0.22931883065643383, 0.3043820162565991, 0.24391073003772537, 0.27684004965462766, 0.30154151508305294, 0.16031478024915835, 0.27945315550516736, 0.2501716279350139, 0.30128923285533915, 0.28693780307169764, 0.2740635774518229, 0.5450929611524883, 0.22542240340797087, 0.30820030926633185, 0.2634869958020222, 0.2590528871182852, 0.237558342612934, 0.30493257654863715, 0.20424004206041954, 0.26235447049917165, 0.30884575982517226, 0.2711247490884643, 0.13653824539452622, 0.1567739953601833, 0.3509668312457909, 0.12256969648200591, 0.08848552958450688, 0.3767092893155121, 0.35309688545000084, 0.1406231686407281, 0.14188930149933837, 0.14364176723489197, 0.20259927808597922, 0.22750145499511099, 0.25478528357575225, 0.1568973489051877, 0.24705450315404442, 0.20663603053009222, 0.3363588312155469, 0.28317568762237877, 0.15607536798480917, 0.2133054355967837, 0.369359275960673, 0.22026254712986837, 0.22075490776539017, 0.35262575813557706, 0.16713991928684377, 0.19270295132054882, 0.1384257462976895, 0.29840417377324513, 0.12350333198360994, 0.15707206619529845, 0.28246830549807, 0.12737552184645745, 0.38888273299555615, 0.2952244355781632, 0.1612827079817331, 0.2666595912870346, 0.274321417438455, 0.22053536161576376, 0.28995173944747443, 0.21829682679710086, 0.1665452998572377, 0.2830015340233021, 0.23840459636050199, 0.14309741005407417, 0.3141107111722531, 0.1539806604855575]\n",
            "epoch #2\n",
            "Processing file: cup_0001.txt\n",
            "feature extraction time:  5.573009014129639\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2783, 5171, 6552,  ..., 4707, 4274, 6815], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0840001106262207\n",
            "Loss: 0.13561131243414615\n",
            "rotation error test:  359.2318766517706\n",
            "translation error test:  0.2155197162821704\n",
            "--- 11.258023977279663 seconds ---\n",
            "Processing file: cup_0002.txt\n",
            "feature extraction time:  5.650015115737915\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9996, 3251, 4667,  ..., 5971, 3274, 3600], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200071334838867\n",
            "Loss: 0.29309773701968106\n",
            "rotation error test:  78.06915586502885\n",
            "translation error test:  0.5606384523920382\n",
            "--- 11.329029560089111 seconds ---\n",
            "Processing file: cup_0003.txt\n",
            "feature extraction time:  5.56101393699646\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6882, 7540,   39,  ..., 9020, 9968, 2747], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08999991416931152\n",
            "Loss: 0.2944856253926542\n",
            "rotation error test:  44.74341760980708\n",
            "translation error test:  0.8456208660276867\n",
            "--- 11.319028854370117 seconds ---\n",
            "Processing file: cup_0004.txt\n",
            "feature extraction time:  5.527013540267944\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9695, 9778, 4906,  ..., 9460,  861, 5878], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09300088882446289\n",
            "Loss: 0.20887352311879298\n",
            "rotation error test:  16.242770900789505\n",
            "translation error test:  0.7377369196911912\n",
            "--- 11.291029214859009 seconds ---\n",
            "Processing file: cup_0005.txt\n",
            "feature extraction time:  5.5980141162872314\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5064, 2283, 6723,  ..., 3162, 7184, 8673], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08571887016296387\n",
            "Loss: 0.22044553628631686\n",
            "rotation error test:  321.08672127588534\n",
            "translation error test:  0.697830603879448\n",
            "--- 11.309722423553467 seconds ---\n",
            "Epoch: [2/4], Batch: 4, Loss: 0.22044553628631686\n",
            "Processing file: cup_0006.txt\n",
            "feature extraction time:  5.4871954917907715\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5374, 9126,  902,  ..., 3688, 8602, 2936], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09113335609436035\n",
            "Loss: 0.24892027226897265\n",
            "rotation error test:  294.59794838336495\n",
            "translation error test:  0.29732521129863576\n",
            "--- 11.395384550094604 seconds ---\n",
            "Processing file: cup_0007.txt\n",
            "feature extraction time:  5.483016490936279\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8561, 5269,  403,  ..., 5592, 7789, 1031], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10326051712036133\n",
            "Loss: 0.21280595820472437\n",
            "rotation error test:  29.302394483271147\n",
            "translation error test:  0.5021947464987704\n",
            "--- 11.19835901260376 seconds ---\n",
            "Processing file: cup_0008.txt\n",
            "feature extraction time:  5.622014999389648\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9013, 1717, 3211,  ..., 7159, 3178,   45], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400056838989258\n",
            "Loss: 0.10090878477502832\n",
            "rotation error test:  63.1561807741489\n",
            "translation error test:  0.042068992955377735\n",
            "--- 11.392030000686646 seconds ---\n",
            "Processing file: cup_0009.txt\n",
            "feature extraction time:  5.58812403678894\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 575, 8922, 6574,  ..., 3857, 5238, 6238], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500049591064453\n",
            "Loss: 0.2841430998881946\n",
            "rotation error test:  173.69480884543285\n",
            "translation error test:  0.543128550059044\n",
            "--- 11.396138906478882 seconds ---\n",
            "Processing file: cup_0010.txt\n",
            "feature extraction time:  5.581014156341553\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6398, 3584,  281,  ..., 2196, 2048, 8714], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09612703323364258\n",
            "Loss: 0.19417165220574284\n",
            "rotation error test:  27.126538364608052\n",
            "translation error test:  0.670513719254411\n",
            "--- 11.278301000595093 seconds ---\n",
            "Epoch: [2/4], Batch: 9, Loss: 0.19417165220574284\n",
            "Processing file: cup_0011.txt\n",
            "feature extraction time:  5.49597954750061\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014049291610717773\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6073, 7477, 8916,  ..., 1292, 7281, 7448], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10100007057189941\n",
            "Loss: 0.2573719358954675\n",
            "rotation error test:  259.842954762901\n",
            "translation error test:  0.44543304753862173\n",
            "--- 11.172013998031616 seconds ---\n",
            "Processing file: cup_0012.txt\n",
            "feature extraction time:  5.663013935089111\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5403, 1250,  606,  ..., 9296, 9624, 2126], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08999991416931152\n",
            "Loss: 0.2602845501747346\n",
            "rotation error test:  162.55035718848896\n",
            "translation error test:  0.4577048415708558\n",
            "--- 11.351029634475708 seconds ---\n",
            "Processing file: cup_0013.txt\n",
            "feature extraction time:  5.508013725280762\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 162, 9689, 5165,  ..., 6775, 1183, 6858], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400056838989258\n",
            "Loss: 0.29128842685438583\n",
            "rotation error test:  250.03223190392157\n",
            "translation error test:  0.5261592898692019\n",
            "--- 11.311028957366943 seconds ---\n",
            "Processing file: cup_0014.txt\n",
            "feature extraction time:  5.62801456451416\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1851, 4976, 4819,  ..., 3101, 1126, 1350], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10491251945495605\n",
            "Loss: 0.17056972738254386\n",
            "rotation error test:  7.290279461784489\n",
            "translation error test:  0.4637140274984909\n",
            "--- 11.403885126113892 seconds ---\n",
            "Processing file: cup_0015.txt\n",
            "feature extraction time:  5.564152717590332\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5182, 1915, 7952,  ..., 8668,  675, 9195], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09939312934875488\n",
            "Loss: 0.21574613650348828\n",
            "rotation error test:  24.406536333477565\n",
            "translation error test:  0.5042137759457077\n",
            "--- 11.350563049316406 seconds ---\n",
            "Epoch: [2/4], Batch: 14, Loss: 0.21574613650348828\n",
            "Processing file: cup_0016.txt\n",
            "feature extraction time:  5.581014156341553\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000249862670898\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6662, 4165, 4136,  ..., 3465, 2897, 7860], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10700035095214844\n",
            "Loss: 0.11660921195409267\n",
            "rotation error test:  37.09804574726889\n",
            "translation error test:  0.21753263149599117\n",
            "--- 11.386338472366333 seconds ---\n",
            "Processing file: cup_0017.txt\n",
            "feature extraction time:  5.5311667919158936\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4503, 2450, 4875,  ..., 8566,  991, 6714], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11100006103515625\n",
            "Loss: 0.33994559734380586\n",
            "rotation error test:  20.075726331325043\n",
            "translation error test:  0.8301889089995746\n",
            "--- 11.339181661605835 seconds ---\n",
            "Processing file: cup_0018.txt\n",
            "feature extraction time:  5.58001446723938\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2694, 3619, 7898,  ..., 8588, 8740, 9912], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400056838989258\n",
            "Loss: 0.1870090413343321\n",
            "rotation error test:  98.04323501167099\n",
            "translation error test:  0.5737090981464685\n",
            "--- 11.30302882194519 seconds ---\n",
            "Processing file: cup_0019.txt\n",
            "feature extraction time:  5.490015745162964\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5626, 3675, 7193,  ..., 4873, 8672, 9287], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10208249092102051\n",
            "Loss: 0.17261106214708896\n",
            "rotation error test:  27.18025250882431\n",
            "translation error test:  0.5386482819025594\n",
            "--- 11.201889276504517 seconds ---\n",
            "Processing file: cup_0020.txt\n",
            "feature extraction time:  5.512014627456665\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5197, 9391, 1367,  ..., 4236, 2970, 9375], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0970003604888916\n",
            "Loss: 0.136800908722958\n",
            "rotation error test:  34.49254764531857\n",
            "translation error test:  0.38475214524643153\n",
            "--- 11.16321611404419 seconds ---\n",
            "Epoch: [2/4], Batch: 19, Loss: 0.136800908722958\n",
            "Processing file: cup_0021.txt\n",
            "feature extraction time:  5.6630167961120605\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015104293823242188\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4101,  301, 8515,  ..., 3598, 5260, 4785], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10000038146972656\n",
            "Loss: 0.23853983269994172\n",
            "rotation error test:  20.82915226787996\n",
            "translation error test:  0.6304340202979365\n",
            "--- 11.377104759216309 seconds ---\n",
            "Processing file: cup_0022.txt\n",
            "feature extraction time:  5.647017240524292\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3871, 9344, 9478,  ..., 8757, 7236, 7460], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10313200950622559\n",
            "Loss: 0.1987204141384075\n",
            "rotation error test:  28.177094101370493\n",
            "translation error test:  0.6250546498561337\n",
            "--- 11.409236669540405 seconds ---\n",
            "Processing file: cup_0023.txt\n",
            "feature extraction time:  5.649066925048828\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5194, 2340, 8815,  ..., 8246,  712, 8781], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0934298038482666\n",
            "Loss: 0.16784868749467488\n",
            "rotation error test:  54.06207681780876\n",
            "translation error test:  0.3570607135563869\n",
            "--- 11.419585466384888 seconds ---\n",
            "Processing file: cup_0024.txt\n",
            "feature extraction time:  5.586010694503784\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000249862670898\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4455, 6339, 8339,  ..., 1367, 8886, 6338], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11423730850219727\n",
            "Loss: 0.3135737617028523\n",
            "rotation error test:  244.056058428826\n",
            "translation error test:  0.4720151774531632\n",
            "--- 11.326262950897217 seconds ---\n",
            "Processing file: cup_0025.txt\n",
            "feature extraction time:  5.503089427947998\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5862, 4174, 6642,  ..., 3799, 2510, 1988], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09400033950805664\n",
            "Loss: 0.3875522858844646\n",
            "rotation error test:  175.25124937393215\n",
            "translation error test:  0.7206267412062618\n",
            "--- 11.17210078239441 seconds ---\n",
            "Epoch: [2/4], Batch: 24, Loss: 0.3875522858844646\n",
            "Processing file: cup_0026.txt\n",
            "feature extraction time:  5.473011493682861\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 314, 8327, 7610,  ..., 6631, 6314, 1551], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08899974822998047\n",
            "Loss: 0.19501987518563574\n",
            "rotation error test:  5.917275457523652\n",
            "translation error test:  0.42802242812173413\n",
            "--- 11.210069179534912 seconds ---\n",
            "Processing file: cup_0027.txt\n",
            "feature extraction time:  5.5080108642578125\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 336, 9329, 5573,  ..., 4364, 7316, 3078], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10247635841369629\n",
            "Loss: 0.11399961474496262\n",
            "rotation error test:  18.029042820093807\n",
            "translation error test:  0.31657520324029487\n",
            "--- 11.184643983840942 seconds ---\n",
            "Processing file: cup_0028.txt\n",
            "feature extraction time:  5.548094749450684\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013998985290527344\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8638,   64, 1293,  ..., 1710, 6251, 1550], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10899949073791504\n",
            "Loss: 0.27101024195681317\n",
            "rotation error test:  380.33342850101116\n",
            "translation error test:  0.43818612977050836\n",
            "--- 11.281104803085327 seconds ---\n",
            "Processing file: cup_0029.txt\n",
            "feature extraction time:  5.568990468978882\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4801, 8089,  881,  ..., 4061, 6663, 1372], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09901785850524902\n",
            "Loss: 0.3171945836580118\n",
            "rotation error test:  182.33418883977237\n",
            "translation error test:  0.7360966899714279\n",
            "--- 11.244022130966187 seconds ---\n",
            "Processing file: cup_0030.txt\n",
            "feature extraction time:  5.60801100730896\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  53, 5114, 4641,  ..., 4503, 7279, 6063], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10810017585754395\n",
            "Loss: 0.2779283286608119\n",
            "rotation error test:  221.6848539841598\n",
            "translation error test:  0.5718173593411608\n",
            "--- 11.297329187393188 seconds ---\n",
            "Epoch: [2/4], Batch: 29, Loss: 0.2779283286608119\n",
            "Processing file: cup_0031.txt\n",
            "feature extraction time:  5.58940315246582\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8396, 5610, 7187,  ..., 6061, 8439, 5002], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10605216026306152\n",
            "Loss: 0.06740662887933409\n",
            "rotation error test:  21.414230670181272\n",
            "translation error test:  0.15687275371798057\n",
            "--- 11.315675497055054 seconds ---\n",
            "Processing file: cup_0032.txt\n",
            "feature extraction time:  5.451010704040527\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014032602310180664\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2915, 5730, 5860,  ..., 3844, 6675, 5417], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11600112915039062\n",
            "Loss: 0.17694291782959085\n",
            "rotation error test:  11.70038339393853\n",
            "translation error test:  0.5798918306605418\n",
            "--- 11.309117078781128 seconds ---\n",
            "Processing file: cup_0033.txt\n",
            "feature extraction time:  5.555085897445679\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   3, 7995, 3643,  ..., 2377, 9139, 6207], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08700037002563477\n",
            "Loss: 0.3740870667634736\n",
            "rotation error test:  147.35040786558983\n",
            "translation error test:  0.7236085651579989\n",
            "--- 11.39424991607666 seconds ---\n",
            "Processing file: cup_0034.txt\n",
            "feature extraction time:  5.611010551452637\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2093, 5658, 5465,  ..., 7503,  746, 8932], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08900022506713867\n",
            "Loss: 0.1655755416373022\n",
            "rotation error test:  19.559092714026853\n",
            "translation error test:  0.45331026239216976\n",
            "--- 11.3050217628479 seconds ---\n",
            "Processing file: cup_0035.txt\n",
            "feature extraction time:  5.564086437225342\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999223709106445\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 380,  834, 7760,  ...,  916, 9279, 5086], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300064086914062\n",
            "Loss: 0.27987970020733005\n",
            "rotation error test:  28.580574199717088\n",
            "translation error test:  0.6273287570064338\n",
            "--- 11.288098335266113 seconds ---\n",
            "Epoch: [2/4], Batch: 34, Loss: 0.27987970020733005\n",
            "Processing file: cup_0036.txt\n",
            "feature extraction time:  5.549066543579102\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8425, 1639, 9003,  ...,  299, 1903,  619], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09900021553039551\n",
            "Loss: 0.2291950343266047\n",
            "rotation error test:  130.6145232742301\n",
            "translation error test:  0.33553585493893634\n",
            "--- 11.315130949020386 seconds ---\n",
            "Processing file: cup_0037.txt\n",
            "feature extraction time:  5.490010976791382\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7064,  878, 2611,  ..., 9058, 5573, 2986], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10677218437194824\n",
            "Loss: 0.31120395799131906\n",
            "rotation error test:  132.727324667618\n",
            "translation error test:  0.3659089060888411\n",
            "--- 11.23079538345337 seconds ---\n",
            "Processing file: cup_0038.txt\n",
            "feature extraction time:  5.600064516067505\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2331, 4361,  459,  ..., 8770, 1583, 6232], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300016403198242\n",
            "Loss: 0.08311236873817163\n",
            "rotation error test:  20.101846735061706\n",
            "translation error test:  0.2010243398973292\n",
            "--- 11.369205713272095 seconds ---\n",
            "Processing file: cup_0039.txt\n",
            "feature extraction time:  5.574073553085327\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3837, 2429, 6328,  ..., 7157, 4527, 1032], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09400033950805664\n",
            "Loss: 0.3485778929739673\n",
            "rotation error test:  159.85190391446852\n",
            "translation error test:  0.9620539007930595\n",
            "--- 11.234447717666626 seconds ---\n",
            "Processing file: cup_0040.txt\n",
            "feature extraction time:  5.518081903457642\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009996891021728516\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7345, 4832,    9,  ..., 2555,   93, 9228], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09137606620788574\n",
            "Loss: 0.2255451586012164\n",
            "rotation error test:  17.924029194775272\n",
            "translation error test:  0.49200813845140345\n",
            "--- 11.217469215393066 seconds ---\n",
            "Epoch: [2/4], Batch: 39, Loss: 0.2255451586012164\n",
            "Processing file: cup_0041.txt\n",
            "feature extraction time:  5.758198976516724\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000249862670898\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9988, 1803, 4829,  ..., 2604, 4214, 1545], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10100007057189941\n",
            "Loss: 0.1584263506471805\n",
            "rotation error test:  27.063920980421717\n",
            "translation error test:  0.5360527288168898\n",
            "--- 11.425246000289917 seconds ---\n",
            "Processing file: cup_0042.txt\n",
            "feature extraction time:  5.529010534286499\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2225, 9547, 5284,  ..., 7661, 1237, 3085], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10669374465942383\n",
            "Loss: 0.1155388655058045\n",
            "rotation error test:  22.131105096192126\n",
            "translation error test:  0.32877894615474995\n",
            "--- 11.329680442810059 seconds ---\n",
            "Processing file: cup_0043.txt\n",
            "feature extraction time:  5.471194505691528\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5289,  251, 5018,  ..., 7789, 5378, 8523], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10007166862487793\n",
            "Loss: 0.33704249656104723\n",
            "rotation error test:  15.475933952220386\n",
            "translation error test:  0.7858170875370653\n",
            "--- 11.331287384033203 seconds ---\n",
            "Processing file: cup_0044.txt\n",
            "feature extraction time:  5.582064867019653\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014055728912353516\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4743, 5265,  715,  ...,  432, 9198, 7464], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10000014305114746\n",
            "Loss: 0.20568403641283187\n",
            "rotation error test:  206.06571843239414\n",
            "translation error test:  0.24551300738517165\n",
            "--- 11.340927600860596 seconds ---\n",
            "Processing file: cup_0045.txt\n",
            "feature extraction time:  5.539013624191284\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009996891021728516\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  48, 6604, 4503,  ..., 9689, 4043, 5896], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10399961471557617\n",
            "Loss: 0.263501957871026\n",
            "rotation error test:  342.23162501609585\n",
            "translation error test:  0.5110285974153057\n",
            "--- 11.373024940490723 seconds ---\n",
            "Epoch: [2/4], Batch: 44, Loss: 0.263501957871026\n",
            "Processing file: cup_0046.txt\n",
            "feature extraction time:  5.634011745452881\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3905, 9615, 2631,  ..., 4883, 6409, 4613], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0970001220703125\n",
            "Loss: 0.19629226490103693\n",
            "rotation error test:  47.54532470961709\n",
            "translation error test:  0.3113465119785012\n",
            "--- 11.381022453308105 seconds ---\n",
            "Processing file: cup_0047.txt\n",
            "feature extraction time:  5.611041307449341\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9881, 7855, 3664,  ...,   37, 4041,  589], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10609579086303711\n",
            "Loss: 0.30589248383128176\n",
            "rotation error test:  20.37568236897414\n",
            "translation error test:  0.6788687157630424\n",
            "--- 11.321810960769653 seconds ---\n",
            "Processing file: cup_0048.txt\n",
            "feature extraction time:  5.5810112953186035\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8055,  316, 9824,  ..., 5702, 8797, 3593], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500073432922363\n",
            "Loss: 0.3311387350019541\n",
            "rotation error test:  27.262321940286565\n",
            "translation error test:  0.8413177910556576\n",
            "--- 11.33002257347107 seconds ---\n",
            "Processing file: cup_0049.txt\n",
            "feature extraction time:  5.558011054992676\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7344, 7517, 4254,  ..., 6311, 4893, 8292], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09300041198730469\n",
            "Loss: 0.196294712701656\n",
            "rotation error test:  53.716664948878226\n",
            "translation error test:  0.5985609933914195\n",
            "--- 11.279226779937744 seconds ---\n",
            "Processing file: cup_0050.txt\n",
            "feature extraction time:  5.6471381187438965\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013951778411865234\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 973, 7412, 9008,  ..., 5093, 5113, 8257], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10408663749694824\n",
            "Loss: 0.14895140616105182\n",
            "rotation error test:  355.4006891515032\n",
            "translation error test:  0.229738881628014\n",
            "--- 11.29423189163208 seconds ---\n",
            "Epoch: [2/4], Batch: 49, Loss: 0.14895140616105182\n",
            "Processing file: cup_0051.txt\n",
            "feature extraction time:  5.634010314941406\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5701, 1984, 9786,  ..., 1302, 1534, 9588], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09206891059875488\n",
            "Loss: 0.24640985806524737\n",
            "rotation error test:  23.68047033356911\n",
            "translation error test:  0.7169962626311204\n",
            "--- 11.297623634338379 seconds ---\n",
            "Processing file: cup_0052.txt\n",
            "feature extraction time:  5.577008962631226\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2722,  360, 1855,  ..., 3389, 1331, 7825], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09611010551452637\n",
            "Loss: 0.08860436052513823\n",
            "rotation error test:  22.11562406595907\n",
            "translation error test:  0.17011703404267112\n",
            "--- 11.285130500793457 seconds ---\n",
            "Processing file: cup_0053.txt\n",
            "feature extraction time:  5.541008710861206\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015126943588256836\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5085, 7031, 9982,  ..., 4649, 8976, 3412], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300064086914062\n",
            "Loss: 0.10409363683586159\n",
            "rotation error test:  39.52826697226461\n",
            "translation error test:  0.13550197756834728\n",
            "--- 11.241276979446411 seconds ---\n",
            "Processing file: cup_0054.txt\n",
            "feature extraction time:  5.559009075164795\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9956, 5712, 4082,  ...,  282, 9409, 4971], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1120002269744873\n",
            "Loss: 0.29516137794550973\n",
            "rotation error test:  313.03433904620437\n",
            "translation error test:  0.6311528725802801\n",
            "--- 11.31898546218872 seconds ---\n",
            "Processing file: cup_0055.txt\n",
            "feature extraction time:  5.583009481430054\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1617, 8753, 6382,  ..., 8297,  339, 3265], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11299943923950195\n",
            "Loss: 0.23129174620858245\n",
            "rotation error test:  21.386895296224758\n",
            "translation error test:  0.6228759518075563\n",
            "--- 11.40006947517395 seconds ---\n",
            "Epoch: [2/4], Batch: 54, Loss: 0.23129174620858245\n",
            "Processing file: cup_0056.txt\n",
            "feature extraction time:  5.558009147644043\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1809, 8188, 9589,  ..., 1206, 9648, 3577], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12380695343017578\n",
            "Loss: 0.19674976600719168\n",
            "rotation error test:  54.92571829732154\n",
            "translation error test:  0.5448417242465131\n",
            "--- 11.297961235046387 seconds ---\n",
            "Processing file: cup_0057.txt\n",
            "feature extraction time:  5.529009103775024\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 404, 6452, 4281,  ..., 2517,   71, 6257], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600043296813965\n",
            "Loss: 0.15538041805637154\n",
            "rotation error test:  16.46592476409129\n",
            "translation error test:  0.2997555138892173\n",
            "--- 11.3040189743042 seconds ---\n",
            "Processing file: cup_0058.txt\n",
            "feature extraction time:  5.570009469985962\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 131, 2206, 2938,  ..., 6552, 8142,  875], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.14200067520141602\n",
            "Loss: 0.34602936600572776\n",
            "rotation error test:  333.44997511214297\n",
            "translation error test:  0.8936058199421818\n",
            "--- 11.447019577026367 seconds ---\n",
            "Processing file: cup_0059.txt\n",
            "feature extraction time:  5.627043724060059\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013965845108032227\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6019, 4134, 9214,  ..., 4783, 4243, 6741], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10369396209716797\n",
            "Loss: 0.18981840442862452\n",
            "rotation error test:  20.75045720300359\n",
            "translation error test:  0.48961353104321925\n",
            "--- 11.327810049057007 seconds ---\n",
            "Processing file: cup_0060.txt\n",
            "feature extraction time:  5.603086948394775\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 781, 6008, 9681,  ...,  191, 8239, 8772], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09904766082763672\n",
            "Loss: 0.22677928399838637\n",
            "rotation error test:  23.205340713723547\n",
            "translation error test:  0.66275471642148\n",
            "--- 11.301113843917847 seconds ---\n",
            "Epoch: [2/4], Batch: 59, Loss: 0.22677928399838637\n",
            "Processing file: cup_0061.txt\n",
            "feature extraction time:  5.494009017944336\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8499, 2763, 1227,  ..., 1592, 9400, 8475], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200047492980957\n",
            "Loss: 0.2839754598530614\n",
            "rotation error test:  13.029255546044535\n",
            "translation error test:  0.8132196392411122\n",
            "--- 11.147018432617188 seconds ---\n",
            "Processing file: cup_0062.txt\n",
            "feature extraction time:  5.47800874710083\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 849, 1887, 5769,  ..., 8218, 2908, 2974], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10600042343139648\n",
            "Loss: 0.13557494624542096\n",
            "rotation error test:  16.890330159471738\n",
            "translation error test:  0.21273781611201925\n",
            "--- 11.16101861000061 seconds ---\n",
            "Processing file: cup_0063.txt\n",
            "feature extraction time:  5.579047203063965\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6730, 5279, 3693,  ..., 2762, 3585, 4675], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09516096115112305\n",
            "Loss: 0.2106732457611351\n",
            "rotation error test:  146.28872136789275\n",
            "translation error test:  0.38178686461668626\n",
            "--- 11.31778883934021 seconds ---\n",
            "Processing file: cup_0064.txt\n",
            "feature extraction time:  5.538084506988525\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000726699829102\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  12, 2744, 7653,  ..., 3896,  957, 5387], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0950007438659668\n",
            "Loss: 0.22029762617149812\n",
            "rotation error test:  8.993150592646861\n",
            "translation error test:  0.7260389056126894\n",
            "--- 11.27809453010559 seconds ---\n",
            "Processing file: cup_0065.txt\n",
            "feature extraction time:  5.498011827468872\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3211, 6640, 6544,  ..., 8153, 6293, 5650], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400032997131348\n",
            "Loss: 0.10097170885021536\n",
            "rotation error test:  18.253213461855996\n",
            "translation error test:  0.1739994956122008\n",
            "--- 11.26560640335083 seconds ---\n",
            "Epoch: [2/4], Batch: 64, Loss: 0.10097170885021536\n",
            "Processing file: cup_0066.txt\n",
            "feature extraction time:  5.524051189422607\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4319, 1819, 7262,  ..., 1180, 8673, 6088], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0950002670288086\n",
            "Loss: 0.31476480631222004\n",
            "rotation error test:  30.069466920061625\n",
            "translation error test:  0.9335059154273444\n",
            "--- 11.3280611038208 seconds ---\n",
            "Processing file: cup_0067.txt\n",
            "feature extraction time:  5.518009424209595\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010004043579101562\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1566, 7642, 4997,  ...,  678, 6251, 1058], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09900021553039551\n",
            "Loss: 0.3014627642303123\n",
            "rotation error test:  304.63918590592573\n",
            "translation error test:  0.5558276167100205\n",
            "--- 11.292427778244019 seconds ---\n",
            "Processing file: cup_0068.txt\n",
            "feature extraction time:  5.475009441375732\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999223709106445\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5325, 9377,  431,  ..., 5632, 7265, 3378], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09300017356872559\n",
            "Loss: 0.27065726599271756\n",
            "rotation error test:  84.45824322239355\n",
            "translation error test:  0.6555604361282169\n",
            "--- 11.127075433731079 seconds ---\n",
            "Processing file: cup_0069.txt\n",
            "feature extraction time:  5.579083204269409\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.0149993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9004, 3484,  513,  ..., 9044,  426, 4704], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10610342025756836\n",
            "Loss: 0.3004818071926478\n",
            "rotation error test:  335.28103843307224\n",
            "translation error test:  0.8320430722080387\n",
            "--- 11.258168458938599 seconds ---\n",
            "Processing file: cup_0070.txt\n",
            "feature extraction time:  5.4560089111328125\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 306, 7408, 1166,  ..., 8645, 4670,  730], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10440921783447266\n",
            "Loss: 0.24657976379308996\n",
            "rotation error test:  86.53890036109657\n",
            "translation error test:  0.7464754425887591\n",
            "--- 11.095394134521484 seconds ---\n",
            "Epoch: [2/4], Batch: 69, Loss: 0.24657976379308996\n",
            "Processing file: cup_0071.txt\n",
            "feature extraction time:  5.482084512710571\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3044, 6350,  593,  ..., 5106, 8000, 3045], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10792088508605957\n",
            "Loss: 0.14687736184293007\n",
            "rotation error test:  30.956853677738906\n",
            "translation error test:  0.33388731597751575\n",
            "--- 11.311014890670776 seconds ---\n",
            "Processing file: cup_0072.txt\n",
            "feature extraction time:  5.59401273727417\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999223709106445\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4499, 7026, 9434,  ..., 3891, 8235, 4151], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1120002269744873\n",
            "Loss: 0.39191752087082415\n",
            "rotation error test:  274.4639271274645\n",
            "translation error test:  0.9533427529762735\n",
            "--- 11.272021770477295 seconds ---\n",
            "Processing file: cup_0073.txt\n",
            "feature extraction time:  5.561009645462036\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000011444091797\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010004043579101562\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1754, 3412, 1255,  ..., 3838,  434, 3957], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11399960517883301\n",
            "Loss: 0.15501082785653594\n",
            "rotation error test:  25.147666693819453\n",
            "translation error test:  0.3585360270643208\n",
            "--- 11.360907316207886 seconds ---\n",
            "Processing file: cup_0074.txt\n",
            "feature extraction time:  5.51808762550354\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6766, 8158,    3,  ..., 1550, 5982, 5836], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0970005989074707\n",
            "Loss: 0.1175407839995668\n",
            "rotation error test:  34.88436647418551\n",
            "translation error test:  0.1878822591548012\n",
            "--- 11.366097450256348 seconds ---\n",
            "Processing file: cup_0075.txt\n",
            "feature extraction time:  5.568010091781616\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 930, 9268, 7654,  ...,  549, 7180, 1903], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08499956130981445\n",
            "Loss: 0.10169100484614979\n",
            "rotation error test:  14.540968725691247\n",
            "translation error test:  0.26551525568366147\n",
            "--- 11.314019680023193 seconds ---\n",
            "Epoch: [2/4], Batch: 74, Loss: 0.10169100484614979\n",
            "Processing file: cup_0076.txt\n",
            "feature extraction time:  5.481009006500244\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000249862670898\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1910, 2282, 7731,  ..., 3021, 5488, 9675], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09200048446655273\n",
            "Loss: 0.31057354744551025\n",
            "rotation error test:  89.29401761555076\n",
            "translation error test:  0.5290602329462044\n",
            "--- 11.184018850326538 seconds ---\n",
            "Processing file: cup_0077.txt\n",
            "feature extraction time:  5.519009113311768\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999462127685547\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 206, 8602, 6684,  ...,  492, 6999, 7175], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1100001335144043\n",
            "Loss: 0.17797312163810863\n",
            "rotation error test:  323.8937284809805\n",
            "translation error test:  0.490830708347425\n",
            "--- 11.291017293930054 seconds ---\n",
            "Processing file: cup_0078.txt\n",
            "feature extraction time:  5.505011081695557\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 695, 4314, 3064,  ...,  699, 6362, 5644], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10199999809265137\n",
            "Loss: 0.21764244269193858\n",
            "rotation error test:  29.67849549726292\n",
            "translation error test:  0.8140856021642522\n",
            "--- 11.203019618988037 seconds ---\n",
            "Processing file: cup_0079.txt\n",
            "feature extraction time:  5.626007080078125\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999462127685547\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6886,    2, 8664,  ..., 3122, 6687, 9260], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0890958309173584\n",
            "Loss: 0.14407642262850867\n",
            "rotation error test:  20.08183816976296\n",
            "translation error test:  0.2747568209808437\n",
            "--- 11.302042484283447 seconds ---\n",
            "Processing file: lamp_0001.txt\n",
            "feature extraction time:  5.562051296234131\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2216, 9863, 9013,  ..., 3551,  629, 9592], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400032997131348\n",
            "Loss: 0.2192036539302291\n",
            "rotation error test:  26.22779646082533\n",
            "translation error test:  0.5515487043752884\n",
            "--- 11.256238460540771 seconds ---\n",
            "Epoch: [2/4], Batch: 79, Loss: 0.2192036539302291\n",
            "Processing file: lamp_0002.txt\n",
            "feature extraction time:  5.487078666687012\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.012993335723876953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009968280792236328\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1023, 5582, 3882,  ..., 5853, 5675, 5738], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11099910736083984\n",
            "Loss: 0.24891452431642985\n",
            "rotation error test:  391.2558622452221\n",
            "translation error test:  0.29949467039592614\n",
            "--- 11.211089849472046 seconds ---\n",
            "Processing file: lamp_0003.txt\n",
            "feature extraction time:  5.53600811958313\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2348, 4504, 8106,  ..., 7315, 9163, 2695], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13379979133605957\n",
            "Loss: 0.24856837634131257\n",
            "rotation error test:  29.040568111334384\n",
            "translation error test:  0.5262979974707315\n",
            "--- 11.358845472335815 seconds ---\n",
            "Processing file: lamp_0004.txt\n",
            "feature extraction time:  5.59419846534729\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014002323150634766\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  32, 9703, 8859,  ...,  111, 9687, 5431], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10800027847290039\n",
            "Loss: 0.2836831367928282\n",
            "rotation error test:  70.01868321861255\n",
            "translation error test:  0.38206313399421027\n",
            "--- 11.302229166030884 seconds ---\n",
            "Processing file: lamp_0005.txt\n",
            "feature extraction time:  5.66100811958313\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 374, 6453, 2719,  ...,  795, 4073, 1331], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10800051689147949\n",
            "Loss: 0.15658091718291706\n",
            "rotation error test:  21.05809458705168\n",
            "translation error test:  0.5260008979507902\n",
            "--- 11.50301742553711 seconds ---\n",
            "Processing file: lamp_0006.txt\n",
            "feature extraction time:  5.4960081577301025\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6075, 9807, 3642,  ..., 2657,  107, 4626], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11096787452697754\n",
            "Loss: 0.2818944785841013\n",
            "rotation error test:  211.95026135672032\n",
            "translation error test:  0.5017803661703784\n",
            "--- 11.258949041366577 seconds ---\n",
            "Epoch: [2/4], Batch: 84, Loss: 0.2818944785841013\n",
            "Processing file: lamp_0007.txt\n",
            "feature extraction time:  5.499007701873779\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  67, 4203, 7982,  ..., 3498, 4696, 9038], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1230001449584961\n",
            "Loss: 0.22738913104525055\n",
            "rotation error test:  154.62567568628603\n",
            "translation error test:  0.20111708861666638\n",
            "--- 11.279016733169556 seconds ---\n",
            "Processing file: lamp_0008.txt\n",
            "feature extraction time:  5.4870078563690186\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999223709106445\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   1, 9756, 6364,  ..., 6172, 3061, 2882], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08500051498413086\n",
            "Loss: 0.28120979026247717\n",
            "rotation error test:  34.12650021529987\n",
            "translation error test:  0.5428711175451045\n",
            "--- 11.186016321182251 seconds ---\n",
            "Processing file: lamp_0009.txt\n",
            "feature extraction time:  5.599100351333618\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999462127685547\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9419, 5731, 4842,  ..., 5770, 4557, 5601], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12168622016906738\n",
            "Loss: 0.1804257996800953\n",
            "rotation error test:  7.845970904925486\n",
            "translation error test:  0.6574689358121936\n",
            "--- 11.32075572013855 seconds ---\n",
            "Processing file: lamp_0010.txt\n",
            "feature extraction time:  5.594067335128784\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   4, 7152, 6372,  ...,  847, 1920, 2702], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0970003604888916\n",
            "Loss: 0.11615260970533262\n",
            "rotation error test:  25.867344743075524\n",
            "translation error test:  0.31479692011644395\n",
            "--- 11.265122652053833 seconds ---\n",
            "Processing file: lamp_0011.txt\n",
            "feature extraction time:  5.624112606048584\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8959, 3094, 1376,  ..., 4367, 6149, 8477], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10000038146972656\n",
            "Loss: 0.45045734313424823\n",
            "rotation error test:  44.343766346490575\n",
            "translation error test:  0.9634596694739066\n",
            "--- 11.305168628692627 seconds ---\n",
            "Epoch: [2/4], Batch: 89, Loss: 0.45045734313424823\n",
            "Processing file: lamp_0012.txt\n",
            "feature extraction time:  5.609008073806763\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8769, 9896, 8513,  ..., 7768, 3119, 3321], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11768674850463867\n",
            "Loss: 0.31059543202917383\n",
            "rotation error test:  323.50314559101804\n",
            "translation error test:  0.6722119943136629\n",
            "--- 11.408706665039062 seconds ---\n",
            "Processing file: lamp_0013.txt\n",
            "feature extraction time:  5.534065008163452\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2017, 8061, 2140,  ..., 9043, 9778, 3917], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12220191955566406\n",
            "Loss: 0.1474982774030784\n",
            "rotation error test:  24.48269349768072\n",
            "translation error test:  0.5206540509934597\n",
            "--- 11.324927568435669 seconds ---\n",
            "Processing file: lamp_0014.txt\n",
            "feature extraction time:  5.577008247375488\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1824,  910, 1152,  ..., 8080, 8642, 1270], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09710550308227539\n",
            "Loss: 0.39513122767287323\n",
            "rotation error test:  6.865794867224928\n",
            "translation error test:  1.2531645775568865\n",
            "--- 11.39512300491333 seconds ---\n",
            "Processing file: lamp_0015.txt\n",
            "feature extraction time:  5.497288465499878\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 227, 7497, 8315,  ..., 4199, 5320, 8095], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09904766082763672\n",
            "Loss: 0.2764429738053923\n",
            "rotation error test:  22.822116695652554\n",
            "translation error test:  0.5940109002849258\n",
            "--- 11.180591344833374 seconds ---\n",
            "Processing file: lamp_0016.txt\n",
            "feature extraction time:  5.498225212097168\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  56, 9204, 5529,  ..., 7198, 8879, 9974], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11100029945373535\n",
            "Loss: 0.21485851019602392\n",
            "rotation error test:  13.304398825276085\n",
            "translation error test:  0.7793633718496622\n",
            "--- 11.184285402297974 seconds ---\n",
            "Epoch: [2/4], Batch: 94, Loss: 0.21485851019602392\n",
            "Processing file: lamp_0017.txt\n",
            "feature extraction time:  5.526074647903442\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3885,  689, 2659,  ..., 5868, 6710, 5544], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.125\n",
            "Loss: 0.2108477442670528\n",
            "rotation error test:  30.284828642908977\n",
            "translation error test:  0.6880270625952086\n",
            "--- 11.258175134658813 seconds ---\n",
            "Processing file: lamp_0018.txt\n",
            "feature extraction time:  5.526008367538452\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5139,  734, 3583,  ..., 9533, 6838, 9084], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12003588676452637\n",
            "Loss: 0.2039244633707199\n",
            "rotation error test:  19.050712918217297\n",
            "translation error test:  0.4872556613731468\n",
            "--- 11.383500814437866 seconds ---\n",
            "Processing file: lamp_0019.txt\n",
            "feature extraction time:  5.696208477020264\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6672, 1670,  238,  ..., 6190, 1138, 6925], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09200000762939453\n",
            "Loss: 0.16346165976674953\n",
            "rotation error test:  32.277208998339425\n",
            "translation error test:  0.23526092398278006\n",
            "--- 11.367361068725586 seconds ---\n",
            "Processing file: lamp_0020.txt\n",
            "feature extraction time:  5.629147052764893\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6922, 9959, 9934,  ...,  560, 2832, 9824], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09308886528015137\n",
            "Loss: 0.27550780205201764\n",
            "rotation error test:  28.062013452351273\n",
            "translation error test:  0.541039093067921\n",
            "--- 11.407307386398315 seconds ---\n",
            "Processing file: lamp_0021.txt\n",
            "feature extraction time:  5.468156099319458\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 452, 2820, 5017,  ..., 2860, 5982, 1712], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10135388374328613\n",
            "Loss: 0.3824357547499121\n",
            "rotation error test:  76.04125791678877\n",
            "translation error test:  1.037470205537455\n",
            "--- 11.162508249282837 seconds ---\n",
            "Epoch: [2/4], Batch: 99, Loss: 0.3824357547499121\n",
            "Processing file: lamp_0022.txt\n",
            "feature extraction time:  5.529007911682129\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6525, 5277, 9221,  ..., 5512, 8840, 9309], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300064086914062\n",
            "Loss: 0.19196061230797745\n",
            "rotation error test:  21.246167301464148\n",
            "translation error test:  0.7078069753910396\n",
            "--- 11.24501633644104 seconds ---\n",
            "Processing file: lamp_0023.txt\n",
            "feature extraction time:  5.50000786781311\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3742, 9547, 4566,  ..., 9807, 7662, 8858], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13400006294250488\n",
            "Loss: 0.29611139000265274\n",
            "rotation error test:  128.3363112369952\n",
            "translation error test:  0.6989442729669673\n",
            "--- 11.267038583755493 seconds ---\n",
            "Processing file: lamp_0024.txt\n",
            "feature extraction time:  5.493546009063721\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 255, 3675, 1450,  ..., 4995, 6081, 1448], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11713075637817383\n",
            "Loss: 0.27712700332611945\n",
            "rotation error test:  40.07532844750989\n",
            "translation error test:  0.7729553318138067\n",
            "--- 11.27965235710144 seconds ---\n",
            "Processing file: lamp_0025.txt\n",
            "feature extraction time:  5.533080339431763\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9530, 2772, 6391,  ..., 7260, 4079, 6445], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300016403198242\n",
            "Loss: 0.4418335627926288\n",
            "rotation error test:  257.50791953102924\n",
            "translation error test:  1.3485466479822161\n",
            "--- 11.226176500320435 seconds ---\n",
            "Processing file: lamp_0026.txt\n",
            "feature extraction time:  5.498009443283081\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.012999534606933594\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5743, 2331,   11,  ..., 2888, 8072, 7522], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0840003490447998\n",
            "Loss: 0.20760448520539898\n",
            "rotation error test:  48.29706553514961\n",
            "translation error test:  0.393810555306399\n",
            "--- 11.24001693725586 seconds ---\n",
            "Epoch: [2/4], Batch: 104, Loss: 0.20760448520539898\n",
            "Processing file: lamp_0027.txt\n",
            "feature extraction time:  5.5140063762664795\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01403188705444336\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5162, 1778, 1512,  ..., 4841, 8556, 1272], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10323691368103027\n",
            "Loss: 0.18107256835836436\n",
            "rotation error test:  161.2646200367704\n",
            "translation error test:  0.1380104484065421\n",
            "--- 11.1973397731781 seconds ---\n",
            "Processing file: lamp_0028.txt\n",
            "feature extraction time:  5.544006824493408\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1823, 4292, 4215,  ..., 9461, 4344, 6884], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10357832908630371\n",
            "Loss: 0.16538009505736811\n",
            "rotation error test:  13.156072882397048\n",
            "translation error test:  0.6233779263113186\n",
            "--- 11.219584226608276 seconds ---\n",
            "Processing file: lamp_0029.txt\n",
            "feature extraction time:  5.590061664581299\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5789,  713, 9844,  ..., 7065, 9512, 4359], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600043296813965\n",
            "Loss: 0.3141902799325951\n",
            "rotation error test:  72.31210556826775\n",
            "translation error test:  0.763547108794028\n",
            "--- 11.337069749832153 seconds ---\n",
            "Processing file: lamp_0030.txt\n",
            "feature extraction time:  5.544007778167725\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 737, 3285,  905,  ..., 8045, 8097, 4249], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10399961471557617\n",
            "Loss: 0.33348095846677056\n",
            "rotation error test:  87.86360862424097\n",
            "translation error test:  0.8649117246288414\n",
            "--- 11.29501485824585 seconds ---\n",
            "Processing file: lamp_0031.txt\n",
            "feature extraction time:  5.613007068634033\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9229, 1293, 4678,  ..., 1585,  941, 7220], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13000011444091797\n",
            "Loss: 0.24441331767409816\n",
            "rotation error test:  112.14615205842787\n",
            "translation error test:  0.5634619682928095\n",
            "--- 11.313014507293701 seconds ---\n",
            "Epoch: [2/4], Batch: 109, Loss: 0.24441331767409816\n",
            "Processing file: lamp_0032.txt\n",
            "feature extraction time:  5.509005308151245\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9900, 1861, 9147,  ..., 9705, 1095, 1402], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500025749206543\n",
            "Loss: 0.16494275439397896\n",
            "rotation error test:  34.69676769422052\n",
            "translation error test:  0.5061862473264518\n",
            "--- 11.2410147190094 seconds ---\n",
            "Processing file: lamp_0033.txt\n",
            "feature extraction time:  5.556006908416748\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 741, 9835, 3223,  ..., 5853, 3976, 2686], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09799957275390625\n",
            "Loss: 0.13023032999789713\n",
            "rotation error test:  19.88950135359459\n",
            "translation error test:  0.3256565057016346\n",
            "--- 11.249014139175415 seconds ---\n",
            "Processing file: lamp_0034.txt\n",
            "feature extraction time:  5.488006591796875\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   1, 6974, 8260,  ..., 1563, 9803, 8137], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12200045585632324\n",
            "Loss: 0.09208210135936822\n",
            "rotation error test:  27.644375725555278\n",
            "translation error test:  0.20503194281783324\n",
            "--- 11.192014455795288 seconds ---\n",
            "Processing file: lamp_0035.txt\n",
            "feature extraction time:  5.4990081787109375\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 397, 6816,  757,  ..., 6780, 6245, 4117], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1230003833770752\n",
            "Loss: 0.2967550410219521\n",
            "rotation error test:  32.50925669308198\n",
            "translation error test:  0.8454010978022966\n",
            "--- 11.179014921188354 seconds ---\n",
            "Processing file: lamp_0036.txt\n",
            "feature extraction time:  5.610007047653198\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999628067016602\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   1, 8371, 5836,  ..., 4485, 6653,  762], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0953371524810791\n",
            "Loss: 0.3258802051951768\n",
            "rotation error test:  46.42120815440829\n",
            "translation error test:  0.7969131029349721\n",
            "--- 11.31300950050354 seconds ---\n",
            "Epoch: [2/4], Batch: 114, Loss: 0.3258802051951768\n",
            "Processing file: lamp_0037.txt\n",
            "feature extraction time:  5.60600733757019\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6450, 1064, 9685,  ..., 5852, 8831,  992], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10316729545593262\n",
            "Loss: 0.3546630896544134\n",
            "rotation error test:  33.999893784686144\n",
            "translation error test:  0.8583301959457748\n",
            "--- 11.291184902191162 seconds ---\n",
            "Processing file: lamp_0038.txt\n",
            "feature extraction time:  5.591081619262695\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4045, 3486, 9769,  ..., 9083, 4303, 1217], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11700057983398438\n",
            "Loss: 0.2608353385971933\n",
            "rotation error test:  15.226428116436407\n",
            "translation error test:  0.7248250702813434\n",
            "--- 11.281155347824097 seconds ---\n",
            "Processing file: lamp_0039.txt\n",
            "feature extraction time:  5.650082111358643\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7049, 5076,  786,  ..., 8560, 4103,  185], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1100006103515625\n",
            "Loss: 0.20498920402911708\n",
            "rotation error test:  11.778530574655376\n",
            "translation error test:  0.6431944586354952\n",
            "--- 11.352432250976562 seconds ---\n",
            "Processing file: lamp_0040.txt\n",
            "feature extraction time:  5.547009468078613\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3832, 1377, 4119,  ..., 7821, 2620, 3669], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11006903648376465\n",
            "Loss: 0.2100573444518514\n",
            "rotation error test:  23.81124416271446\n",
            "translation error test:  0.6100042748689604\n",
            "--- 11.275085687637329 seconds ---\n",
            "Processing file: lamp_0041.txt\n",
            "feature extraction time:  5.4910078048706055\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.012999534606933594\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1850, 5323, 9335,  ..., 4070, 7089, 8460], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11899995803833008\n",
            "Loss: 0.22138176671648174\n",
            "rotation error test:  259.78732674154395\n",
            "translation error test:  0.21209757574752738\n",
            "--- 11.16301441192627 seconds ---\n",
            "Epoch: [2/4], Batch: 119, Loss: 0.22138176671648174\n",
            "Processing file: lamp_0042.txt\n",
            "feature extraction time:  5.570061206817627\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4203, 3895, 1922,  ..., 8141, 8271, 8169], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11674284934997559\n",
            "Loss: 0.36248909398234425\n",
            "rotation error test:  49.44301479277518\n",
            "translation error test:  1.0679198783800243\n",
            "--- 11.345775604248047 seconds ---\n",
            "Processing file: lamp_0043.txt\n",
            "feature extraction time:  5.512006998062134\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000011444091797\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   1, 9997, 9702,  ..., 9563, 8330, 2873], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.07928776741027832\n",
            "Loss: 0.1755379900229707\n",
            "rotation error test:  58.39120496484689\n",
            "translation error test:  0.42960450418466467\n",
            "--- 11.123506307601929 seconds ---\n",
            "Processing file: lamp_0044.txt\n",
            "feature extraction time:  5.5102338790893555\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9857,  591, 3859,  ..., 3976, 6496,  463], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10500001907348633\n",
            "Loss: 0.20345763887548818\n",
            "rotation error test:  78.97306361435595\n",
            "translation error test:  0.4651402481869573\n",
            "--- 11.267486095428467 seconds ---\n",
            "Processing file: lamp_0045.txt\n",
            "feature extraction time:  5.498007297515869\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999462127685547\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4409, 7669, 1101,  ..., 4483, 9235, 9485], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12505269050598145\n",
            "Loss: 0.3586898462487514\n",
            "rotation error test:  178.861565311858\n",
            "translation error test:  0.5348053505919825\n",
            "--- 11.386123657226562 seconds ---\n",
            "Processing file: lamp_0046.txt\n",
            "feature extraction time:  5.63604211807251\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014002561569213867\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9030, 4986, 4837,  ..., 5160, 1950,  900], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1191716194152832\n",
            "Loss: 0.24315431715587124\n",
            "rotation error test:  94.05402233895252\n",
            "translation error test:  0.19555018512629416\n",
            "--- 11.327490329742432 seconds ---\n",
            "Epoch: [2/4], Batch: 124, Loss: 0.24315431715587124\n",
            "Processing file: lamp_0047.txt\n",
            "feature extraction time:  5.542115688323975\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013973474502563477\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1285, 9287, 2484,  ..., 9045, 1656,  728], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.14700007438659668\n",
            "Loss: 0.20075765824164585\n",
            "rotation error test:  30.27125511330951\n",
            "translation error test:  0.5669243555429747\n",
            "--- 11.269495964050293 seconds ---\n",
            "Processing file: lamp_0048.txt\n",
            "feature extraction time:  5.598029136657715\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2606, 3249, 1781,  ..., 7894, 7790, 1225], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11300015449523926\n",
            "Loss: 0.2195892015825748\n",
            "rotation error test:  24.377017380377218\n",
            "translation error test:  0.6133619113044841\n",
            "--- 11.291754484176636 seconds ---\n",
            "Processing file: lamp_0049.txt\n",
            "feature extraction time:  5.722094774246216\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3634, 9596, 7180,  ...,  504, 6043, 7099], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1100001335144043\n",
            "Loss: 0.32537595315664297\n",
            "rotation error test:  35.217561112742096\n",
            "translation error test:  0.9899590236222521\n",
            "--- 11.404102087020874 seconds ---\n",
            "Processing file: lamp_0050.txt\n",
            "feature extraction time:  5.573007345199585\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4209, 4069,  979,  ..., 4061, 7737, 7225], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1201932430267334\n",
            "Loss: 0.18417208969690094\n",
            "rotation error test:  31.8932178731618\n",
            "translation error test:  0.43263954140363203\n",
            "--- 11.271174192428589 seconds ---\n",
            "Processing file: lamp_0051.txt\n",
            "feature extraction time:  5.480006456375122\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9048, 3905,  109,  ..., 7825, 4410, 2414], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.0989995002746582\n",
            "Loss: 0.2720287763230344\n",
            "rotation error test:  317.33169871864584\n",
            "translation error test:  0.7634052773744431\n",
            "--- 11.207013368606567 seconds ---\n",
            "Epoch: [2/4], Batch: 129, Loss: 0.2720287763230344\n",
            "Processing file: lamp_0052.txt\n",
            "feature extraction time:  5.508006572723389\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009996891021728516\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2774, 9405, 8843,  ..., 2751, 6592, 6032], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09499979019165039\n",
            "Loss: 0.3512262474422667\n",
            "rotation error test:  119.69023769132684\n",
            "translation error test:  1.1048135228280311\n",
            "--- 11.181013107299805 seconds ---\n",
            "Processing file: lamp_0053.txt\n",
            "feature extraction time:  5.4860076904296875\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3320, 6021, 8682,  ..., 3241,  490, 7384], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900044441223145\n",
            "Loss: 0.25416523580052036\n",
            "rotation error test:  30.32717488946306\n",
            "translation error test:  0.652126810943114\n",
            "--- 11.15401291847229 seconds ---\n",
            "Processing file: lamp_0054.txt\n",
            "feature extraction time:  5.576042175292969\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 385, 8826, 4950,  ..., 9552, 1286, 2128], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12657427787780762\n",
            "Loss: 0.2682845870212545\n",
            "rotation error test:  38.06672723251366\n",
            "translation error test:  0.4761274384073138\n",
            "--- 11.271761417388916 seconds ---\n",
            "Processing file: lamp_0055.txt\n",
            "feature extraction time:  5.510006427764893\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 255, 7273, 7812,  ..., 8005, 5243, 7846], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1150810718536377\n",
            "Loss: 0.21534758776508084\n",
            "rotation error test:  28.865346878558626\n",
            "translation error test:  0.5374077518570454\n",
            "--- 11.261097431182861 seconds ---\n",
            "Processing file: lamp_0056.txt\n",
            "feature extraction time:  5.469006299972534\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 418,  802, 7132,  ..., 3005, 1466, 3853], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12199997901916504\n",
            "Loss: 0.20885759958318878\n",
            "rotation error test:  30.076311598095838\n",
            "translation error test:  0.4562747489040322\n",
            "--- 11.31001329421997 seconds ---\n",
            "Epoch: [2/4], Batch: 134, Loss: 0.20885759958318878\n",
            "Processing file: lamp_0057.txt\n",
            "feature extraction time:  5.508009433746338\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9566,   12, 7141,  ..., 6566, 6219,  469], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09145474433898926\n",
            "Loss: 0.22975894813736816\n",
            "rotation error test:  42.21437554865194\n",
            "translation error test:  0.7028877872769539\n",
            "--- 11.165524244308472 seconds ---\n",
            "Processing file: lamp_0058.txt\n",
            "feature extraction time:  5.535085678100586\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2206, 7244, 6877,  ..., 5903, 7369, 7368], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10440707206726074\n",
            "Loss: 0.12059378520749542\n",
            "rotation error test:  22.056487747781237\n",
            "translation error test:  0.30853041935804637\n",
            "--- 11.188469886779785 seconds ---\n",
            "Processing file: lamp_0059.txt\n",
            "feature extraction time:  5.581009149551392\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  21, 6969, 9494,  ..., 4354, 8068, 3169], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600043296813965\n",
            "Loss: 0.445281947579174\n",
            "rotation error test:  43.80138708409028\n",
            "translation error test:  1.0609857155477778\n",
            "--- 11.239016056060791 seconds ---\n",
            "Processing file: lamp_0060.txt\n",
            "feature extraction time:  5.482008934020996\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 243, 9701, 6788,  ..., 9116, 9788, 4324], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1141362190246582\n",
            "Loss: 0.22695840863914962\n",
            "rotation error test:  256.8801341481092\n",
            "translation error test:  0.40586088283028593\n",
            "--- 11.244141578674316 seconds ---\n",
            "Processing file: lamp_0061.txt\n",
            "feature extraction time:  5.495072603225708\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1554, 5976, 5826,  ..., 7663, 7944, 5504], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1217813491821289\n",
            "Loss: 0.2854990061143853\n",
            "rotation error test:  23.262919277821947\n",
            "translation error test:  0.6768657062302254\n",
            "--- 11.177340507507324 seconds ---\n",
            "Epoch: [2/4], Batch: 139, Loss: 0.2854990061143853\n",
            "Processing file: lamp_0062.txt\n",
            "feature extraction time:  5.555081367492676\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4918, 8412, 4451,  ..., 6250, 9808, 6942], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11839485168457031\n",
            "Loss: 0.1996559991877707\n",
            "rotation error test:  29.43538212193613\n",
            "translation error test:  0.6792431631978483\n",
            "--- 11.262487173080444 seconds ---\n",
            "Processing file: lamp_0063.txt\n",
            "feature extraction time:  5.5680060386657715\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000726699829102\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.00099945068359375\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3390,  608, 2539,  ..., 7211, 6173, 8458], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11300039291381836\n",
            "Loss: 0.2247667573755586\n",
            "rotation error test:  200.7368205522532\n",
            "translation error test:  0.31107546955783766\n",
            "--- 11.261319398880005 seconds ---\n",
            "Processing file: lamp_0064.txt\n",
            "feature extraction time:  5.501009225845337\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2502, 9957, 2584,  ..., 5947, 2880, 9951], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.14300036430358887\n",
            "Loss: 0.3946689839622621\n",
            "rotation error test:  364.96633672288016\n",
            "translation error test:  0.7355150234913009\n",
            "--- 11.338016033172607 seconds ---\n",
            "Processing file: lamp_0065.txt\n",
            "feature extraction time:  5.479006290435791\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000249862670898\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   4, 1078, 8657,  ..., 2662, 1754, 4832], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10600042343139648\n",
            "Loss: 0.2834771583378989\n",
            "rotation error test:  54.03991274976945\n",
            "translation error test:  0.7078785992542291\n",
            "--- 11.201013565063477 seconds ---\n",
            "Processing file: lamp_0066.txt\n",
            "feature extraction time:  5.568006277084351\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   4, 9812, 4183,  ..., 5612, 1512, 1393], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11299967765808105\n",
            "Loss: 0.24356988211531416\n",
            "rotation error test:  255.8427512139679\n",
            "translation error test:  0.5161758919072019\n",
            "--- 11.24201226234436 seconds ---\n",
            "Epoch: [2/4], Batch: 144, Loss: 0.24356988211531416\n",
            "Processing file: lamp_0067.txt\n",
            "feature extraction time:  5.519006729125977\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2146, 6318, 6460,  ..., 5092, 4817, 4544], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12199974060058594\n",
            "Loss: 0.1512311549455423\n",
            "rotation error test:  20.502202270623787\n",
            "translation error test:  0.3581210569059317\n",
            "--- 11.174013614654541 seconds ---\n",
            "Processing file: lamp_0068.txt\n",
            "feature extraction time:  5.533006429672241\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5506, 1742, 9981,  ..., 6965, 8474, 7081], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09960699081420898\n",
            "Loss: 0.20810921340237679\n",
            "rotation error test:  21.377258232764113\n",
            "translation error test:  0.5339165820022932\n",
            "--- 11.182655096054077 seconds ---\n",
            "Processing file: lamp_0069.txt\n",
            "feature extraction time:  5.635197401046753\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8297, 3197, 9480,  ..., 4186,  654, 7746], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10613298416137695\n",
            "Loss: 0.17822714766853973\n",
            "rotation error test:  67.59756623645777\n",
            "translation error test:  0.39057212390055224\n",
            "--- 11.406456232070923 seconds ---\n",
            "Processing file: lamp_0070.txt\n",
            "feature extraction time:  5.7131688594818115\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4893, 1021, 7230,  ..., 6698, 3473, 7727], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11300277709960938\n",
            "Loss: 0.2556686657281498\n",
            "rotation error test:  41.727578218005505\n",
            "translation error test:  0.43000129820636024\n",
            "--- 11.426293134689331 seconds ---\n",
            "Processing file: lamp_0071.txt\n",
            "feature extraction time:  5.566121816635132\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1124, 1454, 9985,  ..., 5290, 2429,  101], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11705493927001953\n",
            "Loss: 0.25576807234305476\n",
            "rotation error test:  12.892476986721112\n",
            "translation error test:  0.7921538064851328\n",
            "--- 11.330291032791138 seconds ---\n",
            "Epoch: [2/4], Batch: 149, Loss: 0.25576807234305476\n",
            "Processing file: lamp_0072.txt\n",
            "feature extraction time:  5.490217924118042\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2604,   18, 2242,  ..., 6242, 4914, 5561], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400223731994629\n",
            "Loss: 0.22237160634796976\n",
            "rotation error test:  33.208159582837915\n",
            "translation error test:  0.645005543531358\n",
            "--- 11.15334153175354 seconds ---\n",
            "Processing file: lamp_0073.txt\n",
            "feature extraction time:  5.533123254776001\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7520, 6058, 4821,  ..., 2338, 4707, 7508], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10700273513793945\n",
            "Loss: 0.11881035139260174\n",
            "rotation error test:  21.257479812604338\n",
            "translation error test:  0.29593589928001746\n",
            "--- 11.29128122329712 seconds ---\n",
            "Processing file: lamp_0074.txt\n",
            "feature extraction time:  5.64117956161499\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000892639160156\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6687,  199, 1144,  ..., 4171,  819, 8546], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11757683753967285\n",
            "Loss: 0.10913675952428006\n",
            "rotation error test:  12.32493916688816\n",
            "translation error test:  0.2860221649374522\n",
            "--- 11.419882535934448 seconds ---\n",
            "Processing file: lamp_0075.txt\n",
            "feature extraction time:  5.547192573547363\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000654220581055\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 917, 1971, 8845,  ..., 2019, 7322, 2902], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10708427429199219\n",
            "Loss: 0.37398196899293124\n",
            "rotation error test:  153.58357234751895\n",
            "translation error test:  0.7999426335174561\n",
            "--- 11.295453548431396 seconds ---\n",
            "Processing file: lamp_0076.txt\n",
            "feature extraction time:  5.5611207485198975\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4573,  764, 9898,  ..., 1516, 8623, 1893], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200190544128418\n",
            "Loss: 0.38766663640918203\n",
            "rotation error test:  49.00361978551311\n",
            "translation error test:  0.6591529537978963\n",
            "--- 11.2274010181427 seconds ---\n",
            "Epoch: [2/4], Batch: 154, Loss: 0.38766663640918203\n",
            "Processing file: lamp_0077.txt\n",
            "feature extraction time:  5.693172454833984\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000654220581055\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7977, 3364, 3380,  ..., 3352, 6147, 8162], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12900328636169434\n",
            "Loss: 0.3082956964739836\n",
            "rotation error test:  57.76346928378082\n",
            "translation error test:  0.8025471684958468\n",
            "--- 11.402822017669678 seconds ---\n",
            "Processing file: lamp_0078.txt\n",
            "feature extraction time:  5.485215187072754\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  34, 1913,  438,  ..., 7645,  902, 3233], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1063237190246582\n",
            "Loss: 0.17326894739071647\n",
            "rotation error test:  327.9817390580313\n",
            "translation error test:  0.28878981476992044\n",
            "--- 11.14465069770813 seconds ---\n",
            "Processing file: lamp_0079.txt\n",
            "feature extraction time:  5.567121267318726\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   3, 3814, 9818,  ..., 3157,  449, 8348], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1060023307800293\n",
            "Loss: 0.1231427349336528\n",
            "rotation error test:  470.50623991241264\n",
            "translation error test:  0.10592056048809442\n",
            "--- 11.251245021820068 seconds ---\n",
            "Processing file: lamp_0080.txt\n",
            "feature extraction time:  5.606171369552612\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   2, 6863, 9746,  ..., 8757, 8945, 1942], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08600187301635742\n",
            "Loss: 0.258832552081132\n",
            "rotation error test:  273.10564182287953\n",
            "translation error test:  0.618450700892529\n",
            "--- 11.319908857345581 seconds ---\n",
            "Processing file: lamp_0081.txt\n",
            "feature extraction time:  5.628124952316284\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01300048828125\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7160, 2951, 2628,  ..., 7554, 4759, 8375], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11500191688537598\n",
            "Loss: 0.2896929652147542\n",
            "rotation error test:  59.19752524340917\n",
            "translation error test:  0.7395273088312558\n",
            "--- 11.369250297546387 seconds ---\n",
            "Epoch: [2/4], Batch: 159, Loss: 0.2896929652147542\n",
            "Processing file: lamp_0082.txt\n",
            "feature extraction time:  5.5091235637664795\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9101, 1495, 5979,  ...,  449, 7094, 2352], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1080019474029541\n",
            "Loss: 0.2944204090264509\n",
            "rotation error test:  61.22209939535308\n",
            "translation error test:  0.9116971113273221\n",
            "--- 11.234413623809814 seconds ---\n",
            "Processing file: lamp_0083.txt\n",
            "feature extraction time:  5.573222398757935\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 183, 5711, 9729,  ..., 6509, 6808, 5534], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200214385986328\n",
            "Loss: 0.1925381792431139\n",
            "rotation error test:  13.451735920691752\n",
            "translation error test:  0.7644216385712902\n",
            "--- 11.420350074768066 seconds ---\n",
            "Processing file: lamp_0084.txt\n",
            "feature extraction time:  5.489119291305542\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7154,  440, 9637,  ...,  696, 9796,   15], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11200213432312012\n",
            "Loss: 0.18321529504814033\n",
            "rotation error test:  18.052867576796373\n",
            "translation error test:  0.41367592513445905\n",
            "--- 11.282245635986328 seconds ---\n",
            "Processing file: lamp_0085.txt\n",
            "feature extraction time:  5.483119487762451\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6459,  445, 8437,  ..., 3958, 3664, 4384], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09900140762329102\n",
            "Loss: 0.10534598460356412\n",
            "rotation error test:  19.976383571173603\n",
            "translation error test:  0.33492403028198625\n",
            "--- 11.269245386123657 seconds ---\n",
            "Processing file: lamp_0086.txt\n",
            "feature extraction time:  5.507120370864868\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3888, 8721, 5949,  ..., 7951, 9752, 3431], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12200260162353516\n",
            "Loss: 0.3213210207434555\n",
            "rotation error test:  327.4041483887686\n",
            "translation error test:  1.0746893185962418\n",
            "--- 11.326247215270996 seconds ---\n",
            "Epoch: [2/4], Batch: 164, Loss: 0.3213210207434555\n",
            "Processing file: lamp_0087.txt\n",
            "feature extraction time:  5.572120904922485\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   2, 9048,  951,  ..., 3035, 3527, 9584], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12600278854370117\n",
            "Loss: 0.21801699769607907\n",
            "rotation error test:  15.746762426797474\n",
            "translation error test:  0.4757292083527499\n",
            "--- 11.284299850463867 seconds ---\n",
            "Processing file: lamp_0088.txt\n",
            "feature extraction time:  5.577121734619141\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2826, 7430, 3048,  ..., 4056, 6658,  471], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10300207138061523\n",
            "Loss: 0.10505858630253244\n",
            "rotation error test:  100.3294883332944\n",
            "translation error test:  0.2047884594225279\n",
            "--- 11.325246810913086 seconds ---\n",
            "Processing file: lamp_0089.txt\n",
            "feature extraction time:  5.657123327255249\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3976, 1204, 6784,  ..., 5564, 7260, 6094], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11749792098999023\n",
            "Loss: 0.2373695911202581\n",
            "rotation error test:  15.474974516750004\n",
            "translation error test:  0.7954723737473393\n",
            "--- 11.352854013442993 seconds ---\n",
            "Processing file: lamp_0090.txt\n",
            "feature extraction time:  5.667125701904297\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 527, 5582, 7067,  ..., 8908, 5513, 8828], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600210189819336\n",
            "Loss: 0.15540520640109473\n",
            "rotation error test:  45.43583703445539\n",
            "translation error test:  0.4059078612897446\n",
            "--- 11.342249393463135 seconds ---\n",
            "Processing file: lamp_0091.txt\n",
            "feature extraction time:  5.634122848510742\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6018, 9168, 5555,  ..., 1517,  737, 6439], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.1258220672607422\n",
            "Loss: 0.2169013682985619\n",
            "rotation error test:  304.68559394148144\n",
            "translation error test:  0.6585911192989898\n",
            "--- 11.460094690322876 seconds ---\n",
            "Epoch: [2/4], Batch: 169, Loss: 0.2169013682985619\n",
            "Processing file: lamp_0092.txt\n",
            "feature extraction time:  5.722201108932495\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  38, 5870, 2370,  ..., 5149, 3811, 8418], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12600302696228027\n",
            "Loss: 0.28994675037089124\n",
            "rotation error test:  210.5688787100555\n",
            "translation error test:  0.49531246219322744\n",
            "--- 11.530328035354614 seconds ---\n",
            "Processing file: lamp_0093.txt\n",
            "feature extraction time:  5.54412055015564\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 731, 6700, 4289,  ..., 4250, 1413, 1894], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13800358772277832\n",
            "Loss: 0.25389304870747414\n",
            "rotation error test:  44.32346757513085\n",
            "translation error test:  0.7640320040635763\n",
            "--- 11.493338108062744 seconds ---\n",
            "Processing file: lamp_0094.txt\n",
            "feature extraction time:  5.549123048782349\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1478, 2943, 9248,  ..., 4256, 2766,   93], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13007760047912598\n",
            "Loss: 0.38902037431363634\n",
            "rotation error test:  9.601608259891607\n",
            "translation error test:  1.12133103801568\n",
            "--- 11.325323581695557 seconds ---\n",
            "Processing file: lamp_0095.txt\n",
            "feature extraction time:  5.506102085113525\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4149, 1578, 6727,  ..., 8934, 8481, 2420], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12000203132629395\n",
            "Loss: 0.350440258535449\n",
            "rotation error test:  51.75993606837452\n",
            "translation error test:  0.7645303175953393\n",
            "--- 11.313709735870361 seconds ---\n",
            "Processing file: lamp_0096.txt\n",
            "feature extraction time:  5.485085487365723\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9608,  590, 9692,  ..., 7877, 7149, 9404], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400199890136719\n",
            "Loss: 0.3991694883042647\n",
            "rotation error test:  238.6035439397098\n",
            "translation error test:  0.8357928308250295\n",
            "--- 11.161211729049683 seconds ---\n",
            "Epoch: [2/4], Batch: 174, Loss: 0.3991694883042647\n",
            "Processing file: lamp_0097.txt\n",
            "feature extraction time:  5.5840904712677\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  19, 2251, 1920,  ..., 5422, 2974, 2377], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11660051345825195\n",
            "Loss: 0.17717057489409674\n",
            "rotation error test:  45.635015222296474\n",
            "translation error test:  0.4551771155984755\n",
            "--- 11.31384539604187 seconds ---\n",
            "Processing file: lamp_0098.txt\n",
            "feature extraction time:  5.598152160644531\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999223709106445\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4678, 1980, 1050,  ..., 1703, 5751, 8883], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10000181198120117\n",
            "Loss: 0.3167740208774133\n",
            "rotation error test:  56.482791486053145\n",
            "translation error test:  0.693659280057606\n",
            "--- 11.279240369796753 seconds ---\n",
            "Processing file: lamp_0099.txt\n",
            "feature extraction time:  5.613256454467773\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014999866485595703\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9251, 4616, 9938,  ..., 2296, 4937, 4191], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08800172805786133\n",
            "Loss: 0.1103131164531765\n",
            "rotation error test:  29.37068461178016\n",
            "translation error test:  0.3321953165396398\n",
            "--- 11.282344818115234 seconds ---\n",
            "Processing file: lamp_0100.txt\n",
            "feature extraction time:  5.674158096313477\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([8040,  862, 2032,  ...,  746, 5374, 4259], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11900210380554199\n",
            "Loss: 0.3859507360353612\n",
            "rotation error test:  21.97960500693928\n",
            "translation error test:  0.8657358725450935\n",
            "--- 11.419248104095459 seconds ---\n",
            "Processing file: lamp_0101.txt\n",
            "feature extraction time:  5.702089071273804\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4746, 3755, 9962,  ..., 7745, 1765, 1815], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09200119972229004\n",
            "Loss: 0.30570157266468373\n",
            "rotation error test:  112.51122739767747\n",
            "translation error test:  0.7293122939866891\n",
            "--- 11.372178316116333 seconds ---\n",
            "Epoch: [2/4], Batch: 179, Loss: 0.30570157266468373\n",
            "Processing file: lamp_0102.txt\n",
            "feature extraction time:  5.498086214065552\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 906, 6589, 4671,  ..., 2679, 4483,  470], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11100220680236816\n",
            "Loss: 0.22831633813122673\n",
            "rotation error test:  21.95204503715143\n",
            "translation error test:  0.8093909554294645\n",
            "--- 11.220175981521606 seconds ---\n",
            "Processing file: lamp_0103.txt\n",
            "feature extraction time:  5.528086423873901\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   1, 9803, 7195,  ..., 2553, 4030, 3992], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09600138664245605\n",
            "Loss: 0.2458999355298541\n",
            "rotation error test:  160.24580160016293\n",
            "translation error test:  0.699237344926676\n",
            "--- 11.276176691055298 seconds ---\n",
            "Processing file: lamp_0104.txt\n",
            "feature extraction time:  5.482085704803467\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000011444091797\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([   6, 9982, 4853,  ...,  737, 4276, 2969], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09700155258178711\n",
            "Loss: 0.30718317580596266\n",
            "rotation error test:  56.11602443383649\n",
            "translation error test:  0.6030273898869192\n",
            "--- 11.22217583656311 seconds ---\n",
            "Processing file: lamp_0105.txt\n",
            "feature extraction time:  5.5140862464904785\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2403, 6591, 8450,  ..., 1264, 2689,  210], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11681842803955078\n",
            "Loss: 0.3092826412995841\n",
            "rotation error test:  41.166151349517534\n",
            "translation error test:  0.8397358839812554\n",
            "--- 11.364181756973267 seconds ---\n",
            "Processing file: lamp_0106.txt\n",
            "feature extraction time:  5.492085933685303\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9293, 9730, 6204,  ..., 2833, 8894, 4713], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10700225830078125\n",
            "Loss: 0.21258029810673226\n",
            "rotation error test:  35.84621235307203\n",
            "translation error test:  0.6834051848397232\n",
            "--- 11.224175930023193 seconds ---\n",
            "Epoch: [2/4], Batch: 184, Loss: 0.21258029810673226\n",
            "Processing file: lamp_0107.txt\n",
            "feature extraction time:  5.5110862255096436\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5536, 8862, 2094,  ..., 7945, 5615, 7428], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.13902568817138672\n",
            "Loss: 0.11269735860564384\n",
            "rotation error test:  9.68471744917762\n",
            "translation error test:  0.38436086799257957\n",
            "--- 11.28526520729065 seconds ---\n",
            "Processing file: lamp_0108.txt\n",
            "feature extraction time:  5.594089984893799\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4688,  692, 4813,  ..., 8290, 7643, 4655], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10400199890136719\n",
            "Loss: 0.2020860725295736\n",
            "rotation error test:  454.43274103735007\n",
            "translation error test:  0.4565246298154865\n",
            "--- 11.268671751022339 seconds ---\n",
            "Processing file: lamp_0109.txt\n",
            "feature extraction time:  5.544086933135986\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000892639160156\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4260,  894, 5151,  ..., 8050, 2568, 3043], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11108016967773438\n",
            "Loss: 0.28164167617751923\n",
            "rotation error test:  48.19620575864459\n",
            "translation error test:  0.9679467358930015\n",
            "--- 11.20225715637207 seconds ---\n",
            "Processing file: lamp_0110.txt\n",
            "feature extraction time:  5.443087577819824\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000011444091797\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010008811950683594\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4574, 4496, 2779,  ..., 4469, 7293, 3060], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.12104678153991699\n",
            "Loss: 0.2248766476946532\n",
            "rotation error test:  36.639584945038365\n",
            "translation error test:  0.4166874814409566\n",
            "--- 11.178225040435791 seconds ---\n",
            "Processing file: lamp_0111.txt\n",
            "feature extraction time:  5.528087139129639\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 310, 8960, 4238,  ..., 5929, 4751, 1179], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08600091934204102\n",
            "Loss: 0.34161480138673084\n",
            "rotation error test:  18.581993940212\n",
            "translation error test:  0.7837816631181651\n",
            "--- 11.237176656723022 seconds ---\n",
            "Epoch: [2/4], Batch: 189, Loss: 0.34161480138673084\n",
            "Processing file: lamp_0112.txt\n",
            "feature extraction time:  5.5210864543914795\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 855, 7951, 8858,  ..., 2289, 5202, 3956], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11900186538696289\n",
            "Loss: 0.3177331372514923\n",
            "rotation error test:  120.82158419502576\n",
            "translation error test:  0.25086870673833384\n",
            "--- 11.292176961898804 seconds ---\n",
            "Processing file: lamp_0113.txt\n",
            "feature extraction time:  5.5010857582092285\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014001131057739258\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4867, 9497, 3668,  ..., 4244,  983, 4265], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11611437797546387\n",
            "Loss: 0.12709760032594547\n",
            "rotation error test:  230.1219803865031\n",
            "translation error test:  0.22793724007317706\n",
            "--- 11.276306629180908 seconds ---\n",
            "Processing file: lamp_0114.txt\n",
            "feature extraction time:  5.49608850479126\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01400136947631836\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  11, 9989, 9060,  ..., 1852, 2677, 3402], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10100173950195312\n",
            "Loss: 0.18512385091590405\n",
            "rotation error test:  25.521357538035172\n",
            "translation error test:  0.5680497696784661\n",
            "--- 11.224250555038452 seconds ---\n",
            "Processing file: lamp_0115.txt\n",
            "feature extraction time:  5.526086807250977\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([3133, 4200,    9,  ..., 3623,  847, 5331], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11000251770019531\n",
            "Loss: 0.4775396743726668\n",
            "rotation error test:  56.84348913775746\n",
            "translation error test:  1.1237486308873335\n",
            "--- 11.296177387237549 seconds ---\n",
            "loss epoch [0.13561131243414615, 0.29309773701968106, 0.2944856253926542, 0.20887352311879298, 0.22044553628631686, 0.24892027226897265, 0.21280595820472437, 0.10090878477502832, 0.2841430998881946, 0.19417165220574284, 0.2573719358954675, 0.2602845501747346, 0.29128842685438583, 0.17056972738254386, 0.21574613650348828, 0.11660921195409267, 0.33994559734380586, 0.1870090413343321, 0.17261106214708896, 0.136800908722958, 0.23853983269994172, 0.1987204141384075, 0.16784868749467488, 0.3135737617028523, 0.3875522858844646, 0.19501987518563574, 0.11399961474496262, 0.27101024195681317, 0.3171945836580118, 0.2779283286608119, 0.06740662887933409, 0.17694291782959085, 0.3740870667634736, 0.1655755416373022, 0.27987970020733005, 0.2291950343266047, 0.31120395799131906, 0.08311236873817163, 0.3485778929739673, 0.2255451586012164, 0.1584263506471805, 0.1155388655058045, 0.33704249656104723, 0.20568403641283187, 0.263501957871026, 0.19629226490103693, 0.30589248383128176, 0.3311387350019541, 0.196294712701656, 0.14895140616105182, 0.24640985806524737, 0.08860436052513823, 0.10409363683586159, 0.29516137794550973, 0.23129174620858245, 0.19674976600719168, 0.15538041805637154, 0.34602936600572776, 0.18981840442862452, 0.22677928399838637, 0.2839754598530614, 0.13557494624542096, 0.2106732457611351, 0.22029762617149812, 0.10097170885021536, 0.31476480631222004, 0.3014627642303123, 0.27065726599271756, 0.3004818071926478, 0.24657976379308996, 0.14687736184293007, 0.39191752087082415, 0.15501082785653594, 0.1175407839995668, 0.10169100484614979, 0.31057354744551025, 0.17797312163810863, 0.21764244269193858, 0.14407642262850867, 0.2192036539302291, 0.24891452431642985, 0.24856837634131257, 0.2836831367928282, 0.15658091718291706, 0.2818944785841013, 0.22738913104525055, 0.28120979026247717, 0.1804257996800953, 0.11615260970533262, 0.45045734313424823, 0.31059543202917383, 0.1474982774030784, 0.39513122767287323, 0.2764429738053923, 0.21485851019602392, 0.2108477442670528, 0.2039244633707199, 0.16346165976674953, 0.27550780205201764, 0.3824357547499121, 0.19196061230797745, 0.29611139000265274, 0.27712700332611945, 0.4418335627926288, 0.20760448520539898, 0.18107256835836436, 0.16538009505736811, 0.3141902799325951, 0.33348095846677056, 0.24441331767409816, 0.16494275439397896, 0.13023032999789713, 0.09208210135936822, 0.2967550410219521, 0.3258802051951768, 0.3546630896544134, 0.2608353385971933, 0.20498920402911708, 0.2100573444518514, 0.22138176671648174, 0.36248909398234425, 0.1755379900229707, 0.20345763887548818, 0.3586898462487514, 0.24315431715587124, 0.20075765824164585, 0.2195892015825748, 0.32537595315664297, 0.18417208969690094, 0.2720287763230344, 0.3512262474422667, 0.25416523580052036, 0.2682845870212545, 0.21534758776508084, 0.20885759958318878, 0.22975894813736816, 0.12059378520749542, 0.445281947579174, 0.22695840863914962, 0.2854990061143853, 0.1996559991877707, 0.2247667573755586, 0.3946689839622621, 0.2834771583378989, 0.24356988211531416, 0.1512311549455423, 0.20810921340237679, 0.17822714766853973, 0.2556686657281498, 0.25576807234305476, 0.22237160634796976, 0.11881035139260174, 0.10913675952428006, 0.37398196899293124, 0.38766663640918203, 0.3082956964739836, 0.17326894739071647, 0.1231427349336528, 0.258832552081132, 0.2896929652147542, 0.2944204090264509, 0.1925381792431139, 0.18321529504814033, 0.10534598460356412, 0.3213210207434555, 0.21801699769607907, 0.10505858630253244, 0.2373695911202581, 0.15540520640109473, 0.2169013682985619, 0.28994675037089124, 0.25389304870747414, 0.38902037431363634, 0.350440258535449, 0.3991694883042647, 0.17717057489409674, 0.3167740208774133, 0.1103131164531765, 0.3859507360353612, 0.30570157266468373, 0.22831633813122673, 0.2458999355298541, 0.30718317580596266, 0.3092826412995841, 0.21258029810673226, 0.11269735860564384, 0.2020860725295736, 0.28164167617751923, 0.2248766476946532, 0.34161480138673084, 0.3177331372514923, 0.12709760032594547, 0.18512385091590405, 0.4775396743726668]\n",
            "epoch #3\n",
            "Processing file: cup_0001.txt\n",
            "feature extraction time:  5.682806968688965\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0009999275207519531\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 440, 8959, 8199,  ..., 6078, 3160, 3844], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09700155258178711\n",
            "Loss: 0.34165184495277556\n",
            "rotation error test:  45.46439761850555\n",
            "translation error test:  0.9681769039788194\n",
            "--- 11.464977264404297 seconds ---\n",
            "Processing file: cup_0002.txt\n",
            "feature extraction time:  5.505086183547974\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013000249862670898\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6206, 4214,  751,  ..., 2890, 9842, 4976], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11200165748596191\n",
            "Loss: 0.12320126018477297\n",
            "rotation error test:  22.53415251778835\n",
            "translation error test:  0.4408032580959953\n",
            "--- 11.19824767112732 seconds ---\n",
            "Processing file: cup_0003.txt\n",
            "feature extraction time:  5.581059455871582\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014029979705810547\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010068416595458984\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7393,  388, 2319,  ..., 8138, 5265, 8310], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10083866119384766\n",
            "Loss: 0.17389361050665547\n",
            "rotation error test:  28.15594194661253\n",
            "translation error test:  0.3641897167413031\n",
            "--- 11.251171350479126 seconds ---\n",
            "Processing file: cup_0004.txt\n",
            "feature extraction time:  5.695033073425293\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4361, 4623,  733,  ..., 6213, 5028, 1596], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09800124168395996\n",
            "Loss: 0.13369906290020858\n",
            "rotation error test:  22.293960377197656\n",
            "translation error test:  0.3243186299811664\n",
            "--- 11.402122735977173 seconds ---\n",
            "Processing file: cup_0005.txt\n",
            "feature extraction time:  5.498086214065552\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000892639160156\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.00099945068359375\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1977, 6521, 8503,  ..., 9043, 1727, 8128], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09200096130371094\n",
            "Loss: 0.2596533672025551\n",
            "rotation error test:  273.98351421300976\n",
            "translation error test:  0.31976062903164043\n",
            "--- 11.23617672920227 seconds ---\n",
            "Epoch: [3/4], Batch: 4, Loss: 0.2596533672025551\n",
            "Processing file: cup_0006.txt\n",
            "feature extraction time:  5.635087966918945\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7690,  297, 8148,  ...,  411, 2091, 5828], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11300158500671387\n",
            "Loss: 0.21528217578168274\n",
            "rotation error test:  18.105740468131454\n",
            "translation error test:  0.41748823370291066\n",
            "--- 11.35216736793518 seconds ---\n",
            "Processing file: cup_0007.txt\n",
            "feature extraction time:  5.525062799453735\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([5821, 4408, 7808,  ...,  650, 5195, 3000], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09300112724304199\n",
            "Loss: 0.13410194960013147\n",
            "rotation error test:  266.202286796662\n",
            "translation error test:  0.4800815361328301\n",
            "--- 11.274128437042236 seconds ---\n",
            "Processing file: cup_0008.txt\n",
            "feature extraction time:  5.484062194824219\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4066, 4057, 5644,  ..., 7297, 7946, 9557], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10600137710571289\n",
            "Loss: 0.31104881115100613\n",
            "rotation error test:  286.1850826959153\n",
            "translation error test:  0.71210416634093\n",
            "--- 11.171127080917358 seconds ---\n",
            "Processing file: cup_0009.txt\n",
            "feature extraction time:  5.567062616348267\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7818, 2512, 3975,  ..., 6539, 3783, 7073], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11900138854980469\n",
            "Loss: 0.2493357410712865\n",
            "rotation error test:  52.557466168424355\n",
            "translation error test:  0.5885838900933744\n",
            "--- 11.359910249710083 seconds ---\n",
            "Processing file: cup_0010.txt\n",
            "feature extraction time:  5.508063077926636\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015074014663696289\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([4777, 3743,   29,  ..., 4556,  685, 1657], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200142860412598\n",
            "Loss: 0.20646972621604703\n",
            "rotation error test:  46.545261315886655\n",
            "translation error test:  0.5139825438186574\n",
            "--- 11.292202949523926 seconds ---\n",
            "Epoch: [3/4], Batch: 9, Loss: 0.20646972621604703\n",
            "Processing file: cup_0011.txt\n",
            "feature extraction time:  5.6011271476745605\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.013999700546264648\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9222, 9195, 1474,  ..., 9912, 8331, 2514], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10900068283081055\n",
            "Loss: 0.07856220177392725\n",
            "rotation error test:  14.603880747609345\n",
            "translation error test:  0.11550913835611232\n",
            "--- 11.355254173278809 seconds ---\n",
            "Processing file: cup_0012.txt\n",
            "feature extraction time:  5.543062925338745\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([2772,  226,  693,  ..., 3043, 8740, 7657], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09000205993652344\n",
            "Loss: 0.21316497665867626\n",
            "rotation error test:  102.01007130842974\n",
            "translation error test:  0.15130970842132518\n",
            "--- 11.25004506111145 seconds ---\n",
            "Processing file: cup_0013.txt\n",
            "feature extraction time:  5.493062257766724\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7077, 2859, 5618,  ..., 2391, 6271, 6623], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10379815101623535\n",
            "Loss: 0.2858617625244618\n",
            "rotation error test:  100.96472851965603\n",
            "translation error test:  0.6349202912265406\n",
            "--- 11.274966955184937 seconds ---\n",
            "Processing file: cup_0014.txt\n",
            "feature extraction time:  5.689186096191406\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000343322753906\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 933, 9572, 5463,  ..., 5756, 4620, 8328], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200119018554688\n",
            "Loss: 0.21453195299737005\n",
            "rotation error test:  335.0343930261174\n",
            "translation error test:  0.6758556031891114\n",
            "--- 11.410315990447998 seconds ---\n",
            "Processing file: cup_0015.txt\n",
            "feature extraction time:  5.766065835952759\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01400303840637207\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 540, 7118, 2163,  ..., 5813, 9283, 8933], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10445618629455566\n",
            "Loss: 0.21298997255832838\n",
            "rotation error test:  32.12709104578354\n",
            "translation error test:  0.627211994193325\n",
            "--- 11.55777645111084 seconds ---\n",
            "Epoch: [3/4], Batch: 14, Loss: 0.21298997255832838\n",
            "Processing file: cup_0016.txt\n",
            "feature extraction time:  5.5760626792907715\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01399993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1643, 3146, 6397,  ..., 8252, 2201, 4945], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09800100326538086\n",
            "Loss: 0.3025931112850482\n",
            "rotation error test:  273.56934797784857\n",
            "translation error test:  0.7358771560262103\n",
            "--- 11.527131795883179 seconds ---\n",
            "Processing file: cup_0017.txt\n",
            "feature extraction time:  5.767065525054932\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015034914016723633\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  13, 2812, 3720,  ..., 2885, 7735, 3569], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.11124086380004883\n",
            "Loss: 0.19618553045475917\n",
            "rotation error test:  13.735307157214336\n",
            "translation error test:  0.5444314773421968\n",
            "--- 11.742312669754028 seconds ---\n",
            "Processing file: cup_0018.txt\n",
            "feature extraction time:  5.722182989120483\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([7797,  696, 3324,  ..., 2034, 3696, 6077], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09400081634521484\n",
            "Loss: 0.11544401800161813\n",
            "rotation error test:  21.12929556386946\n",
            "translation error test:  0.2596540334743601\n",
            "--- 11.610249996185303 seconds ---\n",
            "Processing file: cup_0019.txt\n",
            "feature extraction time:  5.710064888000488\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([  37, 4528, 6830,  ..., 6358, 9630, 4254], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09399986267089844\n",
            "Loss: 0.1068485424836405\n",
            "rotation error test:  15.850404290203299\n",
            "translation error test:  0.2575485566584009\n",
            "--- 11.620132207870483 seconds ---\n",
            "Processing file: cup_0020.txt\n",
            "feature extraction time:  5.721100091934204\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014002084732055664\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1470, 8019, 7187,  ..., 9740, 5066, 5834], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09900093078613281\n",
            "Loss: 0.13775509211291914\n",
            "rotation error test:  13.23384364437239\n",
            "translation error test:  0.43530545568005663\n",
            "--- 11.644154787063599 seconds ---\n",
            "Epoch: [3/4], Batch: 19, Loss: 0.13775509211291914\n",
            "Processing file: cup_0021.txt\n",
            "feature extraction time:  5.748140335083008\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.015000104904174805\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([9252,    8, 2025,  ..., 8497, 7961, 8406], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.105133056640625\n",
            "Loss: 0.28148624141430867\n",
            "rotation error test:  61.56661720540038\n",
            "translation error test:  0.6052247101129407\n",
            "--- 11.684606552124023 seconds ---\n",
            "Processing file: cup_0022.txt\n",
            "feature extraction time:  5.717064619064331\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.0149993896484375\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([6262, 1645, 7315,  ..., 6664, 7861, 8259], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09912109375\n",
            "Loss: 0.27870569912562254\n",
            "rotation error test:  15.284386553169938\n",
            "translation error test:  0.8390988694174409\n",
            "--- 11.647404909133911 seconds ---\n",
            "Processing file: cup_0023.txt\n",
            "feature extraction time:  5.742065191268921\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000415802001953\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1554, 9763, 7610,  ..., 8728, 3230, 6372], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.09819483757019043\n",
            "Loss: 0.2449341417910931\n",
            "rotation error test:  15.474475297440316\n",
            "translation error test:  0.6229693469271652\n",
            "--- 11.68532943725586 seconds ---\n",
            "Processing file: cup_0024.txt\n",
            "feature extraction time:  5.740149021148682\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.014000177383422852\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0010001659393310547\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([1869, 9756, 5642,  ..., 2342, 5561, 2327], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.08573198318481445\n",
            "Loss: 0.35232744992078757\n",
            "rotation error test:  23.79680858709476\n",
            "translation error test:  0.7887642501429108\n",
            "--- 11.730950832366943 seconds ---\n",
            "Processing file: cup_0025.txt\n",
            "feature extraction time:  5.7360680103302\n",
            "src_keypts_idx_unsqueezed:  torch.Size([1, 6, 64])\n",
            "src_keypts:  torch.Size([1, 64, 6])\n",
            "Grouping keypoints time:  0.01600027084350586\n",
            "B:  1\n",
            "K_topk:  64\n",
            "nsample:  32\n",
            "num_feat:  32\n",
            "get_cat_feat_src time:  0.0\n",
            "tgt_pts_xyz:  torch.Size([1, 10000, 3])\n",
            "ref_pts:  torch.Size([1, 10000, 3])\n",
            "dist_normalize:  torch.Size([1, 32, 13824])\n",
            "feat_weight_map:  torch.Size([1, 32, 32, 13824])\n",
            "idx_1_mask:  tensor([[0]])\n",
            "idx_1_mask_flatten:  tensor([0])\n",
            "idx_2_mask:  tensor([ 354, 3866, 4426,  ...,  584, 4878, 8908], device='cuda:0')\n",
            "get_cat_feat_tgt time:  0.10200095176696777\n",
            "Loss: 0.23121957985000943\n",
            "rotation error test:  24.768646445881206\n",
            "translation error test:  0.7992297480442947\n",
            "--- 11.679135799407959 seconds ---\n",
            "Epoch: [3/4], Batch: 24, Loss: 0.23121957985000943\n",
            "Processing file: cup_0026.txt\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m src, target, R_gt, t_gt, R_prior \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device), R_gt\u001b[38;5;241m.\u001b[39mto(device), t_gt\u001b[38;5;241m.\u001b[39mto(device), R_prior\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m t_init \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m---> 20\u001b[0m src_keypts, target_vcp \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_prior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# print('src_keypts shape', src_keypts.shape)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# print('target_vcp shape', target_vcp.shape)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# zero gradient \u001b[39;00m\n\u001b[0;32m     24\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[1;32mc:\\Users\\niladutt\\.conda\\envs\\nsd\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32m\\\\evs2.cs.ucl.ac.uk\\student-msc\\cgvi\\2022\\niladutt\\DeepVCP-Pointcloud-Registration\\deepVCP.py:30\u001b[0m, in \u001b[0;36mDeepVCP.forward\u001b[1;34m(self, src_pts, tgt_pts, R_init, t_init)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m# deep features extracted from FE layer: B x N x 32\u001b[39;00m\n\u001b[0;32m     29\u001b[0m fe_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 30\u001b[0m src_deep_feat_xyz, src_deep_feat_pts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mFE1(src_pts)\n\u001b[0;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfeature extraction time: \u001b[39m\u001b[39m\"\u001b[39m, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m fe_start_time)\n\u001b[0;32m     33\u001b[0m \u001b[39m# obtain the top k indices for src point clouds\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\niladutt\\.conda\\envs\\nsd\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32m\\\\evs2.cs.ucl.ac.uk\\student-msc\\cgvi\\2022\\niladutt\\DeepVCP-Pointcloud-Registration\\deep_feat_extraction.py:28\u001b[0m, in \u001b[0;36mfeat_extraction_layer.forward\u001b[1;34m(self, pts)\u001b[0m\n\u001b[0;32m     26\u001b[0m output_xyz, output_pts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msa1(xyz, normal)\n\u001b[0;32m     27\u001b[0m output_xyz, output_pts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msa2(output_xyz, normal)\n\u001b[1;32m---> 28\u001b[0m output_xyz, output_pts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msa3(output_xyz, normal)\n\u001b[0;32m     29\u001b[0m output_xyz \u001b[39m=\u001b[39m output_xyz\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m output_pts \u001b[39m=\u001b[39m output_pts\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\niladutt\\.conda\\envs\\nsd\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32m\\\\evs2.cs.ucl.ac.uk\\student-msc\\cgvi\\2022\\niladutt\\DeepVCP-Pointcloud-Registration\\pointnet2_utils.py:192\u001b[0m, in \u001b[0;36mPointNetSetAbstraction.forward\u001b[1;34m(self, xyz, points)\u001b[0m\n\u001b[0;32m    190\u001b[0m     new_xyz, new_points \u001b[39m=\u001b[39m sample_and_group_all(xyz, points)\n\u001b[0;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     new_xyz, new_points \u001b[39m=\u001b[39m sample_and_group(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnpoint, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mradius, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnsample, xyz, points)\n\u001b[0;32m    193\u001b[0m \u001b[39m# new_xyz: sampled points position data, [B, npoint, C]\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m# new_points: sampled points data, [B, npoint, nsample, C+D]\u001b[39;00m\n\u001b[0;32m    195\u001b[0m new_points \u001b[39m=\u001b[39m new_points\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m# [B, C+D, nsample,npoint]\u001b[39;00m\n",
            "File \u001b[1;32m\\\\evs2.cs.ucl.ac.uk\\student-msc\\cgvi\\2022\\niladutt\\DeepVCP-Pointcloud-Registration\\pointnet2_utils.py:124\u001b[0m, in \u001b[0;36msample_and_group\u001b[1;34m(npoint, radius, nsample, xyz, points, returnidx)\u001b[0m\n\u001b[0;32m    122\u001b[0m B, N, C \u001b[39m=\u001b[39m xyz\u001b[39m.\u001b[39mshape\n\u001b[0;32m    123\u001b[0m S \u001b[39m=\u001b[39m npoint\n\u001b[1;32m--> 124\u001b[0m fps_idx \u001b[39m=\u001b[39m farthest_point_sample(xyz, npoint) \u001b[39m# [B, npoint, C]\u001b[39;00m\n\u001b[0;32m    125\u001b[0m new_xyz \u001b[39m=\u001b[39m index_points(xyz, fps_idx)\n\u001b[0;32m    126\u001b[0m idx \u001b[39m=\u001b[39m query_ball_point(radius, nsample, xyz, new_xyz)\n",
            "File \u001b[1;32m\\\\evs2.cs.ucl.ac.uk\\student-msc\\cgvi\\2022\\niladutt\\DeepVCP-Pointcloud-Registration\\pointnet2_utils.py:79\u001b[0m, in \u001b[0;36mfarthest_point_sample\u001b[1;34m(xyz, npoint)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(npoint):\n\u001b[0;32m     78\u001b[0m     centroids[:, i] \u001b[39m=\u001b[39m farthest\n\u001b[1;32m---> 79\u001b[0m     centroid \u001b[39m=\u001b[39m xyz[batch_indices, farthest, :]\u001b[39m.\u001b[39;49mview(B, \u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m)\n\u001b[0;32m     80\u001b[0m     dist \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum((xyz \u001b[39m-\u001b[39m centroid) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     81\u001b[0m     mask \u001b[39m=\u001b[39m dist \u001b[39m<\u001b[39m distance\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "optim = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# begin train \n",
        "model.train()\n",
        "loss_epoch_avg = []\n",
        "train_loss = []\n",
        "rot_error = []\n",
        "translation_error = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"epoch #{epoch}\")\n",
        "    loss_epoch = []\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for n_batch, (src, target, R_gt, t_gt, R_prior) in enumerate(train_loader):\n",
        "        start_time = time.time()\n",
        "        # mini batch\n",
        "        src, target, R_gt, t_gt, R_prior = src.to(device), target.to(device), R_gt.to(device), t_gt.to(device), R_prior.to(device)\n",
        "        t_init = torch.randn((1, 3))\n",
        "        src_keypts, target_vcp = model(src, target, R_prior, t_init)\n",
        "        # print('src_keypts shape', src_keypts.shape)\n",
        "        # print('target_vcp shape', target_vcp.shape)\n",
        "        # zero gradient \n",
        "        optim.zero_grad()\n",
        "        loss, R_pred, t_pred = deepVCP_loss(src_keypts, target_vcp, R_gt, t_gt, alpha=0.5)\n",
        "\n",
        "        # error metric for rigid body transformation\n",
        "        r_pred = R.from_matrix(R_pred.squeeze(0).cpu().detach().numpy())\n",
        "        r_pred_arr = torch.tensor(r_pred.as_euler('xyz', degrees=True)).reshape(1, 3)\n",
        "        r_gt = R.from_matrix(R_gt.squeeze(0).cpu().detach().numpy())\n",
        "        r_gt_arr = torch.tensor(r_gt.as_euler('xyz', degrees=True)).reshape(1, 3)\n",
        "        pdist = nn.PairwiseDistance(p = 2)\n",
        "        t_pred = t_pred.squeeze(-1)\n",
        "        t_gt = t_gt.squeeze(-1)\n",
        "\n",
        "        rot_error.append(pdist(r_pred_arr, r_gt_arr).item())\n",
        "        translation_error.append(pdist(t_pred, t_gt).item())\n",
        "        \n",
        "        print(\"rotation error test: \", rot_error[-1])\n",
        "        print(\"translation error test: \", translation_error[-1])\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        # update parameters \n",
        "        optim.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        loss_epoch += [loss.item()]\n",
        "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        if (n_batch + 1) % 5 == 0:\n",
        "            print(\"Epoch: [{}/{}], Batch: {}, Loss: {}\".format(\n",
        "                epoch, num_epochs, n_batch, loss.item()))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    torch.save(model.state_dict(), \"epoch_\" + str(epoch) + \"_model.pt\")\n",
        "    loss_epoch_avg += [sum(loss_epoch) / len(loss_epoch)]\n",
        "    train_loss.append(sum(loss_epoch))\n",
        "    print(\"loss epoch\", loss_epoch)\n",
        "    with open(\"training_loss_\" + str(epoch) + \".txt\", \"wb\") as fp:   #Pickling\n",
        "        pickle.dump(loss_epoch, fp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2SL28L_2da7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# save\n",
        "print(\"Finished Training\")\n",
        "torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_gt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.10 ('nsd')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "28ddfe019228c1c2f609477641aa95b52d4df5f6bd621eab70bc33a459c81c5e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
